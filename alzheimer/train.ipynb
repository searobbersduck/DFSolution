{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from resnet import *\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import time\n",
    "import math\n",
    "from utils import AverageMeter\n",
    "import argparse\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='alzheimer desease recognnition')\n",
    "    parser.add_argument('--train_images', default='/data/beast/df/alzheimer/train.h5')\n",
    "    parser.add_argument('--train_labels', default='/data/beast/df/alzheimer/train.csv')\n",
    "    parser.add_argument('--val_images', default='/data/beast/df/alzheimer/val.h5')\n",
    "    parser.add_argument('--val_labels', default='/data/beast/df/alzheimer/val.csv')\n",
    "    parser.add_argument('--out_dir', default='/data/beast/df/alzheimer/out_model')\n",
    "    parser.add_argument('--phase', default='train', choices=['train', 'val', 'test', 'predict'])\n",
    "    parser.add_argument('--model', default='resnet34')\n",
    "    parser.add_argument('--weight', default=None)\n",
    "    parser.add_argument('--lr', default=1e-3, type=float)\n",
    "    parser.add_argument('--mom', default=0.9, type=float)\n",
    "    parser.add_argument('--wd', default=1e-4, type=float)\n",
    "    parser.add_argument('--fix', default=50, type=int)\n",
    "    parser.add_argument('--step', default=40, type=int)\n",
    "    parser.add_argument('--epoch', default=120, type=int)\n",
    "    parser.add_argument('--display', default=8, type=int)\n",
    "    parser.add_argument('--num_workers', default=2, type=int)\n",
    "    parser.add_argument('--batch_size', default=32, type=int)\n",
    "    return parser.parse_args(args=[])\n",
    "\n",
    "opt = parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:\t260.4920959472656\n",
      "std:\t273.56634521484375\n"
     ]
    }
   ],
   "source": [
    "def calc_stat_info(infile):\n",
    "    f = h5py.File(infile)\n",
    "    images = f['data']\n",
    "    mean = np.mean(images)\n",
    "    std = np.std(images)\n",
    "    return mean, std\n",
    "\n",
    "mean, std = calc_stat_info(opt.train_images)\n",
    "print('mean:\\t{}'.format(mean))\n",
    "print('std:\\t{}'.format(std))\n",
    "\n",
    "class AlzheimerDS(Dataset):\n",
    "    def __init__(self, infile, label_file):\n",
    "        f = h5py.File(infile)\n",
    "        images = f['data']\n",
    "        self.images = np.transpose(images, [0,1,3,2,4])\n",
    "#         self.mean = np.mean(images)\n",
    "#         self.std = np.std(images)\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.images = (self.images - self.mean)/self.std\n",
    "        self.images = torch.from_numpy(self.images).float()\n",
    "        df_labels = pd.read_csv(label_file)\n",
    "        self.labels = list(df_labels['label'])\n",
    "    def __getitem__(self, item):\n",
    "        image = self.images[item]\n",
    "        return image, self.labels[item]\n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = AlzheimerDS('/data/beast/df/alzheimer/train_pre_data.h5', \n",
    "#                 '/data/beast/df/alzheimer/train_pre_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataloader = DataLoader(ds, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = resnet34(num_classes=3, shortcut_type=True, sample_size=79, sample_duration=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_cls_weights(cls):\n",
    "    for m in cls.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            n = m.kernel_size[0]*m.kernel_size[1]*m.out_channels\n",
    "            m.weight.data.normal_(0, math.sqrt(2./n))\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            m.weight.data.fill_(1)\n",
    "            m.bias.data.zero_()\n",
    "        if isinstance(m, nn.Linear):\n",
    "            m.weight.data.normal_(0, 0.01)\n",
    "            m.bias.data.zero_()\n",
    "        if isinstance(m, nn.Conv3d):\n",
    "            n = m.kernel_size[0]*m.kernel_size[1]*m.kernel_size[2]*m.out_channels\n",
    "            m.weight.data.normal_(0, math.sqrt(2./n))\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_cls_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_cuda = nn.DataParallel(model).cuda()\n",
    "# criterion = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = 1e-3\n",
    "# mom = 0.9\n",
    "# wd = 1e-4\n",
    "\n",
    "# optimizer = optim.SGD([\n",
    "#     {'params': model.parameters()}\n",
    "# ], lr=lr, momentum=mom, weight_decay=wd, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data_loader, model, criterion, optimizer, epoch, display):\n",
    "    model.train()\n",
    "    tot_pred = np.array([], dtype=int)\n",
    "    tot_label = np.array([], dtype=int)\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    accuracy = AverageMeter()\n",
    "    end = time.time()\n",
    "    logger = []\n",
    "    for num_iter, (images, labels) in enumerate(train_data_loader):\n",
    "        data_time.update(time.time()-end)\n",
    "#         print(labels)\n",
    "        output = model(Variable(images.cuda()))\n",
    "        loss = criterion(output, Variable(labels.cuda()))\n",
    "        _,pred = torch.max(output, 1)\n",
    "#         kap = np.array(1-utils.quadratic_weighted_kappa(pred.cpu().numpy(), labels.cpu().numpy()), dtype=np.float32)\n",
    "#         loss1 = torch.autograd.Variable(torch.from_numpy(kap).cuda(), requires_grad=True)\n",
    "#         loss = loss + loss1\n",
    "#         print(loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_time.update(time.time()-end)\n",
    "        pred = pred.cpu().data.numpy().squeeze()\n",
    "        labels = labels.numpy().squeeze()\n",
    "        tot_pred = np.append(tot_pred, pred)\n",
    "        tot_label = np.append(tot_label, labels)\n",
    "        losses.update(loss.data.cpu().numpy(), len(images))\n",
    "        accuracy.update(np.equal(pred, labels).sum()/len(labels), len(labels))\n",
    "        end = time.time()\n",
    "        if (num_iter+1) % display == 0:\n",
    "            correct = np.equal(tot_pred, tot_label).sum()/len(tot_pred)\n",
    "            print_info = 'Epoch: [{0}][{1}/{2}]\\tTime {batch_time.val:3f} ({batch_time.avg:.3f})\\t'\\\n",
    "                'Data {data_time.avg:.3f}\\t''Loss {loss.avg:.4f}\\tAccuray {accuracy.avg:.4f}'.format(\n",
    "                epoch, num_iter, len(train_data_loader),batch_time=batch_time, data_time=data_time,\n",
    "                loss=losses, accuracy=accuracy\n",
    "            )\n",
    "            print(print_info)\n",
    "            logger.append(print_info)\n",
    "    kappa = utils.quadratic_weighted_kappa(tot_pred, tot_label)\n",
    "#     print('kappa:\\t{:.3f}'.format(kappa))\n",
    "    return accuracy.avg, logger\n",
    "\n",
    "\n",
    "def val(train_data_loader, model, criterion, optimizer, epoch, display):\n",
    "    model.train()\n",
    "    tot_pred = np.array([], dtype=int)\n",
    "    tot_label = np.array([], dtype=int)\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    accuracy = AverageMeter()\n",
    "    end = time.time()\n",
    "    logger = []\n",
    "    for num_iter, (images, labels) in enumerate(train_data_loader):\n",
    "        data_time.update(time.time()-end)\n",
    "#         print(labels)\n",
    "        output = model(Variable(images.cuda()))\n",
    "        loss = criterion(output, Variable(labels.cuda()))\n",
    "#         print(loss)\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        batch_time.update(time.time()-end)\n",
    "        _,pred = torch.max(output, 1)\n",
    "        pred = pred.cpu().data.numpy().squeeze()\n",
    "        labels = labels.numpy().squeeze()\n",
    "        tot_pred = np.append(tot_pred, pred)\n",
    "        tot_label = np.append(tot_label, labels)\n",
    "        losses.update(loss.data.cpu().numpy(), len(images))\n",
    "        accuracy.update(np.equal(pred, labels).sum()/len(labels), len(labels))\n",
    "        end = time.time()\n",
    "        if (num_iter+1) % display == 0:\n",
    "            correct = np.equal(tot_pred, tot_label).sum()/len(tot_pred)\n",
    "            print_info = 'Epoch: [{0}][{1}/{2}]\\tTime {batch_time.val:3f} ({batch_time.avg:.3f})\\t'\\\n",
    "                'Data {data_time.avg:.3f}\\t''Loss {loss.avg:.4f}\\tAccuray {accuracy.avg:.4f}'.format(\n",
    "                epoch, num_iter, len(train_data_loader),batch_time=batch_time, data_time=data_time,\n",
    "                loss=losses, accuracy=accuracy\n",
    "            )\n",
    "            print(print_info)\n",
    "            logger.append(print_info)\n",
    "    kappa = utils.quadratic_weighted_kappa(tot_pred, tot_label)\n",
    "    acc = np.sum(tot_pred == tot_label)/len(tot_pred)\n",
    "    print(tot_pred)\n",
    "    print(tot_label)\n",
    "    print('kappa:\\t{:.3f}, accuracy:\\t{:.3f}'.format(kappa, acc))\n",
    "    return accuracy.avg, logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     train(train_dataloader, nn.DataParallel(model).cuda(), criterion, optimizer, i, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(i=0):\n",
    "    print('====> parse options')\n",
    "    opt = parse_args()\n",
    "    print(opt)\n",
    "    \n",
    "    os.makedirs(opt.out_dir, exist_ok=True)\n",
    "#     time_stamp = time.strftime('%Y%m%d%H%M%S', time.localtime(time.time()))\n",
    "    time_stamp = 'xxx_{}'.format(i)\n",
    "    out_dir = os.path.join(opt.out_dir, 'alzheimer_recognition_{}'.format(time_stamp))\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    print('====> building model:')\n",
    "    model = resnet18(num_classes=3, shortcut_type=True, sample_size=79, sample_duration=95)\n",
    "    initial_cls_weights(model)\n",
    "    criterion = nn.CrossEntropyLoss(torch.from_numpy(np.array([2.0,1.0,2.0], dtype=np.float32))).cuda()\n",
    "    if opt.phase == 'train':\n",
    "#         train_ds = AlzheimerDS(opt.train_images, opt.train_labels)\n",
    "#         train_dataloader = DataLoader(train_ds, batch_size=opt.batch_size, shuffle=True, \n",
    "#                                       num_workers=opt.num_workers, pin_memory=True)\n",
    "        \n",
    "#         train_ds = AlzheimerDS(opt.train_images, opt.train_labels)\n",
    "#         train_dataloader = DataLoader(train_ds, batch_size=opt.batch_size, shuffle=True, \n",
    "#                                       num_workers=opt.num_workers, pin_memory=True)\n",
    "#         val_ds = AlzheimerDS(opt.val_images, opt.val_labels)\n",
    "#         val_dataloader = DataLoader(val_ds, batch_size=opt.batch_size, shuffle=True, \n",
    "#                                       num_workers=opt.num_workers, pin_memory=True)\n",
    "        train_ds = AlzheimerDS('/data/beast/df/alzheimer/train_{}.h5'.format(i), '/data/beast/df/alzheimer/train_{}.csv'.format(i))\n",
    "        train_dataloader = DataLoader(train_ds, batch_size=opt.batch_size, shuffle=True, \n",
    "                                      num_workers=opt.num_workers, pin_memory=True)\n",
    "        val_ds = AlzheimerDS('/data/beast/df/alzheimer/val_{}.h5'.format(i), '/data/beast/df/alzheimer/val_{}.csv'.format(i))\n",
    "        val_dataloader = DataLoader(val_ds, batch_size=opt.batch_size, shuffle=True, \n",
    "                                      num_workers=opt.num_workers, pin_memory=True)\n",
    "        beat_acc = 0.7\n",
    "        for epoch in range(opt.epoch):\n",
    "            if epoch < opt.fix:\n",
    "                lr = opt.lr\n",
    "            else:\n",
    "                lr = opt.lr * (0.1 ** (epoch//opt.step))\n",
    "            optimizer = None\n",
    "            optimizer = optim.SGD([{'params': model.parameters()}], \n",
    "                                  lr=opt.lr, momentum=opt.mom, weight_decay=opt.wd, nesterov=True)\n",
    "            \n",
    "            _, _ = train(train_dataloader, nn.DataParallel(model).cuda(), criterion, optimizer, epoch, opt.display)\n",
    "            acc, logger = val(val_dataloader, nn.DataParallel(model).cuda(), criterion, optimizer, epoch, opt.display)\n",
    "            if acc > beat_acc:\n",
    "                print('\\ncurrent best accuracy is: {}\\n'.format(acc))\n",
    "                beat_acc = acc\n",
    "                saved_model_name = os.path.join(out_dir, 'alzheimer_recognition_{:04d}_best.pth'.format(epoch))\n",
    "                torch.save(model.cpu().state_dict(), saved_model_name)\n",
    "                print('====> save model:\\t{}'.format(saved_model_name))\n",
    "                \n",
    "    \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> parse options\n",
      "Namespace(batch_size=32, display=8, epoch=120, fix=50, lr=0.001, model='resnet34', mom=0.9, num_workers=2, out_dir='/data/beast/df/alzheimer/out_model', phase='train', step=40, train_images='/data/beast/df/alzheimer/train.h5', train_labels='/data/beast/df/alzheimer/train.csv', val_images='/data/beast/df/alzheimer/val.h5', val_labels='/data/beast/df/alzheimer/val.csv', wd=0.0001, weight=None)\n",
      "====> building model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/beast/code/DFSolution/alzheimer/resnet.py:145: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][7/9]\tTime 0.161195 (0.231)\tData 0.049\tLoss 1.0966\tAccuray 0.4180\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 1 1 0 2 1 1 1 1 2 2 0 2 0 1 1 1 1 0 0 2 2 1 1 0 1 2 0 1 2]\n",
      "kappa:\t0.000, accuracy:\t0.233\n",
      "Epoch: [1][7/9]\tTime 0.168042 (0.205)\tData 0.038\tLoss 1.0714\tAccuray 0.3828\n",
      "[2 1 2 1 2 1 2 2 1 1 2 1 1 2 1 2 2 1 2 1 1 1 2 2 1 1 1 2 1 1]\n",
      "[2 1 2 1 2 1 0 0 1 1 2 1 1 2 1 2 0 1 0 1 1 1 2 0 1 0 2 0 1 1]\n",
      "kappa:\t0.042, accuracy:\t0.733\n",
      "\n",
      "current best accuracy is: 0.7333333333333333\n",
      "\n",
      "====> save model:\t/data/beast/df/alzheimer/out_model/alzheimer_recognition_xxx_0/alzheimer_recognition_0001_best.pth\n",
      "Epoch: [2][7/9]\tTime 0.165627 (0.214)\tData 0.041\tLoss 1.0311\tAccuray 0.6328\n",
      "[1 2 1 1 2 2 2 2 1 2 2 2 1 2 2 2 2 2 1 2 2 2 2 1 2 2 2 2 2 2]\n",
      "[1 2 1 1 0 0 2 0 1 1 1 0 1 0 1 2 2 2 1 2 1 1 1 1 2 0 1 2 1 0]\n",
      "kappa:\t0.013, accuracy:\t0.500\n",
      "Epoch: [3][7/9]\tTime 0.169170 (0.207)\tData 0.040\tLoss 0.9960\tAccuray 0.6953\n",
      "[2 1 2 1 1 2 1 2 2 1 1 1 2 1 1 1 1 1 2 2 1 1 2 2 2 2 1 1 2 1]\n",
      "[0 1 2 1 1 2 0 0 2 1 1 1 0 2 1 1 1 1 2 0 1 1 0 2 2 0 1 1 2 1]\n",
      "kappa:\t0.042, accuracy:\t0.733\n",
      "Epoch: [4][7/9]\tTime 0.167808 (0.204)\tData 0.034\tLoss 0.9447\tAccuray 0.7773\n",
      "[1 1 1 1 1 2 1 2 2 1 1 2 2 1 2 1 1 1 1 2 2 2 1 2 2 1 2 1 2 1]\n",
      "[1 0 1 1 1 0 1 2 2 1 1 0 0 1 2 1 2 1 1 0 2 2 1 0 2 1 2 1 0 1]\n",
      "kappa:\t0.042, accuracy:\t0.733\n",
      "Epoch: [5][7/9]\tTime 0.159638 (0.198)\tData 0.036\tLoss 0.8905\tAccuray 0.7852\n",
      "[2 1 1 1 2 1 1 1 1 1 2 1 2 1 2 1 1 1 1 1 2 2 2 2 2 1 2 2 1 2]\n",
      "[2 1 1 2 0 1 1 1 1 1 2 1 0 1 0 1 1 1 0 1 0 2 2 0 2 1 2 0 1 2]\n",
      "kappa:\t0.042, accuracy:\t0.733\n",
      "Epoch: [6][7/9]\tTime 0.167299 (0.211)\tData 0.041\tLoss 0.8556\tAccuray 0.7422\n",
      "[0 2 1 1 0 0 1 1 1 1 1 1 1 1 2 1 1 0 2 1 0 2 1 1 0 0 1 1 0 0]\n",
      "[2 0 1 1 0 0 0 1 2 1 1 1 1 1 2 1 1 2 0 1 0 2 1 1 2 2 1 1 0 2]\n",
      "kappa:\t-0.059, accuracy:\t0.700\n",
      "Epoch: [7][7/9]\tTime 0.159394 (0.202)\tData 0.037\tLoss 0.7947\tAccuray 0.7930\n",
      "[1 2 1 2 2 1 2 2 1 2 2 1 1 1 1 1 2 2 1 2 1 1 1 1 1 2 1 2 1 2]\n",
      "[1 0 1 2 2 1 2 0 1 0 2 1 1 1 1 0 2 2 1 0 1 1 1 2 1 0 1 0 1 2]\n",
      "kappa:\t0.042, accuracy:\t0.733\n",
      "Epoch: [8][7/9]\tTime 0.168136 (0.202)\tData 0.033\tLoss 0.7279\tAccuray 0.8164\n",
      "[1 2 2 1 1 2 2 2 2 1 2 1 1 1 2 2 1 1 1 1 1 1 2 1 1 1 2 2 1 2]\n",
      "[1 0 2 2 1 0 2 0 2 1 0 1 1 1 2 2 1 0 1 1 1 1 0 1 1 1 2 2 1 0]\n",
      "kappa:\t0.042, accuracy:\t0.733\n",
      "Epoch: [9][7/9]\tTime 0.166101 (0.208)\tData 0.039\tLoss 0.6821\tAccuray 0.8008\n",
      "[1 1 0 1 1 1 0 0 1 2 1 2 0 0 1 1 0 1 0 1 0 1 1 1 1 0 0 1 1 2]\n",
      "[1 1 2 2 1 1 0 0 1 2 1 2 0 0 1 1 2 1 2 1 2 1 1 1 1 2 0 0 1 0]\n",
      "kappa:\t0.087, accuracy:\t0.733\n",
      "Epoch: [10][7/9]\tTime 0.159378 (0.202)\tData 0.039\tLoss 0.6652\tAccuray 0.7930\n",
      "[2 2 2 1 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1]\n",
      "[2 2 2 1 0 0 0 2 2 2 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 2 1 2 1]\n",
      "kappa:\t0.042, accuracy:\t0.733\n",
      "Epoch: [11][7/9]\tTime 0.159459 (0.204)\tData 0.042\tLoss 0.5825\tAccuray 0.8594\n",
      "[1 1 2 1 1 2 1 1 1 2 1 1 2 1 2 1 1 1 1 2 2 2 1 1 2 2 2 2 1 2]\n",
      "[1 1 2 1 1 0 1 0 1 2 1 1 0 1 2 1 1 1 1 0 2 2 2 1 0 2 0 2 1 0]\n",
      "kappa:\t0.042, accuracy:\t0.733\n",
      "Epoch: [12][7/9]\tTime 0.160981 (0.203)\tData 0.035\tLoss 0.5599\tAccuray 0.8281\n",
      "[1 1 2 1 2 1 2 2 2 1 2 1 2 1 1 2 1 2 2 2 1 1 1 1 1 1 1 1 2 2]\n",
      "[1 1 0 2 0 1 2 0 2 1 0 1 2 1 1 0 1 2 2 2 1 1 1 1 1 1 0 1 0 2]\n",
      "kappa:\t0.042, accuracy:\t0.733\n",
      "Epoch: [13][7/9]\tTime 0.160820 (0.201)\tData 0.032\tLoss 0.5200\tAccuray 0.8359\n",
      "[0 2 2 2 1 2 2 1 1 2 1 1 1 1 0 2 2 1 1 1 2 1 1 1 2 1 2 1 1 0]\n",
      "[2 2 2 2 1 2 0 1 1 0 1 1 1 1 2 2 0 0 1 1 0 1 1 1 0 1 2 1 1 0]\n",
      "kappa:\t-0.019, accuracy:\t0.733\n",
      "Epoch: [14][7/9]\tTime 0.167191 (0.204)\tData 0.033\tLoss 0.5221\tAccuray 0.8555\n",
      "[2 2 1 2 1 2 2 1 1 2 1 1 1 1 1 1 2 1 2 2 1 2 2 0 1 2 2 1 1 2]\n",
      "[0 2 1 0 1 2 2 1 1 0 1 1 1 1 1 1 2 1 2 0 1 0 2 2 1 0 0 1 1 2]\n",
      "kappa:\t-0.098, accuracy:\t0.733\n",
      "Epoch: [15][7/9]\tTime 0.165156 (0.211)\tData 0.040\tLoss 0.4892\tAccuray 0.8633\n",
      "[2 2 1 1 1 1 2 0 1 0 1 1 1 2 1 1 1 2 2 1 1 2 2 1 1 2 2 1 1 2]\n",
      "[2 2 1 1 1 1 0 2 1 2 0 1 1 0 1 1 2 2 2 1 1 2 0 1 1 0 0 1 1 0]\n",
      "kappa:\t-0.241, accuracy:\t0.667\n",
      "Epoch: [16][7/9]\tTime 0.166922 (0.209)\tData 0.041\tLoss 0.4615\tAccuray 0.8594\n",
      "[1 2 1 0 1 0 0 2 2 2 1 1 2 1 2 1 0 2 2 1 2 1 1 0 1 1 1 1 1 0]\n",
      "[1 0 1 2 1 0 0 0 2 2 1 1 0 1 2 1 2 0 2 1 2 1 1 0 1 1 1 1 1 2]\n",
      "kappa:\t0.060, accuracy:\t0.767\n",
      "\n",
      "current best accuracy is: 0.7666666666666667\n",
      "\n",
      "====> save model:\t/data/beast/df/alzheimer/out_model/alzheimer_recognition_xxx_0/alzheimer_recognition_0016_best.pth\n",
      "Epoch: [17][7/9]\tTime 0.165124 (0.203)\tData 0.033\tLoss 0.4454\tAccuray 0.8984\n",
      "[1 1 1 1 1 1 1 2 2 2 0 2 2 1 1 0 2 1 1 0 2 1 1 1 2 2 2 1 1 1]\n",
      "[1 1 1 2 1 1 1 0 0 2 2 0 0 1 1 0 0 1 1 2 2 1 1 1 2 2 2 0 1 1]\n",
      "kappa:\t-0.090, accuracy:\t0.700\n",
      "Epoch: [18][7/9]\tTime 0.168295 (0.210)\tData 0.038\tLoss 0.4503\tAccuray 0.8438\n",
      "[0 0 2 1 0 1 1 1 0 0 1 1 0 0 1 0 1 0 0 1 1 1 2 1 0 1 1 1 0 0]\n",
      "[2 2 2 1 2 1 1 1 2 0 1 1 2 2 1 0 1 0 0 1 1 1 0 1 0 1 1 1 2 0]\n",
      "kappa:\t-0.041, accuracy:\t0.733\n",
      "Epoch: [19][7/9]\tTime 0.159559 (0.203)\tData 0.040\tLoss 0.4419\tAccuray 0.8906\n",
      "[2 1 2 2 2 1 2 1 2 1 2 2 2 1 2 2 2 2 1 1 2 2 1 1 2 1 2 1 2 1]\n",
      "[0 1 2 0 2 1 1 1 1 1 2 0 0 1 0 0 2 2 1 1 2 1 1 1 2 1 2 1 0 1]\n",
      "kappa:\t0.025, accuracy:\t0.667\n",
      "Epoch: [20][7/9]\tTime 0.167354 (0.203)\tData 0.033\tLoss 0.4290\tAccuray 0.8477\n",
      "[1 2 0 0 1 1 1 1 1 1 1 0 0 1 2 1 2 2 0 1 2 0 0 1 0 1 1 1 1 1]\n",
      "[1 2 0 2 1 1 1 1 1 1 1 0 0 0 2 1 0 2 2 1 2 0 2 1 0 2 1 1 1 1]\n",
      "kappa:\t0.362, accuracy:\t0.800\n",
      "\n",
      "current best accuracy is: 0.8\n",
      "\n",
      "====> save model:\t/data/beast/df/alzheimer/out_model/alzheimer_recognition_xxx_0/alzheimer_recognition_0020_best.pth\n",
      "Epoch: [21][7/9]\tTime 0.169636 (0.205)\tData 0.038\tLoss 0.4120\tAccuray 0.9141\n",
      "[2 2 1 2 2 2 1 1 2 1 1 1 2 1 1 2 2 1 2 1 1 2 1 1 2 1 2 1 1 2]\n",
      "[2 0 1 0 2 2 1 1 2 1 1 1 0 1 0 0 2 1 0 1 1 2 1 1 2 1 2 1 1 0]\n",
      "kappa:\t0.109, accuracy:\t0.767\n",
      "Epoch: [22][7/9]\tTime 0.160103 (0.201)\tData 0.040\tLoss 0.3638\tAccuray 0.9258\n",
      "[1 1 1 0 0 0 1 1 1 0 0 1 1 1 1 1 2 0 2 1 2 1 0 1 2 2 1 0 0 1]\n",
      "[1 1 1 2 2 0 1 1 1 0 2 1 1 1 1 1 2 0 2 1 2 1 0 1 0 2 0 0 2 1]\n",
      "kappa:\t0.282, accuracy:\t0.800\n",
      "Epoch: [23][7/9]\tTime 0.159803 (0.201)\tData 0.039\tLoss 0.3838\tAccuray 0.9531\n",
      "[1 1 2 1 2 1 1 2 1 1 2 2 1 2 2 1 1 0 2 1 0 1 2 2 1 1 2 0 1 1]\n",
      "[1 1 2 1 2 0 1 0 1 1 0 0 1 2 2 1 1 2 2 1 0 1 0 2 1 1 0 2 1 1]\n",
      "kappa:\t-0.019, accuracy:\t0.733\n",
      "Epoch: [24][7/9]\tTime 0.169055 (0.208)\tData 0.036\tLoss 0.3435\tAccuray 0.9570\n",
      "[1 2 1 2 1 1 0 1 0 0 1 1 1 2 1 1 2 0 0 1 2 1 1 0 2 1 1 1 0 1]\n",
      "[1 0 1 2 0 1 0 1 0 0 1 1 1 2 1 1 0 2 2 1 2 2 1 0 2 1 1 1 2 1]\n",
      "kappa:\t0.216, accuracy:\t0.767\n",
      "Epoch: [25][7/9]\tTime 0.159700 (0.198)\tData 0.033\tLoss 0.3071\tAccuray 0.9727\n",
      "[1 2 2 1 1 2 1 2 1 2 2 2 2 0 2 1 1 2 2 2 1 1 2 1 2 1 1 1 1 1]\n",
      "[1 0 0 1 1 0 1 2 1 2 2 2 2 2 0 1 1 0 0 2 1 1 0 1 2 1 1 1 1 1]\n",
      "kappa:\t-0.098, accuracy:\t0.733\n",
      "Epoch: [26][7/9]\tTime 0.159565 (0.200)\tData 0.035\tLoss 0.2926\tAccuray 0.9609\n",
      "[2 2 1 1 0 2 1 2 1 2 1 1 2 1 0 1 1 2 1 1 2 1 2 0 0 1 0 1 1 2]\n",
      "[0 2 1 1 2 0 1 0 1 2 1 1 0 1 2 1 1 2 1 1 2 1 2 0 0 1 2 1 1 0]\n",
      "kappa:\t-0.079, accuracy:\t0.733\n",
      "Epoch: [27][7/9]\tTime 0.161466 (0.207)\tData 0.042\tLoss 0.2953\tAccuray 0.9570\n",
      "[1 0 2 1 2 2 0 0 2 1 1 1 2 0 1 1 1 1 2 0 1 1 1 1 1 1 2 0 0 0]\n",
      "[1 0 2 1 0 2 2 0 2 1 1 1 0 0 1 1 1 1 2 2 1 1 1 1 1 1 2 2 0 0]\n",
      "kappa:\t0.335, accuracy:\t0.833\n",
      "\n",
      "current best accuracy is: 0.8333333333333334\n",
      "\n",
      "====> save model:\t/data/beast/df/alzheimer/out_model/alzheimer_recognition_xxx_0/alzheimer_recognition_0027_best.pth\n",
      "Epoch: [28][7/9]\tTime 0.169328 (0.201)\tData 0.031\tLoss 0.2601\tAccuray 0.9883\n",
      "[2 1 2 2 1 1 2 1 1 1 0 1 1 2 2 2 2 1 2 2 0 1 0 1 1 2 1 1 2 1]\n",
      "[2 1 0 2 1 1 2 1 1 1 0 1 1 0 2 2 0 1 0 0 2 1 0 1 1 2 1 1 2 1]\n",
      "kappa:\t0.184, accuracy:\t0.800\n",
      "Epoch: [29][7/9]\tTime 0.165738 (0.210)\tData 0.041\tLoss 0.2551\tAccuray 0.9570\n",
      "[2 2 0 1 2 2 1 1 1 1 0 2 2 1 1 1 1 1 1 2 2 0 2 1 1 1 2 1 1 1]\n",
      "[0 2 0 1 2 2 1 2 1 1 2 2 2 0 1 1 1 1 1 0 0 0 0 1 1 1 2 1 1 1]\n",
      "kappa:\t0.201, accuracy:\t0.767\n",
      "Epoch: [30][7/9]\tTime 0.165997 (0.203)\tData 0.033\tLoss 0.2327\tAccuray 0.9727\n",
      "[0 0 1 1 1 1 2 0 1 2 2 0 1 0 2 1 0 1 1 1 1 2 1 0 1 1 1 1 2 1]\n",
      "[0 2 1 1 1 1 0 0 2 2 2 0 1 2 2 1 2 1 1 1 1 2 1 0 1 1 0 1 0 1]\n",
      "kappa:\t0.216, accuracy:\t0.767\n",
      "Epoch: [31][7/9]\tTime 0.167608 (0.204)\tData 0.035\tLoss 0.3489\tAccuray 0.9531\n",
      "[1 1 2 1 1 1 1 0 1 2 2 1 2 2 2 2 2 2 1 2 1 1 2 1 1 1 1 0 1 1]\n",
      "[1 1 2 1 1 1 1 0 1 0 2 1 2 0 2 2 0 2 1 2 1 1 0 2 1 0 1 0 1 1]\n",
      "kappa:\t0.343, accuracy:\t0.800\n",
      "Epoch: [32][7/9]\tTime 0.166584 (0.206)\tData 0.036\tLoss 0.2168\tAccuray 0.9805\n",
      "[1 1 1 1 2 1 2 0 2 1 0 1 0 1 1 2 1 0 2 1 0 1 1 0 0 2 1 1 1 1]\n",
      "[1 1 1 1 2 2 2 0 0 1 0 1 0 1 1 2 1 2 0 1 2 0 1 0 2 2 1 1 1 1]\n",
      "kappa:\t0.216, accuracy:\t0.767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [33][7/9]\tTime 0.167897 (0.207)\tData 0.039\tLoss 0.1670\tAccuray 0.9922\n",
      "[1 1 0 2 1 2 2 1 1 0 1 1 2 1 1 1 1 1 2 0 2 1 1 0 0 2 2 2 0 1]\n",
      "[1 1 0 0 1 0 2 1 1 0 1 1 2 1 1 1 1 1 2 0 0 1 1 2 2 2 2 2 0 1]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [34][7/9]\tTime 0.167029 (0.210)\tData 0.042\tLoss 0.1769\tAccuray 0.9805\n",
      "[1 0 2 0 1 0 2 1 1 2 2 1 1 1 1 1 1 1 2 1 2 2 0 1 0 2 0 1 1 0]\n",
      "[1 0 2 2 1 2 2 1 1 0 2 1 1 1 1 1 1 1 0 1 2 0 0 1 2 2 0 1 1 0]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [35][7/9]\tTime 0.167249 (0.206)\tData 0.040\tLoss 0.1404\tAccuray 0.9883\n",
      "[2 2 2 0 1 1 1 1 2 1 0 1 2 1 1 2 2 0 1 1 2 2 2 1 1 1 1 2 0 1]\n",
      "[2 0 0 2 1 1 1 1 2 1 0 1 2 1 1 0 2 0 1 1 0 2 2 1 1 1 1 0 2 1]\n",
      "kappa:\t0.052, accuracy:\t0.767\n",
      "Epoch: [36][7/9]\tTime 0.164521 (0.208)\tData 0.036\tLoss 0.1470\tAccuray 0.9805\n",
      "[2 1 1 1 1 0 1 2 1 0 1 0 1 0 0 2 2 1 1 2 1 2 1 1 1 2 0 2 1 0]\n",
      "[0 1 1 1 1 0 1 2 1 2 1 0 1 0 2 0 2 1 1 0 1 2 1 1 1 2 2 2 1 0]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [37][7/9]\tTime 0.164501 (0.208)\tData 0.041\tLoss 0.1613\tAccuray 0.9688\n",
      "[0 2 2 2 1 1 1 1 1 1 2 2 1 1 0 2 1 2 2 1 1 1 1 1 1 1 2 2 1 2]\n",
      "[2 0 2 0 1 1 1 1 1 1 2 0 1 1 0 0 2 2 2 1 1 0 1 1 1 1 0 2 1 2]\n",
      "kappa:\t0.051, accuracy:\t0.733\n",
      "Epoch: [38][7/9]\tTime 0.167026 (0.209)\tData 0.041\tLoss 0.1869\tAccuray 0.9688\n",
      "[0 1 1 0 1 1 2 2 1 2 2 1 1 1 2 0 2 0 2 1 1 1 1 1 0 0 0 0 1 1]\n",
      "[0 1 1 2 1 1 2 0 1 2 0 1 1 1 2 2 2 0 2 1 1 1 1 1 0 0 0 2 1 1]\n",
      "kappa:\t0.335, accuracy:\t0.833\n",
      "Epoch: [39][7/9]\tTime 0.166196 (0.204)\tData 0.034\tLoss 0.1129\tAccuray 0.9805\n",
      "[2 1 0 0 1 1 0 2 2 1 1 0 2 0 1 1 0 1 2 1 1 1 2 1 1 1 1 1 2 2]\n",
      "[0 1 0 2 1 1 0 2 0 1 1 0 2 2 1 0 2 1 2 1 1 1 2 1 1 1 1 1 0 2]\n",
      "kappa:\t0.134, accuracy:\t0.767\n",
      "Epoch: [40][7/9]\tTime 0.169786 (0.212)\tData 0.042\tLoss 0.1038\tAccuray 0.9766\n",
      "[1 0 1 1 2 2 1 1 0 1 1 2 2 1 1 1 1 2 1 0 2 0 0 0 1 1 0 0 2 1]\n",
      "[1 2 1 1 0 2 1 1 0 1 1 0 2 1 1 1 1 2 1 2 2 0 2 0 1 1 0 0 2 1]\n",
      "kappa:\t0.335, accuracy:\t0.833\n",
      "Epoch: [41][7/9]\tTime 0.168118 (0.211)\tData 0.040\tLoss 0.1224\tAccuray 0.9766\n",
      "[2 2 1 0 2 1 2 1 2 1 1 1 0 2 1 1 1 1 1 1 0 0 0 1 1 1 0 0 2 2]\n",
      "[2 2 1 0 0 1 2 1 2 1 1 1 2 2 1 1 1 1 1 1 2 0 0 1 1 1 0 0 2 0]\n",
      "kappa:\t0.465, accuracy:\t0.867\n",
      "\n",
      "current best accuracy is: 0.8666666666666667\n",
      "\n",
      "====> save model:\t/data/beast/df/alzheimer/out_model/alzheimer_recognition_xxx_0/alzheimer_recognition_0041_best.pth\n",
      "Epoch: [42][7/9]\tTime 0.170213 (0.209)\tData 0.042\tLoss 0.1105\tAccuray 0.9766\n",
      "[2 1 1 0 0 2 1 1 1 1 1 2 0 2 1 1 1 1 2 0 1 0 1 2 0 2 1 2 1 2]\n",
      "[2 1 1 0 2 2 1 1 1 1 1 0 0 2 1 1 1 1 2 0 1 0 1 0 2 2 1 2 1 0]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [43][7/9]\tTime 0.167893 (0.210)\tData 0.039\tLoss 0.1223\tAccuray 0.9805\n",
      "[2 1 1 2 0 0 1 1 1 1 2 2 1 2 0 1 0 2 0 2 1 0 1 2 2 1 0 1 0 0]\n",
      "[2 1 1 0 1 0 1 1 1 1 2 0 1 2 2 1 1 2 2 0 1 1 1 2 2 1 0 1 0 0]\n",
      "kappa:\t0.303, accuracy:\t0.733\n",
      "Epoch: [44][7/9]\tTime 0.168833 (0.205)\tData 0.034\tLoss 0.1251\tAccuray 0.9727\n",
      "[1 2 0 0 2 1 1 1 2 1 1 2 0 1 1 0 1 1 2 1 2 2 1 1 1 0 1 0 0 2]\n",
      "[1 0 0 0 2 1 1 1 2 1 1 2 2 1 1 0 1 1 2 1 0 2 1 1 1 2 1 0 2 0]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [45][7/9]\tTime 0.170321 (0.207)\tData 0.034\tLoss 0.0744\tAccuray 0.9844\n",
      "[1 0 1 2 2 1 0 2 1 1 0 1 1 0 2 1 1 2 0 0 2 1 1 0 1 1 1 2 1 2]\n",
      "[1 2 1 2 0 1 2 2 1 1 0 1 1 0 0 1 1 0 0 2 2 1 1 0 1 1 1 2 1 2]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [46][7/9]\tTime 0.167980 (0.211)\tData 0.040\tLoss 0.0903\tAccuray 0.9766\n",
      "[2 2 0 1 0 0 0 0 1 1 1 2 2 0 1 2 1 1 2 2 1 1 0 1 1 1 1 1 2 1]\n",
      "[2 2 2 1 0 2 0 0 1 1 1 0 0 0 1 0 1 1 2 2 1 1 2 1 1 1 1 1 2 1]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [47][7/9]\tTime 0.168522 (0.213)\tData 0.043\tLoss 0.0803\tAccuray 0.9883\n",
      "[1 1 0 2 1 1 2 2 1 0 2 1 2 0 2 2 0 0 1 1 1 1 1 1 2 1 1 1 0 2]\n",
      "[1 1 0 2 1 1 0 2 1 0 2 1 0 0 0 2 0 2 1 1 1 1 1 1 2 1 1 1 2 2]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [48][7/9]\tTime 0.165390 (0.212)\tData 0.043\tLoss 0.1171\tAccuray 0.9727\n",
      "[2 1 1 2 1 1 1 0 0 2 0 1 0 0 2 2 1 0 1 1 2 2 1 2 1 1 1 1 1 0]\n",
      "[0 1 1 2 1 1 1 0 0 0 0 1 2 2 2 2 1 0 1 1 2 2 1 0 1 1 1 1 1 2]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [49][7/9]\tTime 0.167613 (0.212)\tData 0.040\tLoss 0.1027\tAccuray 0.9805\n",
      "[1 1 1 2 1 1 2 0 1 1 2 2 0 2 2 2 0 1 1 1 0 0 1 1 1 2 1 2 1 0]\n",
      "[1 1 1 2 1 1 0 2 1 1 0 2 0 2 0 2 2 1 1 1 0 0 1 1 1 2 1 2 1 0]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [50][7/9]\tTime 0.167755 (0.209)\tData 0.043\tLoss 0.0656\tAccuray 0.9844\n",
      "[0 1 1 1 2 2 0 1 2 2 1 2 1 1 1 1 1 1 2 2 1 0 0 2 1 1 0 2 1 1]\n",
      "[0 1 1 0 2 0 2 1 2 0 1 2 1 1 1 1 1 1 2 2 1 0 2 0 1 1 0 2 1 1]\n",
      "kappa:\t0.269, accuracy:\t0.800\n",
      "Epoch: [51][7/9]\tTime 0.170182 (0.212)\tData 0.041\tLoss 0.0724\tAccuray 0.9844\n",
      "[1 1 1 1 1 0 0 1 2 0 0 1 2 2 1 2 1 2 2 2 1 1 1 1 0 1 0 2 1 0]\n",
      "[1 1 1 1 1 0 0 1 0 2 0 1 2 2 1 2 1 2 0 2 1 1 1 1 0 1 0 2 1 2]\n",
      "kappa:\t0.465, accuracy:\t0.867\n",
      "Epoch: [52][7/9]\tTime 0.165451 (0.209)\tData 0.038\tLoss 0.0712\tAccuray 0.9844\n",
      "[0 0 0 1 2 1 1 1 1 2 1 2 0 1 1 2 0 1 1 1 2 2 1 0 2 1 1 2 2 1]\n",
      "[0 2 0 1 0 1 1 1 1 2 1 0 0 1 1 2 2 1 1 1 0 2 1 0 2 1 1 2 2 1]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [53][7/9]\tTime 0.168120 (0.204)\tData 0.033\tLoss 0.0833\tAccuray 0.9805\n",
      "[1 1 1 0 0 1 2 2 1 1 2 1 0 0 1 0 0 1 2 1 0 2 1 0 0 2 1 1 1 1]\n",
      "[1 1 1 2 2 1 0 2 1 1 2 1 2 0 1 2 0 1 2 1 0 0 1 0 0 2 1 1 1 1]\n",
      "kappa:\t0.205, accuracy:\t0.800\n",
      "Epoch: [54][7/9]\tTime 0.164884 (0.209)\tData 0.042\tLoss 0.1575\tAccuray 0.9766\n",
      "[0 2 2 2 1 1 1 1 1 1 0 2 0 2 1 1 1 2 2 2 1 1 0 1 0 1 0 1 1 2]\n",
      "[0 2 2 2 1 1 1 1 1 1 0 2 0 0 1 1 1 2 0 2 1 1 0 1 2 1 2 1 1 0]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [55][7/9]\tTime 0.165509 (0.209)\tData 0.041\tLoss 0.1452\tAccuray 0.9531\n",
      "[0 1 1 1 2 2 1 0 2 1 2 1 2 1 1 1 1 2 1 1 2 0 0 1 1 1 0 2 1 1]\n",
      "[0 1 1 1 0 2 1 0 0 1 2 1 2 1 1 1 2 2 1 1 2 2 0 1 1 1 2 0 1 0]\n",
      "kappa:\t0.209, accuracy:\t0.767\n",
      "Epoch: [56][7/9]\tTime 0.168182 (0.210)\tData 0.040\tLoss 0.1149\tAccuray 0.9570\n",
      "[1 1 2 1 1 0 2 1 1 0 2 0 0 1 0 1 1 0 1 0 2 2 1 1 1 2 1 2 1 2]\n",
      "[1 1 2 1 1 0 2 1 1 2 2 0 0 1 0 1 1 2 1 2 2 0 1 1 1 0 1 2 1 0]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [57][7/9]\tTime 0.170056 (0.211)\tData 0.041\tLoss 0.0871\tAccuray 0.9805\n",
      "[2 0 1 1 2 1 1 1 0 1 2 1 2 1 0 1 1 2 0 0 1 0 1 1 2 2 0 1 0 1]\n",
      "[2 2 1 1 0 1 1 1 0 1 0 1 2 1 2 1 1 2 0 0 1 2 1 1 2 2 0 1 0 1]\n",
      "kappa:\t0.335, accuracy:\t0.833\n",
      "Epoch: [58][7/9]\tTime 0.166323 (0.210)\tData 0.042\tLoss 0.0774\tAccuray 0.9805\n",
      "[1 1 0 2 2 1 1 1 1 1 1 0 2 1 2 0 1 1 0 1 1 2 0 0 2 1 2 2 0 1]\n",
      "[1 1 0 0 2 1 1 1 1 1 1 0 0 1 2 0 1 1 2 1 1 2 2 2 0 1 2 2 0 1]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [59][7/9]\tTime 0.163519 (0.203)\tData 0.036\tLoss 0.0813\tAccuray 0.9805\n",
      "[2 0 1 2 1 0 0 1 2 0 1 1 1 2 1 0 1 1 1 1 1 2 2 1 0 1 0 2 1 1]\n",
      "[0 0 1 2 1 2 0 1 2 2 1 1 1 2 1 0 1 0 1 1 1 0 2 1 0 1 2 2 1 1]\n",
      "kappa:\t0.276, accuracy:\t0.800\n",
      "Epoch: [60][7/9]\tTime 0.169264 (0.205)\tData 0.032\tLoss 0.0563\tAccuray 0.9883\n",
      "[1 2 1 0 0 0 2 1 0 1 1 1 2 2 2 2 1 1 1 0 1 1 2 1 0 1 0 1 2 1]\n",
      "[1 2 1 0 2 0 2 1 2 1 1 1 0 0 2 2 1 1 1 2 1 1 0 1 0 1 0 1 2 1]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [61][7/9]\tTime 0.164966 (0.202)\tData 0.032\tLoss 0.0736\tAccuray 0.9766\n",
      "[1 2 0 1 1 1 2 2 2 2 1 1 1 1 2 2 1 2 1 0 1 1 0 0 1 0 1 1 2 2]\n",
      "[1 2 0 1 1 1 2 2 0 2 1 1 1 1 0 2 1 2 1 0 1 1 0 0 1 2 1 1 0 2]\n",
      "kappa:\t0.461, accuracy:\t0.867\n",
      "Epoch: [62][7/9]\tTime 0.166300 (0.211)\tData 0.043\tLoss 0.0750\tAccuray 0.9766\n",
      "[2 1 1 1 2 2 1 0 2 0 1 1 1 1 0 1 1 0 2 1 1 1 2 0 0 1 2 2 1 2]\n",
      "[2 1 1 1 2 0 1 2 2 0 1 1 1 1 0 1 1 0 0 1 1 1 0 2 0 1 2 2 1 2]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [63][7/9]\tTime 0.169076 (0.205)\tData 0.031\tLoss 0.0899\tAccuray 0.9766\n",
      "[0 1 2 1 1 1 2 1 1 1 0 0 1 0 2 0 1 0 1 0 1 1 1 2 1 2 0 1 2 2]\n",
      "[0 1 2 1 1 1 0 1 1 1 0 2 1 2 2 0 1 0 1 2 1 1 1 0 1 2 0 1 2 2]\n",
      "kappa:\t0.335, accuracy:\t0.833\n",
      "Epoch: [64][7/9]\tTime 0.168718 (0.207)\tData 0.037\tLoss 0.0565\tAccuray 0.9922\n",
      "[1 2 1 1 1 0 1 0 2 1 0 1 2 1 1 2 1 1 0 2 0 1 0 0 2 2 1 1 2 2]\n",
      "[1 0 1 1 1 0 1 1 0 1 0 1 2 1 1 2 1 1 0 0 2 1 0 2 2 2 1 1 2 2]\n",
      "kappa:\t0.320, accuracy:\t0.800\n",
      "Epoch: [65][7/9]\tTime 0.167619 (0.203)\tData 0.034\tLoss 0.1104\tAccuray 0.9727\n",
      "[1 0 1 2 1 0 1 1 1 1 0 1 0 0 0 2 2 2 2 0 0 1 1 2 1 1 1 2 1 1]\n",
      "[1 0 1 0 1 2 1 1 1 1 0 1 2 2 0 2 2 2 2 0 0 1 1 0 1 1 1 2 1 1]\n",
      "kappa:\t0.335, accuracy:\t0.833\n",
      "Epoch: [66][7/9]\tTime 0.163089 (0.202)\tData 0.033\tLoss 0.0496\tAccuray 0.9883\n",
      "[1 0 1 1 2 1 2 1 2 1 1 1 2 0 1 2 1 1 2 2 2 0 1 0 1 0 1 2 1 0]\n",
      "[1 0 1 1 2 1 2 1 0 1 1 1 2 0 1 2 1 1 0 2 2 2 1 0 1 2 1 0 1 0]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [67][7/9]\tTime 0.167733 (0.206)\tData 0.036\tLoss 0.0589\tAccuray 0.9883\n",
      "[2 1 1 2 1 1 1 0 2 1 1 1 2 1 1 0 0 2 2 1 2 1 0 1 0 0 2 2 1 1]\n",
      "[0 1 1 0 1 1 1 2 0 1 1 1 2 1 1 0 0 2 2 1 2 1 0 1 2 0 2 2 1 1]\n",
      "kappa:\t0.329, accuracy:\t0.833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [68][7/9]\tTime 0.166584 (0.209)\tData 0.040\tLoss 0.0494\tAccuray 0.9922\n",
      "[0 0 2 1 2 1 1 2 0 1 1 1 2 2 1 1 1 1 1 2 2 2 0 1 1 0 2 1 0 1]\n",
      "[2 2 0 1 2 1 1 2 0 1 1 1 2 2 1 1 1 1 1 2 0 2 0 1 1 0 0 1 0 1]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [69][7/9]\tTime 0.167309 (0.204)\tData 0.035\tLoss 0.0453\tAccuray 0.9883\n",
      "[1 2 1 2 2 0 1 0 0 1 0 2 1 1 1 2 1 1 1 1 2 1 1 1 2 1 0 0 2 0]\n",
      "[1 2 1 2 2 2 1 0 2 1 2 0 1 1 1 0 1 1 1 1 2 1 1 1 0 1 0 0 2 0]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [70][7/9]\tTime 0.166312 (0.213)\tData 0.042\tLoss 0.0410\tAccuray 0.9883\n",
      "[2 0 1 2 0 1 0 2 1 1 1 1 0 1 2 2 1 2 1 1 2 2 1 1 2 1 1 1 0 0]\n",
      "[2 0 1 2 0 1 2 2 1 1 1 1 0 1 0 0 1 2 1 1 2 2 1 1 0 1 1 1 2 0]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [71][7/9]\tTime 0.167446 (0.211)\tData 0.043\tLoss 0.0710\tAccuray 0.9805\n",
      "[1 0 2 1 2 1 2 2 2 0 1 2 0 1 2 0 1 1 0 0 1 1 1 0 1 1 1 1 1 2]\n",
      "[1 0 2 1 2 1 0 0 2 0 1 2 0 1 0 2 1 1 2 0 1 1 1 2 1 1 1 1 1 2]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [72][7/9]\tTime 0.164090 (0.204)\tData 0.035\tLoss 0.0396\tAccuray 0.9883\n",
      "[2 1 1 2 1 1 1 2 1 1 0 1 2 1 1 0 1 1 2 2 1 1 2 0 0 0 0 1 0 2]\n",
      "[0 1 1 0 1 1 1 2 1 1 2 1 0 1 1 0 1 1 2 2 1 1 2 0 2 2 0 1 0 2]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [73][7/9]\tTime 0.164927 (0.211)\tData 0.042\tLoss 0.0688\tAccuray 0.9766\n",
      "[2 2 2 2 0 1 1 0 0 1 1 2 2 1 1 1 0 1 1 0 1 2 1 2 1 1 2 1 0 1]\n",
      "[0 2 0 2 2 1 1 0 0 1 1 0 2 1 1 1 0 1 1 0 1 2 1 2 1 1 2 1 2 1]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [74][7/9]\tTime 0.163572 (0.211)\tData 0.042\tLoss 0.0651\tAccuray 0.9766\n",
      "[2 2 0 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1 0 0 1 1 2 0 2 1 2 2 1 0]\n",
      "[2 2 0 0 1 1 1 1 1 0 1 1 2 2 1 1 1 1 2 2 1 1 0 0 2 1 2 0 1 0]\n",
      "kappa:\t0.205, accuracy:\t0.800\n",
      "Epoch: [75][7/9]\tTime 0.165364 (0.205)\tData 0.039\tLoss 0.0577\tAccuray 0.9805\n",
      "[1 0 0 1 1 2 1 2 2 1 0 1 1 0 1 1 0 1 2 2 1 2 0 2 1 1 1 2 1 0]\n",
      "[1 0 0 1 1 2 1 0 2 1 0 1 1 0 1 1 2 1 2 2 1 2 0 0 1 1 1 2 1 2]\n",
      "kappa:\t0.465, accuracy:\t0.867\n",
      "Epoch: [76][7/9]\tTime 0.169276 (0.209)\tData 0.036\tLoss 0.0452\tAccuray 0.9883\n",
      "[1 2 1 2 1 1 2 2 1 1 1 0 0 0 1 1 2 1 1 2 2 1 1 0 2 0 2 0 1 1]\n",
      "[1 2 1 0 1 1 2 2 1 1 1 0 0 0 1 1 2 1 1 0 2 1 1 2 0 2 2 0 1 1]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [77][7/9]\tTime 0.167338 (0.206)\tData 0.036\tLoss 0.0389\tAccuray 0.9883\n",
      "[2 1 1 1 1 1 2 2 0 0 2 1 1 0 0 1 2 1 2 1 0 1 1 1 2 1 2 1 2 0]\n",
      "[2 1 1 1 1 1 0 2 2 0 0 1 1 2 2 1 0 1 2 1 0 1 1 1 2 1 0 1 2 0]\n",
      "kappa:\t0.060, accuracy:\t0.767\n",
      "Epoch: [78][7/9]\tTime 0.166288 (0.209)\tData 0.041\tLoss 0.0384\tAccuray 0.9922\n",
      "[0 2 1 1 1 1 2 1 0 1 2 1 2 0 1 1 0 1 1 1 0 2 2 2 1 1 0 1 0 2]\n",
      "[0 2 1 1 1 1 2 1 2 1 2 1 2 2 1 1 0 1 1 1 0 2 0 2 1 1 0 1 0 0]\n",
      "kappa:\t0.465, accuracy:\t0.867\n",
      "Epoch: [79][7/9]\tTime 0.166372 (0.208)\tData 0.041\tLoss 0.0583\tAccuray 0.9844\n",
      "[1 2 0 0 2 1 1 1 1 1 1 2 1 2 0 0 1 0 2 1 1 1 1 2 0 0 2 1 2 1]\n",
      "[1 0 0 0 2 1 1 1 1 1 1 2 1 2 2 0 1 0 0 1 1 1 1 2 2 2 2 1 0 1]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [80][7/9]\tTime 0.163150 (0.211)\tData 0.043\tLoss 0.0334\tAccuray 0.9922\n",
      "[1 2 2 1 1 2 2 1 0 1 1 1 0 1 2 2 1 0 0 1 2 1 1 1 1 2 2 0 0 1]\n",
      "[1 2 2 1 1 2 0 1 2 1 1 1 0 1 0 0 1 0 0 1 2 1 1 1 1 2 2 0 2 1]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [81][7/9]\tTime 0.163968 (0.206)\tData 0.038\tLoss 0.0586\tAccuray 0.9805\n",
      "[0 1 2 1 2 0 1 2 2 0 1 1 1 0 1 2 2 0 1 2 1 1 2 1 1 1 0 1 0 1]\n",
      "[2 1 0 1 2 0 1 2 0 0 1 1 1 2 1 2 0 2 1 2 1 1 2 1 1 1 0 1 0 1]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [82][7/9]\tTime 0.167693 (0.211)\tData 0.044\tLoss 0.0762\tAccuray 0.9766\n",
      "[1 1 1 1 1 2 0 2 1 0 1 1 2 2 2 2 1 1 2 2 1 0 1 1 1 1 0 0 0 0]\n",
      "[1 1 1 1 1 0 2 0 1 2 1 1 0 2 2 2 1 1 2 2 1 2 1 1 1 1 0 0 0 0]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [83][7/9]\tTime 0.170080 (0.207)\tData 0.035\tLoss 0.0557\tAccuray 0.9883\n",
      "[1 2 1 1 2 2 1 0 0 1 0 1 1 1 1 2 0 2 1 0 1 1 2 1 0 1 2 1 0 2]\n",
      "[1 2 1 1 2 2 1 0 2 1 0 1 1 1 1 0 0 0 1 0 1 1 2 1 0 1 2 1 2 2]\n",
      "kappa:\t0.465, accuracy:\t0.867\n",
      "Epoch: [84][7/9]\tTime 0.165191 (0.206)\tData 0.034\tLoss 0.0296\tAccuray 0.9961\n",
      "[0 2 2 1 2 0 0 1 1 1 1 2 2 0 1 1 1 2 1 2 1 1 1 0 1 1 0 2 1 2]\n",
      "[2 2 2 1 2 0 0 1 1 1 1 2 0 2 1 1 1 0 1 2 1 1 1 2 1 1 0 0 1 0]\n",
      "kappa:\t0.060, accuracy:\t0.767\n",
      "Epoch: [85][7/9]\tTime 0.170697 (0.209)\tData 0.036\tLoss 0.0382\tAccuray 0.9922\n",
      "[2 2 2 0 1 2 1 0 1 0 1 1 2 2 2 0 1 0 1 1 1 1 1 0 1 0 1 1 1 2]\n",
      "[2 0 2 0 1 2 1 2 1 0 1 1 0 2 2 0 1 0 1 1 1 1 1 0 1 2 1 1 1 2]\n",
      "kappa:\t0.465, accuracy:\t0.867\n",
      "Epoch: [86][7/9]\tTime 0.164413 (0.213)\tData 0.042\tLoss 0.0363\tAccuray 0.9922\n",
      "[1 1 0 1 2 1 1 2 1 1 1 2 0 2 0 2 2 1 0 1 1 0 0 1 1 1 1 2 2 0]\n",
      "[1 1 0 1 0 1 1 0 1 1 1 2 0 2 0 2 2 1 2 1 1 0 2 1 1 1 1 0 2 2]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [87][7/9]\tTime 0.165738 (0.209)\tData 0.041\tLoss 0.0319\tAccuray 0.9922\n",
      "[1 0 0 1 1 1 2 2 1 2 0 0 1 2 1 1 1 2 2 1 0 1 1 1 2 2 1 2 0 1]\n",
      "[1 0 0 1 1 1 2 0 1 0 2 0 1 2 1 1 1 0 2 1 2 1 1 1 2 2 1 2 0 1]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [88][7/9]\tTime 0.162599 (0.207)\tData 0.043\tLoss 0.0378\tAccuray 0.9922\n",
      "[2 2 2 2 1 0 1 1 1 1 1 1 2 1 1 2 1 0 1 2 1 0 2 1 1 0 1 0 2 0]\n",
      "[2 2 2 2 1 0 1 1 1 1 1 1 0 1 1 2 1 0 1 0 1 0 0 1 1 2 1 2 2 0]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [89][7/9]\tTime 0.164946 (0.210)\tData 0.040\tLoss 0.0436\tAccuray 0.9883\n",
      "[2 2 2 1 1 2 1 1 1 1 1 0 1 2 0 0 1 1 2 1 1 2 1 1 2 0 0 2 1 0]\n",
      "[0 0 2 1 1 2 1 1 1 1 1 2 1 0 0 2 1 1 2 1 1 2 1 1 0 0 2 2 1 0]\n",
      "kappa:\t0.060, accuracy:\t0.767\n",
      "Epoch: [90][7/9]\tTime 0.170187 (0.206)\tData 0.033\tLoss 0.0654\tAccuray 0.9766\n",
      "[2 1 2 0 1 2 0 2 1 2 0 2 2 1 1 1 1 1 1 0 2 0 1 1 1 1 1 0 0 1]\n",
      "[2 1 2 0 1 0 2 2 1 2 0 0 2 1 1 1 1 1 1 0 2 0 1 1 1 1 1 2 0 1]\n",
      "kappa:\t0.465, accuracy:\t0.867\n",
      "Epoch: [91][7/9]\tTime 0.169296 (0.216)\tData 0.046\tLoss 0.0448\tAccuray 0.9922\n",
      "[0 1 1 1 1 0 1 1 0 1 1 2 1 0 2 1 2 1 2 0 1 2 2 2 1 2 1 0 0 1]\n",
      "[2 1 1 1 1 0 1 1 0 1 1 0 1 0 2 1 2 1 2 0 1 2 2 0 1 0 1 2 2 1]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [92][7/9]\tTime 0.168659 (0.213)\tData 0.044\tLoss 0.0378\tAccuray 0.9922\n",
      "[1 2 0 1 2 1 1 2 1 1 2 1 1 0 0 0 0 2 2 1 2 2 1 2 1 0 1 1 1 1]\n",
      "[1 0 2 1 2 1 1 2 1 1 2 1 1 0 0 0 0 0 2 1 0 2 1 2 1 2 1 1 1 1]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [93][7/9]\tTime 0.165408 (0.210)\tData 0.044\tLoss 0.0620\tAccuray 0.9688\n",
      "[1 2 1 1 2 0 1 2 1 1 0 2 2 1 2 1 2 1 0 0 0 1 1 2 0 1 1 1 1 0]\n",
      "[1 0 1 1 2 0 1 2 1 1 0 0 0 1 2 1 2 1 2 2 2 1 1 2 0 1 1 1 1 0]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [94][7/9]\tTime 0.168800 (0.212)\tData 0.040\tLoss 0.0395\tAccuray 0.9883\n",
      "[1 1 1 2 1 0 1 2 1 1 2 0 1 1 2 1 1 2 1 1 0 1 1 0 1 2 0 0 2 2]\n",
      "[1 1 1 0 1 2 1 2 1 1 2 0 1 1 0 1 1 2 1 1 0 1 0 2 1 0 2 0 2 2]\n",
      "kappa:\t0.134, accuracy:\t0.767\n",
      "Epoch: [95][7/9]\tTime 0.166984 (0.212)\tData 0.040\tLoss 0.0554\tAccuray 0.9727\n",
      "[2 2 0 2 2 0 1 1 1 1 0 0 2 1 1 2 1 1 1 1 2 2 1 1 2 0 0 1 1 1]\n",
      "[2 0 2 0 2 0 1 1 1 1 0 2 2 1 1 2 1 1 1 1 0 2 1 1 2 0 0 1 1 1]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [96][7/9]\tTime 0.169581 (0.215)\tData 0.045\tLoss 0.0312\tAccuray 0.9922\n",
      "[1 1 2 1 1 2 1 1 0 1 2 1 1 2 2 1 0 1 2 0 0 1 0 2 1 2 1 0 1 2]\n",
      "[1 1 0 1 1 0 1 1 0 1 2 1 1 2 2 1 0 1 2 0 0 1 2 0 1 2 1 2 1 2]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [97][7/9]\tTime 0.167830 (0.205)\tData 0.035\tLoss 0.0340\tAccuray 0.9883\n",
      "[1 2 1 1 0 0 0 2 1 2 0 0 2 1 1 1 2 2 0 1 2 1 2 0 1 2 2 1 1 2]\n",
      "[1 1 1 1 0 0 2 0 1 0 0 0 2 1 1 1 2 2 2 1 2 1 2 2 1 1 1 1 1 0]\n",
      "kappa:\t0.175, accuracy:\t0.700\n",
      "Epoch: [98][7/9]\tTime 0.166451 (0.203)\tData 0.034\tLoss 0.0953\tAccuray 0.9688\n",
      "[1 0 0 1 1 1 1 0 1 2 1 2 1 1 1 2 2 2 2 2 1 1 2 2 0 2 1 1 1 0]\n",
      "[1 0 2 1 1 1 1 2 1 0 1 2 1 1 1 2 0 0 0 2 1 1 2 2 0 2 1 1 1 0]\n",
      "kappa:\t0.191, accuracy:\t0.800\n",
      "Epoch: [99][7/9]\tTime 0.165944 (0.208)\tData 0.041\tLoss 0.0662\tAccuray 0.9844\n",
      "[0 2 0 1 1 1 1 1 2 2 2 0 1 0 2 2 1 2 1 1 1 2 1 2 0 1 1 1 0 1]\n",
      "[2 2 0 1 1 1 1 1 0 0 0 0 1 2 2 2 1 2 1 1 1 2 1 2 0 1 1 1 0 1]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [100][7/9]\tTime 0.168781 (0.204)\tData 0.032\tLoss 0.0391\tAccuray 0.9961\n",
      "[0 1 1 2 0 1 1 0 1 2 1 2 1 1 0 0 2 2 0 2 1 2 1 2 1 1 2 1 1 1]\n",
      "[2 1 1 2 0 1 1 0 1 2 1 2 1 1 2 0 2 0 0 0 1 2 1 2 1 1 0 1 1 1]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [101][7/9]\tTime 0.166800 (0.204)\tData 0.035\tLoss 0.0368\tAccuray 0.9883\n",
      "[1 0 1 1 0 1 1 1 2 0 2 2 1 2 0 1 2 1 1 1 2 0 1 2 0 2 1 2 1 1]\n",
      "[1 0 1 1 0 1 1 1 0 0 2 0 1 2 0 1 0 1 1 1 2 2 1 2 2 2 1 2 1 1]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [102][7/9]\tTime 0.165128 (0.208)\tData 0.041\tLoss 0.0239\tAccuray 0.9922\n",
      "[0 1 2 2 1 1 2 1 0 0 1 2 2 1 1 2 1 1 1 0 0 1 0 2 1 1 2 1 2 1]\n",
      "[0 1 2 0 1 1 0 1 2 0 1 2 2 1 1 2 1 1 1 0 2 1 0 2 1 1 2 1 0 1]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [103][7/9]\tTime 0.167758 (0.211)\tData 0.042\tLoss 0.0165\tAccuray 1.0000\n",
      "[2 1 0 1 1 1 2 2 0 1 1 1 2 0 1 1 2 1 0 1 1 1 0 1 2 0 0 1 2 2]\n",
      "[2 1 0 1 1 1 2 2 0 1 1 1 2 2 1 1 2 1 0 1 1 1 0 1 0 2 0 1 2 0]\n",
      "kappa:\t0.465, accuracy:\t0.867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [104][7/9]\tTime 0.168614 (0.212)\tData 0.042\tLoss 0.0223\tAccuray 0.9883\n",
      "[1 1 2 0 1 1 1 0 1 1 2 0 0 2 2 0 2 1 2 2 0 2 2 1 1 1 1 1 1 1]\n",
      "[1 1 0 0 1 1 1 0 1 1 2 0 2 2 0 2 2 1 0 2 0 2 2 1 1 1 1 1 1 1]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [105][7/9]\tTime 0.166080 (0.210)\tData 0.041\tLoss 0.0376\tAccuray 0.9883\n",
      "[1 0 2 2 2 1 1 0 1 1 2 2 1 1 2 0 0 1 1 1 1 2 1 2 1 0 1 0 2 1]\n",
      "[1 2 2 2 2 1 1 0 1 1 2 0 1 1 2 0 0 1 1 1 1 0 1 0 1 2 1 0 2 1]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [106][7/9]\tTime 0.165157 (0.203)\tData 0.034\tLoss 0.0365\tAccuray 0.9922\n",
      "[1 1 0 1 2 2 0 1 1 1 1 0 1 0 2 2 2 1 1 0 2 1 1 0 0 1 2 1 1 2]\n",
      "[1 1 0 1 2 2 0 1 1 1 1 0 1 2 2 0 2 1 1 2 2 1 1 0 0 1 0 1 1 2]\n",
      "kappa:\t0.465, accuracy:\t0.867\n",
      "Epoch: [107][7/9]\tTime 0.163455 (0.204)\tData 0.036\tLoss 0.0313\tAccuray 0.9922\n",
      "[0 1 1 2 1 1 2 2 0 0 2 1 2 1 1 2 0 1 2 1 0 2 1 1 0 1 1 1 1 0]\n",
      "[0 1 1 2 1 1 0 2 2 2 2 1 0 1 1 2 0 1 2 1 2 0 1 1 0 1 1 1 1 0]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [108][7/9]\tTime 0.167812 (0.208)\tData 0.041\tLoss 0.0430\tAccuray 0.9883\n",
      "[1 1 1 1 0 1 1 2 2 1 1 0 2 1 2 0 2 1 1 2 1 2 1 0 2 1 2 0 2 1]\n",
      "[1 1 1 1 2 1 1 0 0 1 1 0 2 1 0 0 2 1 1 2 1 2 1 0 2 1 2 0 2 1]\n",
      "kappa:\t0.461, accuracy:\t0.867\n",
      "Epoch: [109][7/9]\tTime 0.166898 (0.209)\tData 0.041\tLoss 0.0258\tAccuray 0.9922\n",
      "[1 2 1 2 1 1 1 2 1 1 2 1 1 1 1 1 0 2 0 2 0 1 1 2 2 0 2 2 0 1]\n",
      "[1 2 1 2 1 1 1 0 1 1 2 1 1 1 1 1 2 0 0 2 0 1 1 2 2 0 2 0 0 1]\n",
      "kappa:\t0.461, accuracy:\t0.867\n",
      "Epoch: [110][7/9]\tTime 0.164889 (0.203)\tData 0.033\tLoss 0.0207\tAccuray 0.9883\n",
      "[2 2 0 1 2 2 1 1 2 1 2 0 1 1 1 1 0 1 1 0 1 0 1 1 0 2 2 1 0 1]\n",
      "[2 0 0 1 2 2 1 1 2 1 2 2 1 1 1 1 2 1 1 0 1 0 1 1 0 0 2 1 0 1]\n",
      "kappa:\t0.465, accuracy:\t0.867\n",
      "Epoch: [111][7/9]\tTime 0.167121 (0.200)\tData 0.033\tLoss 0.0204\tAccuray 0.9961\n",
      "[0 2 1 1 2 1 2 1 0 1 2 1 1 0 1 1 2 1 0 2 1 2 0 0 1 1 1 1 2 0]\n",
      "[0 2 1 1 2 1 0 1 0 1 2 1 1 2 1 1 2 1 2 0 1 2 0 2 1 1 1 1 0 0]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [112][7/9]\tTime 0.168066 (0.217)\tData 0.045\tLoss 0.0400\tAccuray 0.9844\n",
      "[1 2 0 0 0 0 2 2 1 1 1 0 0 1 1 1 0 1 1 2 1 2 2 2 1 1 1 1 1 2]\n",
      "[1 0 0 2 2 2 0 2 1 1 1 0 0 1 1 1 0 1 1 2 1 2 2 2 1 1 1 1 1 0]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [113][7/9]\tTime 0.164247 (0.201)\tData 0.033\tLoss 0.0624\tAccuray 0.9766\n",
      "[0 2 2 0 1 2 0 1 0 0 2 0 2 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 2 1]\n",
      "[0 2 2 2 1 0 0 1 2 0 2 0 0 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 0 1]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [114][7/9]\tTime 0.168409 (0.215)\tData 0.044\tLoss 0.0243\tAccuray 1.0000\n",
      "[2 1 2 1 0 1 2 0 1 2 2 1 0 0 0 1 1 1 1 2 1 1 0 1 0 0 1 1 2 1]\n",
      "[2 1 2 1 2 1 0 0 1 2 2 1 0 0 0 1 1 1 1 0 1 1 0 1 2 2 1 1 2 1]\n",
      "kappa:\t0.335, accuracy:\t0.833\n",
      "Epoch: [115][7/9]\tTime 0.167202 (0.206)\tData 0.034\tLoss 0.0214\tAccuray 0.9961\n",
      "[2 2 1 2 0 0 2 2 0 2 1 1 0 1 1 1 0 1 1 1 1 0 2 1 1 1 2 1 1 2]\n",
      "[2 0 1 2 0 0 2 2 2 0 1 1 0 1 1 1 2 1 1 1 1 0 2 1 1 1 0 1 1 2]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [116][7/9]\tTime 0.168061 (0.205)\tData 0.037\tLoss 0.0316\tAccuray 0.9922\n",
      "[1 1 1 0 1 2 1 2 0 1 2 1 2 0 1 1 0 2 1 2 1 0 2 1 2 1 2 0 1 1]\n",
      "[1 1 1 0 1 2 1 2 0 1 2 1 0 0 1 1 0 0 1 2 1 2 2 1 0 1 2 2 1 1]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [117][7/9]\tTime 0.168650 (0.209)\tData 0.037\tLoss 0.0242\tAccuray 0.9922\n",
      "[1 0 1 1 2 1 1 1 0 0 2 1 0 2 2 1 1 1 0 1 1 2 2 2 1 2 2 1 0 1]\n",
      "[1 2 1 1 2 1 1 1 0 0 2 1 0 2 2 1 1 1 2 1 1 0 2 0 1 0 2 1 0 1]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [118][7/9]\tTime 0.167043 (0.204)\tData 0.034\tLoss 0.0149\tAccuray 0.9961\n",
      "[2 2 1 1 1 1 0 1 0 0 2 2 1 1 2 2 0 1 1 0 0 2 1 1 1 2 1 1 2 1]\n",
      "[2 0 1 1 1 1 0 1 0 0 2 2 1 1 0 2 0 1 1 2 2 0 1 1 1 2 1 1 2 1]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [119][7/9]\tTime 0.163703 (0.208)\tData 0.038\tLoss 0.0380\tAccuray 0.9922\n",
      "[2 1 0 2 1 1 2 2 2 0 1 1 0 1 1 0 1 2 0 1 2 1 0 1 2 0 1 1 1 1]\n",
      "[2 1 0 0 1 1 2 2 0 0 1 1 0 1 1 0 1 2 0 1 2 1 2 1 2 2 1 1 1 1]\n",
      "kappa:\t0.465, accuracy:\t0.867\n",
      "====> parse options\n",
      "Namespace(batch_size=32, display=8, epoch=120, fix=50, lr=0.001, model='resnet34', mom=0.9, num_workers=2, out_dir='/data/beast/df/alzheimer/out_model', phase='train', step=40, train_images='/data/beast/df/alzheimer/train.h5', train_labels='/data/beast/df/alzheimer/train.csv', val_images='/data/beast/df/alzheimer/val.h5', val_labels='/data/beast/df/alzheimer/val.csv', wd=0.0001, weight=None)\n",
      "====> building model:\n",
      "Epoch: [0][7/9]\tTime 0.170946 (0.213)\tData 0.042\tLoss 1.1024\tAccuray 0.2852\n",
      "[2 2 1 1 2 1 2 1 2 2 2 1 2 2 2 1 2 2 2 1 1 1 2 1 2 1 1 2 1 1]\n",
      "[2 0 1 1 2 1 0 1 2 0 0 1 2 2 2 1 2 0 1 1 1 1 0 1 2 1 1 0 1 1]\n",
      "kappa:\t0.031, accuracy:\t0.733\n",
      "\n",
      "current best accuracy is: 0.7333333333333333\n",
      "\n",
      "====> save model:\t/data/beast/df/alzheimer/out_model/alzheimer_recognition_xxx_1/alzheimer_recognition_0000_best.pth\n",
      "Epoch: [1][7/9]\tTime 0.167387 (0.212)\tData 0.042\tLoss 1.0540\tAccuray 0.4688\n",
      "[1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 2 0 1 0 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 0 0 2 1 0 1 0 1 2 2 2 2 1 1 1 0 0 1 0 2 2 2 1 1 1 1 1]\n",
      "kappa:\t0.013, accuracy:\t0.600\n",
      "Epoch: [2][7/9]\tTime 0.170025 (0.215)\tData 0.044\tLoss 1.0276\tAccuray 0.5742\n",
      "[2 1 1 2 1 1 1 0 1 0 2 1 1 1 2 0 1 2 1 2 2 1 2 0 1 2 2 1 1 2]\n",
      "[0 1 1 0 1 1 1 0 1 2 2 1 1 1 2 0 1 2 1 0 2 1 2 2 1 0 0 1 1 2]\n",
      "kappa:\t0.052, accuracy:\t0.767\n",
      "\n",
      "current best accuracy is: 0.7666666666666667\n",
      "\n",
      "====> save model:\t/data/beast/df/alzheimer/out_model/alzheimer_recognition_xxx_1/alzheimer_recognition_0002_best.pth\n",
      "Epoch: [3][7/9]\tTime 0.168014 (0.218)\tData 0.046\tLoss 0.9943\tAccuray 0.7344\n",
      "[2 2 1 2 1 2 1 2 1 1 2 1 1 1 2 2 1 1 2 2 1 2 2 1 2 1 2 1 1 2]\n",
      "[2 2 1 0 1 2 1 2 1 1 0 1 1 1 2 0 1 1 0 0 1 0 2 1 0 1 2 1 1 2]\n",
      "kappa:\t0.034, accuracy:\t0.767\n",
      "Epoch: [4][7/9]\tTime 0.163738 (0.209)\tData 0.039\tLoss 0.9471\tAccuray 0.7578\n",
      "[1 0 2 2 1 1 1 2 1 2 2 1 2 1 0 1 1 1 1 1 2 2 1 0 2 0 1 0 1 2]\n",
      "[1 0 2 2 1 1 1 2 1 0 0 1 2 1 2 1 1 1 1 1 0 2 1 2 0 0 1 0 1 2]\n",
      "kappa:\t0.191, accuracy:\t0.800\n",
      "\n",
      "current best accuracy is: 0.8\n",
      "\n",
      "====> save model:\t/data/beast/df/alzheimer/out_model/alzheimer_recognition_xxx_1/alzheimer_recognition_0004_best.pth\n",
      "Epoch: [5][7/9]\tTime 0.169680 (0.212)\tData 0.043\tLoss 0.9081\tAccuray 0.7773\n",
      "[2 1 2 1 2 2 2 1 1 2 1 2 1 2 1 1 1 2 2 1 1 2 1 1 2 2 1 1 2 2]\n",
      "[0 1 2 1 2 2 0 1 1 0 1 2 1 2 1 1 1 2 0 1 1 2 1 1 2 0 1 1 0 0]\n",
      "kappa:\t0.034, accuracy:\t0.767\n",
      "Epoch: [6][7/9]\tTime 0.167810 (0.208)\tData 0.035\tLoss 0.8649\tAccuray 0.7461\n",
      "[0 1 0 1 0 0 0 0 2 1 0 2 1 1 1 1 2 1 0 0 1 0 1 1 1 0 1 0 1 1]\n",
      "[0 1 0 1 2 2 2 2 0 1 2 2 1 1 1 1 2 1 0 0 1 2 1 1 1 0 1 0 1 1]\n",
      "kappa:\t0.085, accuracy:\t0.767\n",
      "Epoch: [7][7/9]\tTime 0.167710 (0.207)\tData 0.040\tLoss 0.8143\tAccuray 0.7812\n",
      "[2 1 2 2 1 2 1 1 1 2 2 2 1 2 2 1 2 1 1 1 1 1 1 2 1 2 1 2 2 2]\n",
      "[2 1 2 2 1 2 1 1 1 0 0 0 1 0 2 1 0 1 1 1 1 1 1 2 1 2 1 2 0 0]\n",
      "kappa:\t0.034, accuracy:\t0.767\n",
      "Epoch: [8][7/9]\tTime 0.166404 (0.216)\tData 0.046\tLoss 0.7583\tAccuray 0.7656\n",
      "[2 1 1 0 1 0 0 1 2 2 1 1 1 2 1 2 1 1 0 0 1 0 0 2 0 1 1 1 2 1]\n",
      "[0 1 1 0 1 0 2 1 0 2 1 1 1 2 1 2 1 1 2 2 1 2 0 0 0 1 1 1 2 1]\n",
      "kappa:\t0.069, accuracy:\t0.767\n",
      "Epoch: [9][7/9]\tTime 0.168423 (0.214)\tData 0.044\tLoss 0.7111\tAccuray 0.7656\n",
      "[1 2 1 2 2 2 1 2 2 1 2 2 1 1 1 1 2 1 2 2 2 1 2 1 1 1 2 2 1 1]\n",
      "[1 0 1 2 2 0 1 2 2 1 2 0 1 1 1 1 2 1 0 2 2 1 0 1 1 1 0 0 1 1]\n",
      "kappa:\t0.034, accuracy:\t0.767\n",
      "Epoch: [10][7/9]\tTime 0.171727 (0.215)\tData 0.043\tLoss 0.6732\tAccuray 0.8359\n",
      "[1 1 2 2 1 2 1 2 1 2 1 1 2 1 1 2 1 2 2 1 1 2 1 2 2 1 1 2 2 2]\n",
      "[1 1 2 2 1 2 1 0 1 2 1 1 2 1 1 0 1 0 0 1 1 0 1 0 0 1 1 2 2 2]\n",
      "kappa:\t0.034, accuracy:\t0.767\n",
      "Epoch: [11][7/9]\tTime 0.167192 (0.215)\tData 0.045\tLoss 0.6254\tAccuray 0.8008\n",
      "[1 1 1 2 1 0 0 2 1 2 1 1 2 1 0 1 1 0 2 1 1 0 2 0 0 1 0 0 1 1]\n",
      "[1 1 1 0 1 0 2 0 1 0 1 1 2 1 2 1 1 0 2 1 1 0 2 2 2 1 2 0 1 1]\n",
      "kappa:\t-0.060, accuracy:\t0.733\n",
      "Epoch: [12][7/9]\tTime 0.166541 (0.204)\tData 0.036\tLoss 0.5752\tAccuray 0.8906\n",
      "[2 2 2 2 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 2 2 2 2 2 2 2 2 2 1 1]\n",
      "[2 0 0 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 2 2 2 2 2 0 0 2 2 1 1]\n",
      "kappa:\t0.034, accuracy:\t0.767\n",
      "Epoch: [13][7/9]\tTime 0.168660 (0.211)\tData 0.041\tLoss 0.5709\tAccuray 0.8438\n",
      "[1 2 1 2 1 1 2 2 1 2 2 2 1 2 1 1 1 1 1 2 2 1 2 1 2 1 2 2 1 2]\n",
      "[1 0 1 2 1 1 0 2 1 0 0 2 1 0 1 1 1 1 1 2 2 1 2 1 0 1 0 2 1 2]\n",
      "kappa:\t0.034, accuracy:\t0.767\n",
      "Epoch: [14][7/9]\tTime 0.168008 (0.205)\tData 0.036\tLoss 0.5455\tAccuray 0.8164\n",
      "[2 1 0 0 1 1 1 2 2 0 2 1 1 1 2 2 1 1 2 2 1 1 1 1 2 1 2 0 1 2]\n",
      "[2 1 0 2 1 1 1 0 2 0 0 1 1 1 0 2 1 1 2 2 1 1 1 1 2 1 0 0 1 2]\n",
      "kappa:\t0.323, accuracy:\t0.833\n",
      "\n",
      "current best accuracy is: 0.8333333333333334\n",
      "\n",
      "====> save model:\t/data/beast/df/alzheimer/out_model/alzheimer_recognition_xxx_1/alzheimer_recognition_0014_best.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [15][7/9]\tTime 0.165657 (0.211)\tData 0.042\tLoss 0.5208\tAccuray 0.8672\n",
      "[1 1 1 1 1 2 2 1 2 1 2 1 1 2 2 2 2 2 1 1 2 1 2 1 2 2 1 2 2 1]\n",
      "[1 1 1 1 1 0 0 1 0 1 0 1 1 2 2 2 2 2 1 1 2 1 0 1 0 2 1 2 0 1]\n",
      "kappa:\t0.034, accuracy:\t0.767\n",
      "Epoch: [16][7/9]\tTime 0.167330 (0.210)\tData 0.042\tLoss 0.4951\tAccuray 0.8438\n",
      "[2 2 1 1 2 1 0 2 2 2 1 1 1 2 1 1 2 1 1 1 1 1 2 1 0 2 2 2 2 1]\n",
      "[2 0 1 1 0 1 2 0 0 2 1 1 1 2 1 1 0 1 1 1 1 1 2 1 0 2 2 2 0 1]\n",
      "kappa:\t0.043, accuracy:\t0.767\n",
      "Epoch: [17][7/9]\tTime 0.166007 (0.205)\tData 0.036\tLoss 0.4794\tAccuray 0.8086\n",
      "[2 2 0 0 0 0 1 1 2 2 1 1 1 1 1 2 1 0 1 1 0 1 1 1 1 0 0 2 1 0]\n",
      "[2 2 2 2 0 0 1 1 2 0 1 1 1 1 1 0 1 0 1 1 2 1 1 1 1 2 0 2 1 0]\n",
      "kappa:\t0.205, accuracy:\t0.800\n",
      "Epoch: [18][7/9]\tTime 0.165375 (0.208)\tData 0.038\tLoss 0.4642\tAccuray 0.9258\n",
      "[1 2 2 1 2 1 1 2 1 1 2 1 2 2 2 1 2 1 2 1 2 2 2 1 2 2 1 2 1 2]\n",
      "[1 0 2 1 2 1 1 0 1 1 0 1 0 2 2 1 0 1 0 1 1 0 2 1 2 2 1 1 1 2]\n",
      "kappa:\t0.028, accuracy:\t0.700\n",
      "Epoch: [19][7/9]\tTime 0.165781 (0.211)\tData 0.045\tLoss 0.4565\tAccuray 0.8555\n",
      "[1 1 2 2 2 1 1 2 0 1 1 1 2 0 1 0 1 1 1 2 0 0 0 0 2 1 1 1 2 1]\n",
      "[1 1 2 2 0 1 1 2 0 1 1 1 0 0 1 0 1 1 1 0 2 2 0 2 2 1 1 1 2 1]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [20][7/9]\tTime 0.165592 (0.211)\tData 0.041\tLoss 0.4372\tAccuray 0.9023\n",
      "[1 1 1 1 1 2 1 2 1 1 2 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 1 2]\n",
      "[1 1 1 1 1 2 1 2 1 1 2 1 1 1 1 1 1 0 2 0 2 2 0 0 2 0 0 0 1 2]\n",
      "kappa:\t0.034, accuracy:\t0.767\n",
      "Epoch: [21][7/9]\tTime 0.167204 (0.207)\tData 0.038\tLoss 0.4537\tAccuray 0.8789\n",
      "[2 2 0 2 2 2 1 2 1 0 1 1 1 2 1 1 1 1 2 1 0 0 1 2 2 1 1 1 1 2]\n",
      "[0 2 2 0 0 0 1 2 1 0 1 1 1 2 1 1 1 1 0 1 2 0 1 2 2 1 1 1 1 2]\n",
      "kappa:\t0.052, accuracy:\t0.767\n",
      "Epoch: [22][7/9]\tTime 0.170020 (0.209)\tData 0.037\tLoss 0.4373\tAccuray 0.9141\n",
      "[1 2 1 1 2 2 0 2 1 1 1 2 1 2 1 2 1 1 2 1 2 2 1 1 0 2 0 1 2 1]\n",
      "[1 2 1 1 2 2 0 0 1 1 1 2 1 2 1 2 1 1 2 1 0 0 1 1 0 0 0 1 2 1]\n",
      "kappa:\t0.456, accuracy:\t0.867\n",
      "\n",
      "current best accuracy is: 0.8666666666666667\n",
      "\n",
      "====> save model:\t/data/beast/df/alzheimer/out_model/alzheimer_recognition_xxx_1/alzheimer_recognition_0022_best.pth\n",
      "Epoch: [23][7/9]\tTime 0.166695 (0.211)\tData 0.044\tLoss 0.4099\tAccuray 0.9180\n",
      "[1 1 0 2 1 1 1 1 1 2 1 1 2 2 2 0 2 2 1 1 2 1 1 1 2 2 2 2 2 1]\n",
      "[1 1 0 0 1 1 1 1 1 2 1 1 2 2 0 0 0 2 1 1 2 1 1 1 2 2 0 0 2 1]\n",
      "kappa:\t0.317, accuracy:\t0.833\n",
      "Epoch: [24][7/9]\tTime 0.166092 (0.208)\tData 0.041\tLoss 0.4066\tAccuray 0.9102\n",
      "[2 1 2 1 2 2 0 1 2 1 1 0 1 2 2 1 1 0 1 1 1 2 1 2 2 2 1 2 2 2]\n",
      "[2 1 2 1 1 0 0 1 0 1 1 0 1 2 2 1 1 0 1 1 1 2 1 1 2 2 1 0 0 2]\n",
      "kappa:\t0.424, accuracy:\t0.800\n",
      "Epoch: [25][7/9]\tTime 0.167375 (0.204)\tData 0.036\tLoss 0.3939\tAccuray 0.9453\n",
      "[2 1 2 1 2 2 2 2 2 2 2 1 0 1 1 1 1 2 2 2 1 1 1 1 1 2 1 1 2 2]\n",
      "[2 1 2 1 2 0 0 0 2 2 0 1 1 1 1 1 1 0 0 2 1 1 1 1 1 0 1 1 2 2]\n",
      "kappa:\t0.035, accuracy:\t0.733\n",
      "Epoch: [26][7/9]\tTime 0.167255 (0.207)\tData 0.037\tLoss 0.3752\tAccuray 0.9180\n",
      "[1 1 2 1 1 0 1 1 1 0 0 2 1 0 2 1 1 2 2 0 1 1 1 2 1 1 2 0 0 2]\n",
      "[1 1 2 1 1 0 1 1 1 2 2 0 1 0 2 1 1 0 2 0 1 1 1 2 1 1 0 2 2 0]\n",
      "kappa:\t-0.069, accuracy:\t0.733\n",
      "Epoch: [27][7/9]\tTime 0.168254 (0.209)\tData 0.035\tLoss 0.3699\tAccuray 0.9297\n",
      "[1 1 2 2 1 2 1 1 2 1 2 1 1 2 2 1 2 2 1 2 1 0 1 2 1 1 2 1 2 2]\n",
      "[1 1 0 2 1 2 1 1 2 1 2 1 1 0 0 1 2 0 1 2 1 0 1 2 1 1 0 1 2 0]\n",
      "kappa:\t0.176, accuracy:\t0.800\n",
      "Epoch: [28][7/9]\tTime 0.165495 (0.205)\tData 0.036\tLoss 0.3681\tAccuray 0.9414\n",
      "[1 1 1 2 0 0 1 1 1 1 1 1 0 2 2 1 2 2 1 0 2 0 2 0 2 0 2 2 1 1]\n",
      "[1 1 1 2 0 0 1 1 1 1 1 1 0 2 2 1 0 1 1 0 2 2 1 2 0 2 0 2 1 1]\n",
      "kappa:\t0.182, accuracy:\t0.733\n",
      "Epoch: [29][7/9]\tTime 0.166402 (0.214)\tData 0.045\tLoss 0.3731\tAccuray 0.9219\n",
      "[2 1 0 1 1 1 0 2 1 1 1 2 1 1 1 1 0 0 2 2 2 1 2 0 1 2 1 2 1 2]\n",
      "[2 1 2 1 1 1 0 2 1 1 1 2 1 1 1 1 2 0 2 0 0 1 2 0 1 0 1 0 1 2]\n",
      "kappa:\t0.191, accuracy:\t0.800\n",
      "Epoch: [30][7/9]\tTime 0.161959 (0.210)\tData 0.043\tLoss 0.3347\tAccuray 0.9492\n",
      "[1 1 2 2 1 0 1 0 1 2 2 1 1 2 1 1 1 2 2 1 2 1 0 2 1 2 1 1 2 0]\n",
      "[1 1 0 2 1 0 1 0 1 2 2 1 1 0 1 1 1 0 0 1 2 1 0 2 1 2 1 1 2 2]\n",
      "kappa:\t0.323, accuracy:\t0.833\n",
      "Epoch: [31][7/9]\tTime 0.165303 (0.215)\tData 0.044\tLoss 0.2777\tAccuray 0.9727\n",
      "[1 1 1 2 1 2 2 2 1 2 1 2 1 2 1 2 2 2 2 1 1 1 2 1 1 2 2 2 1 1]\n",
      "[1 1 1 0 1 2 2 2 1 2 1 0 1 2 1 2 0 2 0 1 1 1 0 1 1 0 2 0 1 1]\n",
      "kappa:\t0.034, accuracy:\t0.767\n",
      "Epoch: [32][7/9]\tTime 0.164642 (0.205)\tData 0.036\tLoss 0.2815\tAccuray 0.9727\n",
      "[1 2 1 1 0 1 1 2 1 2 0 1 1 1 1 2 1 2 0 1 1 1 0 2 0 2 2 1 0 0]\n",
      "[1 2 1 1 0 1 1 2 1 0 2 1 1 1 1 2 1 2 2 1 1 1 0 0 0 2 0 1 2 0]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [33][7/9]\tTime 0.168536 (0.208)\tData 0.042\tLoss 0.2690\tAccuray 0.9766\n",
      "[2 1 2 2 0 0 2 1 0 1 1 0 2 0 1 1 1 2 1 1 2 1 1 2 1 2 0 1 1 1]\n",
      "[0 1 0 2 0 0 2 1 2 1 1 2 2 0 1 1 1 2 1 1 0 1 1 2 1 2 0 1 1 1]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [34][7/9]\tTime 0.167867 (0.212)\tData 0.045\tLoss 0.2805\tAccuray 0.9648\n",
      "[1 0 0 1 2 2 1 1 1 1 1 0 1 1 1 1 2 2 1 0 0 1 0 0 2 2 2 1 2 1]\n",
      "[1 2 0 1 2 2 1 1 1 1 1 0 1 1 1 1 2 0 1 0 2 1 0 2 0 2 2 1 0 1]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [35][7/9]\tTime 0.170982 (0.216)\tData 0.045\tLoss 0.3000\tAccuray 0.9531\n",
      "[1 1 1 1 2 2 1 0 1 1 1 2 1 2 2 1 2 1 2 2 0 1 1 2 1 1 2 0 0 0]\n",
      "[1 1 1 1 2 0 1 0 1 1 1 0 1 2 2 1 2 1 0 2 2 1 1 2 1 1 0 0 0 2]\n",
      "kappa:\t0.191, accuracy:\t0.800\n",
      "Epoch: [36][7/9]\tTime 0.166736 (0.209)\tData 0.039\tLoss 0.2476\tAccuray 0.9531\n",
      "[2 2 2 2 1 1 1 2 1 2 1 2 2 1 2 1 1 1 2 2 1 2 1 2 1 1 1 1 2 0]\n",
      "[0 2 0 0 1 1 1 0 1 2 1 2 0 1 0 1 1 1 2 2 1 2 1 2 1 1 1 1 2 0]\n",
      "kappa:\t0.176, accuracy:\t0.800\n",
      "Epoch: [37][7/9]\tTime 0.166676 (0.211)\tData 0.043\tLoss 0.2491\tAccuray 0.9570\n",
      "[2 2 1 1 1 1 2 1 0 1 1 2 2 1 1 2 0 0 2 1 1 1 2 1 0 0 0 1 1 0]\n",
      "[2 2 1 1 1 1 2 1 0 1 1 2 2 1 1 2 2 0 0 1 1 1 0 1 0 0 2 1 1 0]\n",
      "kappa:\t0.465, accuracy:\t0.867\n",
      "Epoch: [38][7/9]\tTime 0.173892 (0.217)\tData 0.046\tLoss 0.1677\tAccuray 0.9805\n",
      "[1 1 0 2 1 2 1 1 1 1 0 1 0 2 1 1 0 2 1 2 2 2 2 0 1 1 1 2 1 2]\n",
      "[1 1 0 2 1 0 1 1 1 1 2 1 0 0 1 1 0 2 1 0 2 2 2 2 1 1 1 0 1 2]\n",
      "kappa:\t0.191, accuracy:\t0.800\n",
      "Epoch: [39][7/9]\tTime 0.174505 (0.214)\tData 0.044\tLoss 0.1586\tAccuray 0.9844\n",
      "[1 2 1 2 1 1 2 2 0 0 2 1 2 2 1 1 1 0 1 1 2 1 2 1 1 2 1 2 1 2]\n",
      "[1 2 1 2 1 1 0 2 2 0 2 1 0 2 1 1 1 2 1 1 0 1 0 1 1 0 1 2 1 0]\n",
      "kappa:\t-0.088, accuracy:\t0.733\n",
      "Epoch: [40][7/9]\tTime 0.167437 (0.206)\tData 0.035\tLoss 0.1740\tAccuray 0.9688\n",
      "[2 1 0 0 0 2 0 1 2 2 1 2 1 2 1 2 1 1 1 1 1 2 1 2 1 1 2 1 1 2]\n",
      "[0 1 0 2 0 0 0 1 2 0 1 2 1 2 1 2 1 1 1 1 1 2 1 0 1 1 2 1 1 2]\n",
      "kappa:\t0.323, accuracy:\t0.833\n",
      "Epoch: [41][7/9]\tTime 0.166396 (0.214)\tData 0.047\tLoss 0.2319\tAccuray 0.9336\n",
      "[2 0 1 1 1 1 2 1 0 2 0 2 1 2 0 2 0 1 2 1 2 1 1 1 2 2 1 1 1 1]\n",
      "[2 2 1 1 1 1 2 1 0 2 0 0 1 2 0 2 0 1 0 1 2 1 1 1 2 0 1 1 1 1]\n",
      "kappa:\t0.461, accuracy:\t0.867\n",
      "Epoch: [42][7/9]\tTime 0.165281 (0.217)\tData 0.047\tLoss 0.1885\tAccuray 0.9727\n",
      "[2 1 2 1 1 1 0 2 1 0 1 2 1 1 2 2 0 2 0 0 1 1 0 0 2 1 1 1 1 1]\n",
      "[2 1 2 1 1 1 2 2 1 0 1 2 1 1 0 0 0 2 2 0 1 1 0 0 2 1 1 1 1 1]\n",
      "kappa:\t0.465, accuracy:\t0.867\n",
      "Epoch: [43][7/9]\tTime 0.167292 (0.205)\tData 0.035\tLoss 0.1754\tAccuray 0.9609\n",
      "[2 2 1 2 2 2 0 2 1 1 1 0 1 1 0 2 1 0 0 0 1 1 2 1 1 1 1 1 1 0]\n",
      "[2 2 1 2 0 2 0 0 1 1 1 0 1 1 0 2 1 2 2 2 1 1 0 1 1 1 1 1 1 0]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [44][7/9]\tTime 0.166019 (0.215)\tData 0.047\tLoss 0.2094\tAccuray 0.9531\n",
      "[1 1 0 2 2 1 0 0 1 2 1 2 2 1 2 1 0 1 0 1 2 2 1 1 1 1 1 2 2 1]\n",
      "[1 1 0 2 2 1 0 2 1 2 1 0 2 1 2 1 0 1 0 1 2 0 1 1 1 1 1 0 2 1]\n",
      "kappa:\t0.461, accuracy:\t0.867\n",
      "Epoch: [45][7/9]\tTime 0.168433 (0.213)\tData 0.042\tLoss 0.1386\tAccuray 0.9766\n",
      "[1 1 2 2 1 2 1 0 2 1 2 2 1 1 1 1 2 1 0 2 1 1 2 0 0 1 2 0 1 1]\n",
      "[1 1 2 2 1 2 1 2 2 1 2 0 1 1 1 1 0 1 0 2 1 1 0 0 2 1 0 0 1 1]\n",
      "kappa:\t0.191, accuracy:\t0.800\n",
      "Epoch: [46][7/9]\tTime 0.166921 (0.205)\tData 0.036\tLoss 0.1232\tAccuray 0.9688\n",
      "[1 2 2 1 1 1 0 1 2 0 2 1 2 1 1 1 1 1 0 1 2 2 1 2 2 1 0 1 0 0]\n",
      "[1 0 2 1 1 1 2 1 2 2 2 1 2 1 1 1 1 1 0 1 0 2 1 2 0 1 0 1 0 0]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [47][7/9]\tTime 0.169660 (0.210)\tData 0.039\tLoss 0.1355\tAccuray 0.9766\n",
      "[1 2 1 1 2 0 2 2 1 1 0 1 0 1 1 1 2 2 2 2 2 1 1 1 0 1 2 1 2 1]\n",
      "[1 0 1 1 0 0 2 2 1 1 0 1 0 1 1 1 0 2 2 2 2 1 1 1 2 1 0 1 2 1]\n",
      "kappa:\t0.323, accuracy:\t0.833\n",
      "Epoch: [48][7/9]\tTime 0.171503 (0.214)\tData 0.044\tLoss 0.1164\tAccuray 0.9766\n",
      "[0 1 1 1 1 0 0 2 2 1 1 0 2 2 1 0 1 1 2 2 1 1 1 2 0 1 1 1 2 2]\n",
      "[2 1 1 1 1 0 0 2 0 1 1 2 2 0 1 2 1 1 0 2 1 1 1 2 0 1 1 1 0 2]\n",
      "kappa:\t0.060, accuracy:\t0.767\n",
      "Epoch: [49][7/9]\tTime 0.171446 (0.210)\tData 0.038\tLoss 0.0734\tAccuray 0.9961\n",
      "[0 2 2 1 1 2 1 2 1 2 1 1 1 2 2 1 2 2 1 2 1 1 1 0 1 2 0 1 2 1]\n",
      "[0 0 2 1 1 2 1 0 1 2 1 1 1 2 2 1 2 0 1 0 1 1 1 0 1 2 2 1 0 1]\n",
      "kappa:\t0.184, accuracy:\t0.800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [50][7/9]\tTime 0.164387 (0.205)\tData 0.035\tLoss 0.0934\tAccuray 0.9805\n",
      "[0 2 2 1 1 1 1 2 1 0 0 1 0 0 1 1 2 2 2 1 1 1 1 1 1 0 1 2 2 2]\n",
      "[0 0 2 1 1 1 1 2 1 0 2 1 2 0 1 1 2 2 0 1 1 1 1 1 1 2 1 0 2 0]\n",
      "kappa:\t0.060, accuracy:\t0.767\n",
      "Epoch: [51][7/9]\tTime 0.167758 (0.205)\tData 0.036\tLoss 0.0921\tAccuray 0.9805\n",
      "[2 1 2 1 0 1 1 0 2 1 2 1 1 2 2 1 1 1 1 2 1 0 0 1 2 1 1 2 2 2]\n",
      "[0 1 0 1 2 1 1 0 2 1 2 1 1 2 0 1 1 1 1 0 1 2 0 1 0 1 1 2 2 2]\n",
      "kappa:\t0.052, accuracy:\t0.767\n",
      "Epoch: [52][7/9]\tTime 0.165053 (0.207)\tData 0.038\tLoss 0.0888\tAccuray 0.9805\n",
      "[2 1 2 0 1 1 1 1 2 1 1 0 0 0 2 1 0 1 2 2 2 2 1 1 0 1 1 1 2 1]\n",
      "[2 1 2 2 1 1 1 1 0 1 1 0 0 2 2 1 0 1 0 0 2 2 1 1 0 1 1 1 2 1]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [53][7/9]\tTime 0.166291 (0.204)\tData 0.036\tLoss 0.0822\tAccuray 0.9844\n",
      "[1 0 1 2 1 2 1 1 2 2 2 2 2 2 1 1 2 1 1 2 2 0 1 2 0 1 1 1 1 1]\n",
      "[1 0 1 0 1 2 1 1 2 2 0 2 0 0 1 1 2 1 1 2 2 0 1 0 2 1 1 1 1 1]\n",
      "kappa:\t0.184, accuracy:\t0.800\n",
      "Epoch: [54][7/9]\tTime 0.169275 (0.214)\tData 0.043\tLoss 0.1702\tAccuray 0.9492\n",
      "[1 2 1 1 2 2 1 1 0 1 2 1 2 0 1 2 2 1 0 1 2 0 1 0 1 1 1 0 1 2]\n",
      "[1 0 1 1 2 0 1 1 2 1 0 1 2 0 1 2 0 1 0 1 2 2 1 0 1 1 1 2 1 2]\n",
      "kappa:\t0.060, accuracy:\t0.767\n",
      "Epoch: [55][7/9]\tTime 0.169194 (0.211)\tData 0.038\tLoss 0.1508\tAccuray 0.9688\n",
      "[0 1 0 1 2 2 1 1 2 1 1 2 0 0 2 0 1 0 1 1 1 2 1 0 2 1 1 2 1 1]\n",
      "[0 1 0 1 0 0 1 1 2 1 1 2 0 2 2 2 1 2 1 1 1 2 1 0 2 1 1 0 1 1]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [56][7/9]\tTime 0.175529 (0.215)\tData 0.042\tLoss 0.1163\tAccuray 0.9727\n",
      "[2 0 1 2 0 2 1 2 1 2 1 0 2 1 1 1 1 0 2 1 0 2 1 1 1 2 1 1 2 1]\n",
      "[2 0 1 0 2 2 1 0 1 2 1 2 0 1 1 1 1 0 2 1 0 2 1 1 1 0 1 1 2 1]\n",
      "kappa:\t0.191, accuracy:\t0.800\n",
      "Epoch: [57][7/9]\tTime 0.168828 (0.217)\tData 0.046\tLoss 0.1380\tAccuray 0.9570\n",
      "[1 2 2 1 1 1 1 1 2 1 1 0 2 2 2 1 1 0 2 1 2 1 1 1 2 1 0 0 2 0]\n",
      "[1 0 0 1 1 1 1 1 2 1 1 0 0 2 2 1 1 2 0 1 2 1 1 1 2 1 0 2 2 0]\n",
      "kappa:\t0.191, accuracy:\t0.800\n",
      "Epoch: [58][7/9]\tTime 0.169999 (0.216)\tData 0.044\tLoss 0.0886\tAccuray 0.9844\n",
      "[1 2 1 1 2 0 1 1 1 1 0 2 0 0 2 1 1 2 2 1 2 1 1 2 0 2 1 1 2 1]\n",
      "[1 2 1 1 2 2 1 1 1 1 2 2 2 0 0 1 1 2 0 1 0 1 1 0 0 0 1 1 2 1]\n",
      "kappa:\t-0.079, accuracy:\t0.733\n",
      "Epoch: [59][7/9]\tTime 0.171696 (0.218)\tData 0.046\tLoss 0.0683\tAccuray 0.9883\n",
      "[1 2 0 0 2 2 2 1 1 2 1 0 2 0 2 1 1 1 1 1 1 1 2 1 2 0 1 2 1 1]\n",
      "[1 2 0 2 2 2 2 1 1 2 1 0 2 2 0 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1]\n",
      "kappa:\t0.191, accuracy:\t0.800\n",
      "Epoch: [60][7/9]\tTime 0.173002 (0.212)\tData 0.036\tLoss 0.0902\tAccuray 0.9766\n",
      "[0 1 2 1 0 1 2 2 1 2 1 2 2 2 1 0 1 2 2 1 1 1 2 0 2 1 1 1 0 0]\n",
      "[0 1 2 1 1 1 0 0 1 2 1 0 2 0 1 2 1 2 2 1 1 1 2 0 2 1 1 1 1 0]\n",
      "kappa:\t0.305, accuracy:\t0.767\n",
      "Epoch: [61][7/9]\tTime 0.171964 (0.215)\tData 0.043\tLoss 0.0811\tAccuray 0.9766\n",
      "[2 1 1 0 0 1 2 2 0 1 1 2 1 1 1 1 1 1 1 2 0 2 1 1 2 0 2 2 1 2]\n",
      "[2 1 1 0 2 1 2 2 0 1 1 2 1 1 1 1 1 1 1 2 2 2 1 1 0 0 0 0 1 0]\n",
      "kappa:\t0.191, accuracy:\t0.800\n",
      "Epoch: [62][7/9]\tTime 0.170152 (0.213)\tData 0.043\tLoss 0.0585\tAccuray 0.9844\n",
      "[1 0 2 1 2 1 1 0 0 2 1 2 2 1 1 1 1 1 2 1 1 2 2 2 1 1 2 2 0 1]\n",
      "[1 2 0 1 2 1 1 0 0 2 1 0 0 1 1 1 1 1 2 1 1 2 2 0 1 1 0 2 2 1]\n",
      "kappa:\t0.052, accuracy:\t0.767\n",
      "Epoch: [63][7/9]\tTime 0.176104 (0.206)\tData 0.034\tLoss 0.0488\tAccuray 0.9961\n",
      "[2 1 2 1 2 1 1 0 1 2 1 1 0 2 1 2 1 1 1 2 2 2 1 2 2 0 1 0 1 1]\n",
      "[2 1 0 1 0 1 1 2 1 2 1 1 2 0 1 0 1 1 1 2 2 2 1 2 0 0 1 0 1 1]\n",
      "kappa:\t0.052, accuracy:\t0.767\n",
      "Epoch: [64][7/9]\tTime 0.172117 (0.213)\tData 0.039\tLoss 0.0435\tAccuray 0.9883\n",
      "[1 1 2 2 0 2 2 2 1 0 1 2 0 0 1 2 1 2 1 2 1 1 1 2 1 1 2 1 1 1]\n",
      "[1 1 0 2 2 0 0 2 1 2 1 2 0 0 1 0 1 0 1 2 1 1 1 2 1 1 2 1 1 1]\n",
      "kappa:\t0.052, accuracy:\t0.767\n",
      "Epoch: [65][7/9]\tTime 0.170676 (0.213)\tData 0.039\tLoss 0.0467\tAccuray 0.9883\n",
      "[1 1 2 2 1 0 1 1 0 2 2 1 1 0 1 2 0 1 2 2 2 1 1 0 1 1 1 2 1 2]\n",
      "[1 1 2 2 1 2 1 1 0 0 2 1 1 0 1 2 0 1 0 2 2 1 1 2 1 1 1 0 1 0]\n",
      "kappa:\t0.191, accuracy:\t0.800\n",
      "Epoch: [66][7/9]\tTime 0.170413 (0.216)\tData 0.044\tLoss 0.0576\tAccuray 0.9883\n",
      "[1 2 1 0 2 1 1 1 2 1 1 2 0 1 2 1 1 2 1 0 0 2 2 0 1 1 1 1 2 2]\n",
      "[1 2 1 0 2 1 1 1 2 1 1 2 2 1 2 1 1 2 1 0 2 0 0 0 1 1 1 1 0 0]\n",
      "kappa:\t0.191, accuracy:\t0.800\n",
      "Epoch: [67][7/9]\tTime 0.174424 (0.215)\tData 0.039\tLoss 0.0716\tAccuray 0.9844\n",
      "[2 2 0 1 2 1 2 0 1 2 1 2 1 1 2 2 1 0 0 0 1 1 2 1 1 1 1 1 2 1]\n",
      "[2 2 0 1 0 1 2 2 1 2 1 2 1 1 2 0 1 0 2 0 1 1 0 1 1 1 1 1 0 1]\n",
      "kappa:\t0.191, accuracy:\t0.800\n",
      "Epoch: [68][7/9]\tTime 0.170867 (0.214)\tData 0.043\tLoss 0.0758\tAccuray 0.9844\n",
      "[1 1 1 2 0 2 2 2 1 0 1 1 1 1 2 0 1 1 1 1 2 0 0 1 2 2 1 0 0 1]\n",
      "[1 1 1 2 0 2 0 2 1 2 1 1 1 1 2 0 1 1 1 1 0 2 0 1 0 2 1 0 2 1]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [69][7/9]\tTime 0.169625 (0.217)\tData 0.045\tLoss 0.1228\tAccuray 0.9727\n",
      "[2 1 0 1 0 1 1 0 1 1 1 2 2 2 0 2 0 2 2 1 1 1 0 2 2 1 1 2 0 1]\n",
      "[2 1 2 1 0 1 1 0 1 1 1 1 2 2 2 2 0 1 0 1 1 1 0 2 0 1 1 2 0 1]\n",
      "kappa:\t0.434, accuracy:\t0.800\n",
      "Epoch: [70][7/9]\tTime 0.171698 (0.209)\tData 0.035\tLoss 0.1656\tAccuray 0.9492\n",
      "[2 1 1 2 1 1 2 1 1 1 1 1 2 2 0 0 0 0 2 0 1 1 0 1 1 2 1 0 2 1]\n",
      "[0 1 1 2 1 1 2 1 1 1 1 1 2 0 0 0 0 0 2 0 1 1 2 1 1 2 1 2 2 1]\n",
      "kappa:\t0.465, accuracy:\t0.867\n",
      "Epoch: [71][7/9]\tTime 0.171300 (0.215)\tData 0.043\tLoss 0.1086\tAccuray 0.9883\n",
      "[1 1 2 0 0 2 1 2 0 1 1 2 1 0 2 1 2 2 1 2 1 0 1 0 1 1 1 1 0 1]\n",
      "[1 1 0 0 2 2 1 2 0 1 1 2 1 0 2 1 2 2 1 0 1 0 1 0 1 1 1 1 2 1]\n",
      "kappa:\t0.465, accuracy:\t0.867\n",
      "Epoch: [72][7/9]\tTime 0.176083 (0.225)\tData 0.049\tLoss 0.0929\tAccuray 0.9805\n",
      "[2 0 1 2 0 1 0 0 2 0 0 2 1 1 1 1 1 0 1 1 1 1 1 2 0 2 2 1 1 1]\n",
      "[2 2 1 2 2 1 0 0 0 0 0 2 1 1 1 1 1 0 1 1 1 1 1 2 2 0 2 1 1 1]\n",
      "kappa:\t0.335, accuracy:\t0.833\n",
      "Epoch: [73][7/9]\tTime 0.171760 (0.215)\tData 0.044\tLoss 0.0904\tAccuray 0.9883\n",
      "[1 0 1 1 2 1 1 2 1 1 1 2 1 2 2 0 2 2 0 2 2 1 0 1 0 1 2 1 1 1]\n",
      "[1 0 1 1 2 1 1 0 1 1 1 0 1 2 2 0 0 0 2 2 2 1 2 1 0 1 2 1 1 1]\n",
      "kappa:\t0.191, accuracy:\t0.800\n",
      "Epoch: [74][7/9]\tTime 0.173586 (0.214)\tData 0.043\tLoss 0.0611\tAccuray 0.9805\n",
      "[1 2 2 0 1 1 2 1 1 1 0 0 2 2 0 1 0 1 1 0 2 1 1 2 1 1 1 1 2 2]\n",
      "[1 2 0 0 1 1 2 1 1 1 2 0 2 2 2 1 0 1 1 0 2 1 1 0 1 1 1 1 2 0]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [75][7/9]\tTime 0.174829 (0.214)\tData 0.043\tLoss 0.0696\tAccuray 0.9805\n",
      "[1 0 1 1 0 2 1 1 0 1 1 2 2 0 1 0 2 2 0 1 1 2 2 1 1 1 2 0 1 1]\n",
      "[1 0 1 1 0 0 1 1 0 1 1 2 2 0 1 0 2 2 2 1 1 2 2 1 1 1 0 2 1 1]\n",
      "kappa:\t0.465, accuracy:\t0.867\n",
      "Epoch: [76][7/9]\tTime 0.172516 (0.207)\tData 0.035\tLoss 0.0468\tAccuray 0.9922\n",
      "[1 0 1 2 0 2 1 1 1 0 2 1 2 0 1 1 1 1 2 0 1 0 2 1 0 1 2 1 1 2]\n",
      "[1 2 1 0 0 0 1 1 1 0 0 1 2 0 1 1 1 1 2 2 1 0 2 1 2 1 2 1 1 2]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [77][7/9]\tTime 0.171812 (0.221)\tData 0.047\tLoss 0.0804\tAccuray 0.9844\n",
      "[1 2 2 0 1 2 1 0 1 0 2 1 2 2 0 1 1 0 2 1 1 0 2 2 1 1 1 1 1 1]\n",
      "[1 2 2 2 1 2 1 0 1 0 2 1 2 0 0 1 1 0 0 1 1 0 2 2 1 1 1 1 1 1]\n",
      "kappa:\t0.597, accuracy:\t0.900\n",
      "\n",
      "current best accuracy is: 0.9\n",
      "\n",
      "====> save model:\t/data/beast/df/alzheimer/out_model/alzheimer_recognition_xxx_1/alzheimer_recognition_0077_best.pth\n",
      "Epoch: [78][7/9]\tTime 0.174556 (0.217)\tData 0.040\tLoss 0.0438\tAccuray 0.9922\n",
      "[0 1 1 1 2 2 2 2 1 0 1 1 1 1 1 2 1 0 1 0 1 1 1 0 2 2 0 2 2 1]\n",
      "[0 1 1 1 2 0 0 2 1 2 1 1 1 1 1 2 1 0 1 0 1 1 1 2 0 2 2 2 0 1]\n",
      "kappa:\t0.060, accuracy:\t0.767\n",
      "Epoch: [79][7/9]\tTime 0.177114 (0.223)\tData 0.045\tLoss 0.0579\tAccuray 0.9883\n",
      "[2 1 2 0 1 1 0 1 2 2 1 1 1 1 1 1 2 1 1 0 2 2 1 0 1 2 2 1 0 2]\n",
      "[0 1 2 2 1 1 0 1 2 0 1 1 1 1 1 1 2 1 1 0 0 2 1 0 1 2 2 1 0 2]\n",
      "kappa:\t0.461, accuracy:\t0.867\n",
      "Epoch: [80][7/9]\tTime 0.178550 (0.214)\tData 0.035\tLoss 0.1105\tAccuray 0.9727\n",
      "[2 1 1 2 2 2 1 2 2 1 1 2 1 1 1 1 1 0 1 0 1 0 2 0 2 1 1 2 1 0]\n",
      "[2 1 1 0 0 2 1 2 2 1 1 2 1 1 1 1 1 0 1 2 1 0 2 0 2 1 1 0 1 0]\n",
      "kappa:\t0.461, accuracy:\t0.867\n",
      "Epoch: [81][7/9]\tTime 0.171932 (0.219)\tData 0.047\tLoss 0.0507\tAccuray 0.9922\n",
      "[2 1 1 1 1 1 2 0 0 2 1 1 1 2 2 1 0 1 1 0 0 2 0 2 1 1 2 1 2 1]\n",
      "[2 1 1 1 1 1 0 0 0 2 1 1 1 2 0 1 2 1 1 0 2 2 0 2 1 1 0 1 2 1]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [82][7/9]\tTime 0.175144 (0.220)\tData 0.044\tLoss 0.0513\tAccuray 0.9883\n",
      "[0 2 2 1 1 1 1 1 1 1 1 1 2 2 1 2 0 2 2 1 1 2 2 0 1 0 1 0 0 1]\n",
      "[0 2 0 1 1 1 1 1 1 1 1 1 2 2 1 0 2 2 2 1 1 2 0 0 1 0 1 0 2 1]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [83][7/9]\tTime 0.176656 (0.212)\tData 0.038\tLoss 0.0955\tAccuray 0.9766\n",
      "[2 0 0 0 1 0 1 1 1 2 2 1 2 1 2 2 1 2 1 1 1 1 0 0 1 1 1 2 1 2]\n",
      "[2 0 2 0 1 2 1 1 1 2 0 1 0 1 2 2 1 2 1 1 1 1 0 0 1 1 1 0 1 2]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [84][7/9]\tTime 0.173017 (0.217)\tData 0.043\tLoss 0.0840\tAccuray 0.9844\n",
      "[1 0 0 1 0 1 2 0 1 1 0 1 2 2 1 2 1 1 1 2 1 1 0 1 1 2 0 2 1 2]\n",
      "[1 2 0 1 2 1 0 2 1 1 0 1 2 2 1 2 1 1 1 0 1 1 0 1 1 2 0 0 1 2]\n",
      "kappa:\t0.198, accuracy:\t0.800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [85][7/9]\tTime 0.167962 (0.210)\tData 0.042\tLoss 0.0974\tAccuray 0.9805\n",
      "[0 2 0 1 1 0 2 2 1 1 1 0 2 1 1 2 1 2 1 1 1 1 1 0 1 2 2 2 1 0]\n",
      "[0 2 0 1 1 0 0 2 1 1 1 0 0 1 1 2 1 0 1 1 1 1 1 2 1 2 2 2 1 2]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [86][7/9]\tTime 0.172949 (0.209)\tData 0.039\tLoss 0.0500\tAccuray 0.9805\n",
      "[1 2 1 2 1 2 2 1 1 1 2 0 1 1 0 0 2 1 1 1 1 2 0 2 1 0 1 2 0 1]\n",
      "[1 0 1 0 1 2 0 1 1 1 2 0 1 1 0 2 2 1 1 1 1 2 2 2 1 0 1 2 0 1]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [87][7/9]\tTime 0.169591 (0.212)\tData 0.038\tLoss 0.0308\tAccuray 0.9961\n",
      "[2 2 1 2 2 0 1 1 1 1 1 1 2 0 1 0 1 0 2 2 1 2 2 1 1 1 0 1 1 2]\n",
      "[2 2 1 0 2 0 1 1 1 1 1 1 2 0 1 0 1 2 2 0 1 2 2 1 1 1 0 1 1 0]\n",
      "kappa:\t0.461, accuracy:\t0.867\n",
      "Epoch: [88][7/9]\tTime 0.167301 (0.213)\tData 0.045\tLoss 0.0334\tAccuray 0.9883\n",
      "[2 1 2 1 1 0 2 1 0 2 1 1 2 1 1 2 2 1 2 1 1 1 1 0 0 1 0 2 2 1]\n",
      "[2 1 0 1 1 2 2 1 0 0 1 1 0 1 1 2 2 1 2 1 1 1 1 0 2 1 0 0 2 1]\n",
      "kappa:\t0.191, accuracy:\t0.800\n",
      "Epoch: [89][7/9]\tTime 0.166632 (0.212)\tData 0.043\tLoss 0.0436\tAccuray 0.9922\n",
      "[1 2 1 2 1 1 0 2 1 0 2 2 1 1 1 2 2 0 2 0 1 0 1 2 1 1 1 1 1 0]\n",
      "[1 2 1 2 1 1 2 2 1 2 0 2 1 1 1 2 0 0 0 0 1 0 1 2 1 1 1 1 1 0]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [90][7/9]\tTime 0.164966 (0.205)\tData 0.036\tLoss 0.0543\tAccuray 0.9805\n",
      "[0 0 2 0 2 1 1 1 2 1 2 1 2 1 2 2 1 2 1 0 0 1 1 1 1 2 1 0 1 1]\n",
      "[0 2 2 0 0 1 1 1 0 1 2 1 2 1 2 2 1 2 1 0 0 1 1 1 1 0 1 2 1 1]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [91][7/9]\tTime 0.166364 (0.211)\tData 0.043\tLoss 0.0270\tAccuray 0.9961\n",
      "[2 2 2 1 2 1 1 1 0 1 2 0 2 0 1 1 1 2 2 1 1 1 2 1 1 2 1 0 0 1]\n",
      "[0 2 2 1 0 1 1 1 0 1 2 0 2 2 1 1 1 0 2 1 1 1 2 1 1 2 1 0 0 1]\n",
      "kappa:\t0.461, accuracy:\t0.867\n",
      "Epoch: [92][7/9]\tTime 0.167728 (0.206)\tData 0.037\tLoss 0.0202\tAccuray 0.9961\n",
      "[0 1 1 1 2 0 0 1 1 1 2 0 1 2 2 2 0 1 1 2 1 1 2 1 1 0 1 1 2 2]\n",
      "[0 1 1 1 2 2 0 1 1 1 2 0 1 2 0 2 0 1 1 2 1 1 0 1 1 2 1 1 0 2]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [93][7/9]\tTime 0.168514 (0.215)\tData 0.042\tLoss 0.0275\tAccuray 0.9922\n",
      "[1 0 0 0 0 0 1 1 1 1 2 1 2 1 0 1 2 2 2 0 1 1 2 1 2 1 1 1 1 2]\n",
      "[1 2 0 0 0 0 1 1 1 1 0 1 2 1 0 1 2 2 2 2 1 1 0 1 2 1 1 1 1 2]\n",
      "kappa:\t0.465, accuracy:\t0.867\n",
      "Epoch: [94][7/9]\tTime 0.164726 (0.208)\tData 0.038\tLoss 0.0389\tAccuray 0.9883\n",
      "[1 1 2 1 2 0 1 1 1 0 1 0 1 0 1 2 1 1 1 2 2 1 1 0 2 0 2 1 2 2]\n",
      "[1 1 2 1 0 0 1 1 1 2 1 0 1 2 1 2 1 1 1 2 2 1 1 0 2 0 0 1 0 2]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [95][7/9]\tTime 0.164973 (0.214)\tData 0.046\tLoss 0.0309\tAccuray 0.9922\n",
      "[2 2 1 2 0 1 1 1 1 0 1 0 2 0 1 0 2 1 1 2 0 1 1 2 1 2 1 1 1 0]\n",
      "[2 2 1 0 2 1 1 1 1 0 1 0 2 2 1 0 2 1 1 2 0 1 1 0 1 2 1 1 1 0]\n",
      "kappa:\t0.465, accuracy:\t0.867\n",
      "Epoch: [96][7/9]\tTime 0.162934 (0.206)\tData 0.037\tLoss 0.0243\tAccuray 0.9961\n",
      "[1 1 1 2 0 0 1 2 1 2 0 0 1 0 2 1 1 1 1 1 0 1 1 2 1 1 2 2 0 2]\n",
      "[1 1 1 2 0 2 1 0 1 0 2 0 1 0 2 1 1 1 1 1 0 1 1 2 1 1 2 2 0 2]\n",
      "kappa:\t0.465, accuracy:\t0.867\n",
      "Epoch: [97][7/9]\tTime 0.166919 (0.214)\tData 0.044\tLoss 0.0523\tAccuray 0.9844\n",
      "[1 1 0 1 1 1 1 0 2 2 2 1 0 2 1 0 0 1 0 1 2 2 1 1 0 2 1 1 2 1]\n",
      "[1 1 2 1 1 1 1 0 2 0 0 1 0 2 1 0 2 1 2 1 2 0 1 1 0 2 1 1 2 1]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [98][7/9]\tTime 0.168772 (0.206)\tData 0.036\tLoss 0.0240\tAccuray 0.9883\n",
      "[1 0 0 2 0 0 1 2 1 1 1 0 0 1 1 2 2 1 1 1 2 1 1 2 1 2 1 2 1 2]\n",
      "[1 0 2 2 0 0 1 2 1 1 1 2 0 1 1 2 0 1 1 1 0 1 1 2 1 0 1 2 1 2]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [99][7/9]\tTime 0.166111 (0.206)\tData 0.037\tLoss 0.0240\tAccuray 0.9961\n",
      "[2 2 2 2 1 1 0 1 1 1 1 2 2 1 0 0 1 1 2 0 2 1 1 1 1 1 0 1 2 2]\n",
      "[2 0 2 2 1 1 2 1 1 1 1 2 2 1 0 0 1 1 0 0 0 1 1 1 1 1 2 1 2 0]\n",
      "kappa:\t0.191, accuracy:\t0.800\n",
      "Epoch: [100][7/9]\tTime 0.167223 (0.207)\tData 0.037\tLoss 0.0307\tAccuray 0.9922\n",
      "[2 1 0 1 2 1 2 2 2 1 0 2 1 1 1 1 2 1 2 0 1 0 1 1 0 1 1 0 1 2]\n",
      "[2 1 2 1 0 1 2 2 2 1 0 0 1 1 1 1 2 1 0 2 1 0 1 1 0 1 1 0 1 2]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [101][7/9]\tTime 0.168763 (0.216)\tData 0.047\tLoss 0.0219\tAccuray 0.9961\n",
      "[1 2 0 1 2 1 0 0 2 0 1 1 0 1 2 1 1 1 1 2 1 1 0 1 1 0 0 0 1 2]\n",
      "[1 2 0 1 2 1 2 0 0 0 1 1 2 1 2 1 1 1 1 2 1 1 0 1 1 0 0 2 1 2]\n",
      "kappa:\t0.470, accuracy:\t0.867\n",
      "Epoch: [102][7/9]\tTime 0.170226 (0.214)\tData 0.044\tLoss 0.0609\tAccuray 0.9883\n",
      "[1 2 0 2 1 2 0 1 2 1 1 0 1 1 1 2 1 1 2 0 1 2 0 2 1 1 0 1 1 0]\n",
      "[1 0 0 2 1 2 0 1 2 1 1 2 1 1 1 0 1 1 2 2 1 2 0 2 1 1 0 1 1 0]\n",
      "kappa:\t0.465, accuracy:\t0.867\n",
      "Epoch: [103][7/9]\tTime 0.171102 (0.218)\tData 0.048\tLoss 0.0292\tAccuray 0.9922\n",
      "[0 1 2 2 1 2 1 0 0 1 2 2 2 1 1 1 2 1 0 1 0 0 1 1 0 0 1 1 1 1]\n",
      "[0 1 2 2 1 2 1 2 2 1 2 2 0 1 1 1 0 1 0 1 0 0 1 1 2 0 1 1 1 1]\n",
      "kappa:\t0.335, accuracy:\t0.833\n",
      "Epoch: [104][7/9]\tTime 0.164796 (0.213)\tData 0.045\tLoss 0.0195\tAccuray 1.0000\n",
      "[1 1 0 1 0 2 1 0 1 2 1 1 1 1 0 1 1 1 0 1 2 2 2 1 2 2 2 0 1 2]\n",
      "[1 1 0 1 0 2 1 0 1 2 1 1 1 1 2 1 1 1 2 1 0 2 0 1 2 2 2 0 1 0]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [105][7/9]\tTime 0.167492 (0.214)\tData 0.046\tLoss 0.0572\tAccuray 0.9844\n",
      "[2 2 1 2 1 0 1 1 2 0 2 1 1 0 0 1 2 0 1 1 0 1 1 1 0 1 1 2 0 1]\n",
      "[2 2 1 0 1 2 1 1 2 0 0 1 1 0 0 1 2 2 1 1 2 1 1 1 0 1 1 2 0 1]\n",
      "kappa:\t0.335, accuracy:\t0.833\n",
      "Epoch: [106][7/9]\tTime 0.165915 (0.213)\tData 0.045\tLoss 0.0245\tAccuray 0.9922\n",
      "[0 2 1 1 2 2 2 1 1 1 0 1 1 1 1 1 0 1 2 1 1 0 2 0 1 2 0 1 0 0]\n",
      "[0 2 1 1 2 2 2 1 1 1 0 1 1 1 1 1 0 1 2 1 1 0 0 2 1 2 0 1 2 0]\n",
      "kappa:\t0.601, accuracy:\t0.900\n",
      "Epoch: [107][7/9]\tTime 0.166901 (0.211)\tData 0.043\tLoss 0.0181\tAccuray 0.9961\n",
      "[1 1 2 0 1 1 0 1 1 2 1 2 1 1 1 1 0 0 1 0 1 0 0 0 2 1 2 2 2 1]\n",
      "[1 1 2 0 1 1 0 1 1 0 1 2 1 1 1 1 0 0 1 0 1 2 2 2 0 1 2 2 2 1]\n",
      "kappa:\t0.335, accuracy:\t0.833\n",
      "Epoch: [108][7/9]\tTime 0.165057 (0.211)\tData 0.043\tLoss 0.0489\tAccuray 0.9883\n",
      "[1 0 2 0 1 0 1 1 1 0 2 1 2 1 1 1 2 2 1 1 0 1 1 2 0 1 0 1 2 2]\n",
      "[1 0 2 0 1 2 1 1 1 0 2 1 2 1 1 1 2 0 1 1 2 1 1 2 0 1 0 1 0 2]\n",
      "kappa:\t0.465, accuracy:\t0.867\n",
      "Epoch: [109][7/9]\tTime 0.167850 (0.209)\tData 0.038\tLoss 0.0178\tAccuray 0.9961\n",
      "[0 1 1 0 1 1 1 2 2 0 0 1 1 2 0 0 2 1 1 0 1 0 2 2 1 1 1 2 1 1]\n",
      "[0 1 1 2 1 1 1 2 2 0 2 1 1 2 2 0 2 1 1 0 1 0 0 0 1 1 1 2 1 1]\n",
      "kappa:\t0.335, accuracy:\t0.833\n",
      "Epoch: [110][7/9]\tTime 0.167127 (0.210)\tData 0.042\tLoss 0.0129\tAccuray 1.0000\n",
      "[1 1 0 2 2 1 1 1 1 2 0 2 2 1 1 2 1 1 1 2 1 0 0 1 1 0 2 0 0 1]\n",
      "[1 1 0 2 0 1 1 1 1 0 2 2 2 1 1 2 1 1 1 2 1 2 0 1 1 0 2 0 0 1]\n",
      "kappa:\t0.465, accuracy:\t0.867\n",
      "Epoch: [111][7/9]\tTime 0.166679 (0.211)\tData 0.042\tLoss 0.0268\tAccuray 0.9922\n",
      "[2 0 0 1 2 1 1 1 2 2 1 0 1 2 1 0 1 1 0 2 1 1 1 1 0 0 2 0 1 1]\n",
      "[2 0 2 1 2 1 1 1 2 0 1 0 1 2 1 0 1 1 0 2 1 1 1 1 2 2 0 0 1 1]\n",
      "kappa:\t0.335, accuracy:\t0.833\n",
      "Epoch: [112][7/9]\tTime 0.166170 (0.205)\tData 0.036\tLoss 0.0104\tAccuray 1.0000\n",
      "[0 1 1 0 0 0 1 2 1 0 1 1 1 0 1 0 0 2 2 1 2 1 1 1 0 1 1 1 2 2]\n",
      "[0 1 1 0 2 2 1 0 1 0 1 1 1 2 1 0 0 2 2 1 2 1 1 1 0 1 1 1 2 2]\n",
      "kappa:\t0.470, accuracy:\t0.867\n",
      "Epoch: [113][7/9]\tTime 0.166836 (0.210)\tData 0.040\tLoss 0.0339\tAccuray 0.9961\n",
      "[1 1 2 1 2 1 1 0 1 0 1 2 1 1 2 0 1 2 1 1 1 0 2 1 1 2 0 2 0 2]\n",
      "[1 1 0 1 0 1 1 0 1 0 1 2 1 1 2 2 1 2 1 1 1 0 2 1 1 2 2 2 0 0]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [114][7/9]\tTime 0.162271 (0.207)\tData 0.036\tLoss 0.0382\tAccuray 0.9883\n",
      "[0 1 2 1 2 1 2 2 1 1 2 1 0 1 0 1 0 2 0 1 0 1 2 2 1 2 1 1 1 1]\n",
      "[0 1 2 1 2 1 0 0 1 1 0 1 0 1 2 1 0 2 0 1 2 1 2 2 1 2 1 1 1 1]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [115][7/9]\tTime 0.167094 (0.216)\tData 0.045\tLoss 0.0287\tAccuray 0.9922\n",
      "[2 2 1 1 1 1 1 1 0 2 1 1 2 0 1 1 2 0 2 2 1 2 1 2 2 1 1 0 0 1]\n",
      "[2 0 1 1 1 1 1 1 2 0 1 1 2 0 1 1 2 0 2 0 1 2 1 2 0 1 1 2 0 1]\n",
      "kappa:\t0.191, accuracy:\t0.800\n",
      "Epoch: [116][7/9]\tTime 0.167325 (0.215)\tData 0.047\tLoss 0.0267\tAccuray 0.9961\n",
      "[0 2 1 1 1 1 0 1 1 0 2 2 1 1 2 0 2 0 1 1 1 2 0 1 1 1 2 1 0 2]\n",
      "[0 2 1 1 1 1 0 1 1 0 0 2 1 1 0 0 2 0 1 1 1 2 2 1 1 1 2 1 2 2]\n",
      "kappa:\t0.465, accuracy:\t0.867\n",
      "Epoch: [117][7/9]\tTime 0.167956 (0.207)\tData 0.039\tLoss 0.0278\tAccuray 0.9961\n",
      "[1 1 1 0 2 1 0 1 2 1 1 0 2 1 0 1 2 1 2 1 0 1 1 0 2 1 2 2 2 1]\n",
      "[1 1 1 0 2 1 2 1 2 1 1 0 2 1 0 1 0 1 2 1 2 1 1 0 2 1 0 2 0 1]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [118][7/9]\tTime 0.165839 (0.213)\tData 0.045\tLoss 0.0117\tAccuray 1.0000\n",
      "[0 1 1 1 2 1 1 1 2 2 1 1 1 1 2 2 2 1 2 2 0 0 0 1 1 0 0 1 2 1]\n",
      "[0 1 1 1 0 1 1 1 0 2 1 1 1 1 2 2 2 1 2 0 2 0 0 1 1 0 2 1 2 1]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [119][7/9]\tTime 0.163224 (0.209)\tData 0.038\tLoss 0.0063\tAccuray 1.0000\n",
      "[0 0 1 1 2 2 1 1 1 0 0 1 1 2 2 2 0 2 2 1 1 1 1 0 1 2 1 1 2 1]\n",
      "[0 2 1 1 2 2 1 1 1 0 0 1 1 2 2 2 2 0 0 1 1 1 1 0 1 0 1 1 2 1]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "====> parse options\n",
      "Namespace(batch_size=32, display=8, epoch=120, fix=50, lr=0.001, model='resnet34', mom=0.9, num_workers=2, out_dir='/data/beast/df/alzheimer/out_model', phase='train', step=40, train_images='/data/beast/df/alzheimer/train.h5', train_labels='/data/beast/df/alzheimer/train.csv', val_images='/data/beast/df/alzheimer/val.h5', val_labels='/data/beast/df/alzheimer/val.csv', wd=0.0001, weight=None)\n",
      "====> building model:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][7/9]\tTime 0.164842 (0.211)\tData 0.041\tLoss 1.1167\tAccuray 0.3516\n",
      "[2 2 2 2 2 2 2 1 2 1 1 2 2 2 2 2 1 2 1 2 2 2 2 1 2 2 2 1 2 2]\n",
      "[1 0 0 2 2 2 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 0 2 1 1 2 2 1 2 2]\n",
      "kappa:\t0.013, accuracy:\t0.500\n",
      "Epoch: [1][7/9]\tTime 0.169754 (0.212)\tData 0.041\tLoss 1.0630\tAccuray 0.3789\n",
      "[1 1 1 2 1 1 1 2 1 1 2 1 2 1 1 0 1 1 1 1 2 1 2 1 1 2 1 2 1 1]\n",
      "[1 0 1 0 1 1 2 0 1 1 0 1 2 2 1 2 1 1 2 1 2 1 2 1 1 0 1 2 0 0]\n",
      "kappa:\t-0.105, accuracy:\t0.633\n",
      "Epoch: [2][7/9]\tTime 0.167748 (0.226)\tData 0.051\tLoss 1.0356\tAccuray 0.6211\n",
      "[2 2 2 2 2 2 2 2 1 2 1 2 2 2 2 1 2 2 1 1 1 2 2 2 1 2 1 1 2 1]\n",
      "[2 0 2 2 1 0 2 1 1 2 1 0 0 0 0 1 2 2 1 1 1 0 1 2 1 1 1 1 1 1]\n",
      "kappa:\t0.020, accuracy:\t0.600\n",
      "Epoch: [3][7/9]\tTime 0.166766 (0.212)\tData 0.043\tLoss 1.0101\tAccuray 0.6914\n",
      "[0 2 0 2 1 0 1 2 2 0 1 2 2 2 1 0 1 2 2 0 2 0 1 2 2 2 2 0 2 2]\n",
      "[2 1 2 0 1 2 1 1 1 2 1 0 0 2 1 0 1 1 2 1 0 2 1 2 0 1 1 1 0 1]\n",
      "kappa:\t-0.378, accuracy:\t0.333\n",
      "Epoch: [4][7/9]\tTime 0.166625 (0.206)\tData 0.034\tLoss 0.9666\tAccuray 0.7031\n",
      "[1 1 1 2 1 2 2 1 1 1 2 1 2 1 1 1 2 1 1 2 1 2 2 2 2 1 1 1 2 2]\n",
      "[1 1 1 2 1 2 2 1 0 1 2 1 2 1 1 1 2 1 1 0 1 0 2 0 0 0 1 1 0 2]\n",
      "kappa:\t0.189, accuracy:\t0.767\n",
      "\n",
      "current best accuracy is: 0.7666666666666667\n",
      "\n",
      "====> save model:\t/data/beast/df/alzheimer/out_model/alzheimer_recognition_xxx_2/alzheimer_recognition_0004_best.pth\n",
      "Epoch: [5][7/9]\tTime 0.168515 (0.207)\tData 0.044\tLoss 0.9218\tAccuray 0.7695\n",
      "[2 2 1 2 1 1 1 1 1 1 2 1 1 2 1 1 1 2 1 2 2 2 1 2 1 2 1 1 2 2]\n",
      "[2 0 1 0 0 1 1 1 0 1 2 1 1 2 1 1 1 2 1 0 0 2 1 0 1 2 1 1 2 2]\n",
      "kappa:\t0.189, accuracy:\t0.767\n",
      "Epoch: [6][7/9]\tTime 0.168857 (0.205)\tData 0.035\tLoss 0.8775\tAccuray 0.8008\n",
      "[1 2 2 2 2 1 2 2 2 1 1 1 2 2 1 2 2 2 1 2 1 2 1 1 1 1 1 2 2 1]\n",
      "[1 2 0 0 2 1 2 2 0 1 1 1 0 0 1 0 2 2 1 2 1 2 1 1 1 1 1 1 0 1]\n",
      "kappa:\t0.031, accuracy:\t0.733\n",
      "Epoch: [7][7/9]\tTime 0.169728 (0.206)\tData 0.037\tLoss 0.8331\tAccuray 0.7695\n",
      "[2 0 0 2 1 2 1 1 1 1 1 2 1 1 2 0 1 1 2 1 1 0 0 0 2 1 1 1 1 1]\n",
      "[0 2 2 0 1 0 1 1 1 1 0 2 0 1 0 2 1 1 2 1 1 2 2 0 2 1 1 1 1 1]\n",
      "kappa:\t-0.360, accuracy:\t0.633\n",
      "Epoch: [8][7/9]\tTime 0.171154 (0.219)\tData 0.047\tLoss 0.7663\tAccuray 0.8203\n",
      "[1 2 1 2 2 2 2 2 1 1 2 2 1 1 1 2 1 2 1 1 1 2 2 1 2 1 1 1 1 1]\n",
      "[0 0 1 2 0 0 2 2 1 1 2 2 1 1 1 2 1 0 1 0 1 2 0 1 2 1 1 1 1 1]\n",
      "kappa:\t0.189, accuracy:\t0.767\n",
      "Epoch: [9][7/9]\tTime 0.164677 (0.216)\tData 0.047\tLoss 0.7081\tAccuray 0.7969\n",
      "[1 0 1 2 1 1 1 0 0 1 1 0 2 2 0 2 1 2 1 0 1 2 0 1 1 1 1 1 1 1]\n",
      "[1 0 0 2 1 1 1 2 2 1 1 2 0 2 0 0 1 2 1 2 1 0 2 1 1 1 1 1 0 1]\n",
      "kappa:\t-0.211, accuracy:\t0.667\n",
      "Epoch: [10][7/9]\tTime 0.162681 (0.216)\tData 0.046\tLoss 0.6761\tAccuray 0.7656\n",
      "[1 0 2 1 0 0 1 1 0 0 2 1 0 1 1 2 1 0 0 1 1 1 1 2 1 1 1 2 1 1]\n",
      "[1 2 2 1 2 2 1 1 2 2 0 1 0 1 1 0 1 0 0 1 1 1 1 2 0 1 1 2 0 1]\n",
      "kappa:\t-0.064, accuracy:\t0.700\n",
      "Epoch: [11][7/9]\tTime 0.167908 (0.215)\tData 0.045\tLoss 0.6215\tAccuray 0.8203\n",
      "[2 1 1 2 1 1 1 1 0 1 1 2 1 0 2 1 1 1 2 1 0 0 1 1 0 1 1 2 2 0]\n",
      "[0 1 1 0 1 1 0 1 2 1 1 2 1 2 2 1 0 1 0 1 2 0 1 1 2 1 1 2 0 2]\n",
      "kappa:\t-0.360, accuracy:\t0.633\n",
      "Epoch: [12][7/9]\tTime 0.164927 (0.212)\tData 0.042\tLoss 0.5694\tAccuray 0.8555\n",
      "[2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 2 2 2 1 2 2 2 1 1 2 1 2 1 1 1]\n",
      "[0 2 2 1 0 1 1 0 1 1 2 1 1 1 1 2 0 2 1 2 0 0 1 1 2 1 2 1 0 1]\n",
      "kappa:\t0.189, accuracy:\t0.767\n",
      "Epoch: [13][7/9]\tTime 0.167271 (0.203)\tData 0.035\tLoss 0.5548\tAccuray 0.8516\n",
      "[1 2 2 1 1 1 1 2 2 2 1 1 1 2 2 2 2 1 1 1 1 1 2 1 1 1 2 1 2 2]\n",
      "[1 2 0 1 0 1 1 2 0 0 1 1 1 2 2 0 0 1 1 1 1 0 2 1 1 1 2 1 2 2]\n",
      "kappa:\t0.189, accuracy:\t0.767\n",
      "Epoch: [14][7/9]\tTime 0.169976 (0.207)\tData 0.038\tLoss 0.5170\tAccuray 0.8203\n",
      "[1 1 1 0 1 1 1 0 1 1 2 1 1 1 1 2 0 1 0 1 2 1 2 1 2 0 0 1 2 0]\n",
      "[1 1 1 2 0 1 1 2 1 1 2 1 1 1 1 0 2 1 2 1 0 1 2 0 2 0 2 1 0 0]\n",
      "kappa:\t-0.211, accuracy:\t0.667\n",
      "Epoch: [15][7/9]\tTime 0.168256 (0.212)\tData 0.043\tLoss 0.5122\tAccuray 0.8594\n",
      "[2 2 2 2 1 1 1 1 1 2 1 1 2 1 2 2 1 1 1 1 1 1 1 2 2 2 1 2 2 1]\n",
      "[2 2 2 0 0 1 1 1 1 2 1 1 2 1 0 0 1 1 1 1 1 1 1 2 2 0 0 0 2 1]\n",
      "kappa:\t0.189, accuracy:\t0.767\n",
      "Epoch: [16][7/9]\tTime 0.167133 (0.206)\tData 0.035\tLoss 0.4917\tAccuray 0.8516\n",
      "[2 1 0 1 1 1 2 2 1 1 1 0 2 0 2 1 1 0 2 1 1 2 2 2 1 1 1 1 1 1]\n",
      "[2 1 2 1 0 1 0 0 0 1 1 2 0 2 2 1 1 2 2 1 1 0 0 2 1 1 1 1 1 1]\n",
      "kappa:\t-0.373, accuracy:\t0.633\n",
      "Epoch: [17][7/9]\tTime 0.169422 (0.211)\tData 0.041\tLoss 0.4637\tAccuray 0.9023\n",
      "[2 2 2 2 1 1 2 2 2 1 1 1 2 2 1 1 2 1 1 2 2 1 1 2 1 0 1 1 2 1]\n",
      "[0 2 2 2 1 1 2 2 0 1 1 1 0 2 1 1 0 1 1 0 0 1 1 0 1 2 1 1 2 1]\n",
      "kappa:\t-0.098, accuracy:\t0.733\n",
      "Epoch: [18][7/9]\tTime 0.165179 (0.216)\tData 0.046\tLoss 0.4527\tAccuray 0.8906\n",
      "[1 0 0 0 0 1 2 2 0 1 1 1 1 2 0 2 1 2 2 1 1 1 1 0 1 1 1 1 1 1]\n",
      "[1 0 2 0 2 1 0 2 2 1 1 0 1 2 2 0 1 0 2 1 1 1 1 2 1 1 1 0 1 1]\n",
      "kappa:\t-0.211, accuracy:\t0.667\n",
      "Epoch: [19][7/9]\tTime 0.171322 (0.216)\tData 0.044\tLoss 0.4273\tAccuray 0.9297\n",
      "[2 2 2 2 2 1 2 1 2 0 2 2 2 2 1 1 1 2 2 1 1 1 2 1 1 1 1 1 2 2]\n",
      "[2 0 1 0 0 1 1 1 2 2 2 0 2 0 1 1 1 2 0 1 1 1 2 1 1 1 1 1 2 0]\n",
      "kappa:\t-0.097, accuracy:\t0.667\n",
      "Epoch: [20][7/9]\tTime 0.166095 (0.211)\tData 0.041\tLoss 0.4524\tAccuray 0.8984\n",
      "[1 2 2 1 2 2 1 1 2 1 2 0 1 1 2 1 1 1 1 2 2 2 2 1 1 1 1 1 1 2]\n",
      "[1 2 0 1 2 2 1 1 0 1 2 2 1 0 0 1 1 1 0 0 2 2 0 1 1 1 1 1 1 2]\n",
      "kappa:\t0.046, accuracy:\t0.733\n",
      "Epoch: [21][7/9]\tTime 0.165323 (0.212)\tData 0.044\tLoss 0.4084\tAccuray 0.9141\n",
      "[1 2 0 1 2 2 0 1 1 1 1 0 1 1 0 1 2 1 1 2 1 2 1 0 1 1 0 1 0 1]\n",
      "[1 0 2 0 0 0 0 1 1 0 1 0 1 1 2 1 2 1 1 2 1 2 1 2 1 1 2 1 2 1]\n",
      "kappa:\t-0.211, accuracy:\t0.667\n",
      "Epoch: [22][7/9]\tTime 0.170476 (0.205)\tData 0.035\tLoss 0.3847\tAccuray 0.9492\n",
      "[2 1 2 1 2 2 1 1 1 1 1 1 2 2 1 1 0 1 1 2 1 2 2 0 2 1 2 0 1 2]\n",
      "[0 1 0 1 2 2 1 1 1 1 1 1 2 0 1 1 2 1 1 2 1 0 2 2 0 1 0 2 1 0]\n",
      "kappa:\t-0.361, accuracy:\t0.667\n",
      "Epoch: [23][7/9]\tTime 0.170015 (0.210)\tData 0.038\tLoss 0.4056\tAccuray 0.9023\n",
      "[1 1 1 1 1 2 2 2 2 2 1 2 2 2 1 2 2 1 1 2 2 1 2 1 1 1 2 2 1 1]\n",
      "[1 1 1 1 1 0 0 2 2 2 1 0 2 2 1 2 2 1 1 0 0 1 2 1 1 1 0 0 1 1]\n",
      "kappa:\t0.034, accuracy:\t0.767\n",
      "Epoch: [24][7/9]\tTime 0.167209 (0.215)\tData 0.045\tLoss 0.3644\tAccuray 0.9414\n",
      "[2 2 2 1 2 2 1 2 1 1 1 1 0 1 2 2 1 1 0 2 1 2 2 1 0 1 1 1 1 2]\n",
      "[0 2 0 1 0 2 1 2 1 1 1 1 2 1 0 2 1 1 2 0 1 0 2 1 2 1 1 1 1 0]\n",
      "kappa:\t-0.361, accuracy:\t0.667\n",
      "Epoch: [25][7/9]\tTime 0.165478 (0.209)\tData 0.044\tLoss 0.3264\tAccuray 0.9883\n",
      "[1 1 1 0 2 1 1 1 1 2 1 0 2 2 1 1 1 1 2 2 2 0 1 2 2 2 2 2 1 1]\n",
      "[1 1 1 2 2 1 1 1 1 2 1 2 2 0 1 1 1 1 0 0 2 2 1 0 0 0 2 0 1 1]\n",
      "kappa:\t-0.361, accuracy:\t0.667\n",
      "Epoch: [26][7/9]\tTime 0.166151 (0.204)\tData 0.035\tLoss 0.2900\tAccuray 0.9766\n",
      "[2 2 1 0 2 1 2 0 1 2 1 1 1 2 0 1 1 1 1 1 1 1 2 1 2 2 2 1 2 2]\n",
      "[0 2 1 2 2 1 2 2 1 2 1 1 1 0 2 1 1 1 1 1 1 1 2 1 0 0 0 1 0 0]\n",
      "kappa:\t-0.361, accuracy:\t0.667\n",
      "Epoch: [27][7/9]\tTime 0.165797 (0.211)\tData 0.043\tLoss 0.3046\tAccuray 0.9648\n",
      "[1 2 2 1 0 2 1 2 0 1 0 1 1 1 1 1 1 1 2 0 1 1 2 2 1 2 1 1 1 0]\n",
      "[1 2 2 1 2 0 1 2 0 1 0 0 1 1 1 1 1 1 2 2 0 1 0 0 1 2 1 1 1 2]\n",
      "kappa:\t0.065, accuracy:\t0.733\n",
      "Epoch: [28][7/9]\tTime 0.168633 (0.210)\tData 0.039\tLoss 0.3019\tAccuray 0.9766\n",
      "[1 2 1 2 2 2 2 2 2 2 1 2 1 0 1 1 1 2 2 1 2 1 1 0 2 1 1 2 1 2]\n",
      "[1 0 1 2 1 0 0 2 0 0 1 2 1 2 1 1 1 2 0 1 2 1 1 2 2 1 1 0 1 1]\n",
      "kappa:\t-0.221, accuracy:\t0.633\n",
      "Epoch: [29][7/9]\tTime 0.168762 (0.210)\tData 0.039\tLoss 0.3232\tAccuray 0.9453\n",
      "[1 2 2 1 1 2 0 1 0 1 2 1 2 2 1 1 2 1 1 0 2 2 1 1 2 1 0 2 1 1]\n",
      "[1 0 2 1 1 2 0 1 2 1 0 1 0 0 1 1 0 1 1 2 2 2 1 1 0 1 2 2 1 1]\n",
      "kappa:\t-0.219, accuracy:\t0.700\n",
      "Epoch: [30][7/9]\tTime 0.169781 (0.212)\tData 0.043\tLoss 0.2611\tAccuray 0.9688\n",
      "[1 2 1 2 1 0 1 1 0 1 1 2 1 1 2 2 1 2 1 1 1 2 1 0 0 1 1 2 2 1]\n",
      "[1 2 1 0 0 2 1 1 0 0 1 0 1 1 0 2 1 2 1 1 1 2 1 2 2 1 1 2 0 1]\n",
      "kappa:\t-0.084, accuracy:\t0.700\n",
      "Epoch: [31][7/9]\tTime 0.166320 (0.207)\tData 0.039\tLoss 0.2241\tAccuray 0.9766\n",
      "[1 2 2 2 1 1 2 2 2 2 1 0 1 1 2 2 2 1 1 2 2 1 1 1 1 1 2 1 2 1]\n",
      "[1 2 0 0 1 1 2 0 2 0 1 2 1 1 2 0 0 1 1 2 0 1 1 1 1 1 2 1 2 1]\n",
      "kappa:\t-0.098, accuracy:\t0.733\n",
      "Epoch: [32][7/9]\tTime 0.162643 (0.205)\tData 0.036\tLoss 0.2008\tAccuray 0.9805\n",
      "[0 1 2 0 0 2 1 1 1 2 1 2 2 2 1 2 2 2 1 1 1 1 1 1 0 2 1 1 0 1]\n",
      "[0 1 2 0 2 0 1 1 1 0 1 0 0 2 1 2 2 2 1 1 1 1 1 1 2 0 1 1 2 1]\n",
      "kappa:\t-0.079, accuracy:\t0.733\n",
      "Epoch: [33][7/9]\tTime 0.171105 (0.213)\tData 0.045\tLoss 0.1708\tAccuray 0.9883\n",
      "[1 2 2 1 2 1 1 1 1 1 1 1 1 1 2 2 2 1 0 1 2 2 0 1 2 1 0 2 0 2]\n",
      "[1 0 2 1 0 1 1 1 1 1 1 1 1 1 2 0 2 1 2 1 2 2 2 1 0 1 0 0 2 0]\n",
      "kappa:\t-0.219, accuracy:\t0.700\n",
      "Epoch: [34][7/9]\tTime 0.169256 (0.214)\tData 0.043\tLoss 0.1850\tAccuray 0.9883\n",
      "[2 1 1 2 1 2 2 1 1 2 1 2 0 2 2 1 1 0 2 1 0 1 2 2 1 1 1 1 1 0]\n",
      "[0 1 1 0 1 0 2 1 1 2 1 0 2 0 2 1 1 0 2 1 2 1 2 0 1 1 1 1 1 2]\n",
      "kappa:\t-0.219, accuracy:\t0.700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [35][7/9]\tTime 0.167953 (0.206)\tData 0.038\tLoss 0.1949\tAccuray 0.9727\n",
      "[1 1 1 1 1 0 0 1 1 0 1 0 0 1 0 0 1 1 2 0 1 1 2 1 1 0 0 1 1 2]\n",
      "[1 1 1 1 1 2 2 1 0 0 1 2 2 1 2 0 1 1 2 0 1 1 2 0 1 2 0 1 1 0]\n",
      "kappa:\t-0.054, accuracy:\t0.700\n",
      "Epoch: [36][7/9]\tTime 0.169964 (0.215)\tData 0.044\tLoss 0.1602\tAccuray 0.9805\n",
      "[1 1 2 2 2 1 2 2 1 2 1 2 1 2 1 1 1 0 2 1 1 0 0 2 1 1 0 1 2 1]\n",
      "[1 1 0 0 2 1 2 0 1 0 1 0 1 0 1 1 1 2 2 1 1 2 0 2 1 1 2 1 2 1]\n",
      "kappa:\t-0.219, accuracy:\t0.700\n",
      "Epoch: [37][7/9]\tTime 0.167610 (0.205)\tData 0.035\tLoss 0.1246\tAccuray 0.9883\n",
      "[1 1 1 1 2 1 0 1 2 2 0 2 1 2 1 2 0 0 2 1 1 1 2 2 1 1 1 1 2 2]\n",
      "[1 1 1 1 0 1 0 1 0 0 2 2 1 2 1 0 2 2 0 1 1 1 2 2 1 1 1 1 0 2]\n",
      "kappa:\t-0.219, accuracy:\t0.700\n",
      "Epoch: [38][7/9]\tTime 0.167840 (0.210)\tData 0.041\tLoss 0.1245\tAccuray 0.9766\n",
      "[1 1 2 0 0 1 2 2 2 2 1 2 1 0 1 0 1 1 2 1 1 2 2 1 2 1 1 1 2 1]\n",
      "[1 1 0 2 2 1 0 0 2 0 1 2 1 0 1 2 1 1 0 1 1 2 2 1 2 1 1 1 0 1]\n",
      "kappa:\t-0.219, accuracy:\t0.700\n",
      "Epoch: [39][7/9]\tTime 0.164249 (0.211)\tData 0.040\tLoss 0.0923\tAccuray 0.9883\n",
      "[1 1 2 2 0 2 0 1 1 1 2 2 1 1 1 1 1 2 1 2 2 2 0 0 1 2 1 0 1 1]\n",
      "[1 1 0 2 2 2 0 1 1 1 0 2 1 1 1 1 1 2 1 2 0 0 2 0 1 2 1 0 1 1]\n",
      "kappa:\t0.191, accuracy:\t0.800\n",
      "\n",
      "current best accuracy is: 0.8\n",
      "\n",
      "====> save model:\t/data/beast/df/alzheimer/out_model/alzheimer_recognition_xxx_2/alzheimer_recognition_0039_best.pth\n",
      "Epoch: [40][7/9]\tTime 0.168710 (0.208)\tData 0.037\tLoss 0.1034\tAccuray 0.9805\n",
      "[1 0 0 1 0 1 1 0 1 1 0 2 2 2 2 1 1 2 1 1 2 2 1 1 1 1 1 2 2 2]\n",
      "[1 2 0 1 0 1 1 2 1 1 2 0 0 0 2 1 1 2 1 1 0 2 1 1 1 1 1 2 2 0]\n",
      "kappa:\t-0.079, accuracy:\t0.733\n",
      "Epoch: [41][7/9]\tTime 0.168917 (0.214)\tData 0.041\tLoss 0.1322\tAccuray 0.9883\n",
      "[1 1 2 2 1 2 0 1 2 2 1 1 1 2 2 0 2 0 2 1 1 1 2 1 2 2 1 1 1 1]\n",
      "[1 1 2 2 1 2 2 1 0 2 1 1 1 0 2 0 0 2 2 1 1 1 0 1 0 0 1 1 1 1]\n",
      "kappa:\t-0.088, accuracy:\t0.733\n",
      "Epoch: [42][7/9]\tTime 0.167202 (0.217)\tData 0.048\tLoss 0.1024\tAccuray 0.9805\n",
      "[0 1 2 2 0 1 1 2 1 2 1 1 1 1 1 2 1 2 0 1 1 1 0 2 1 0 1 0 2 0]\n",
      "[2 1 2 0 2 1 1 0 1 2 1 1 1 1 1 2 1 0 0 1 1 1 2 0 1 0 1 2 2 0]\n",
      "kappa:\t-0.069, accuracy:\t0.733\n",
      "Epoch: [43][7/9]\tTime 0.166525 (0.217)\tData 0.046\tLoss 0.1469\tAccuray 0.9609\n",
      "[1 1 2 0 1 1 0 1 1 1 0 2 2 1 2 1 1 1 2 2 1 2 1 1 1 2 1 0 2 1]\n",
      "[1 1 0 2 1 1 2 1 1 1 2 0 2 1 0 1 1 1 2 0 1 2 0 1 0 2 1 0 2 1]\n",
      "kappa:\t-0.084, accuracy:\t0.700\n",
      "Epoch: [44][7/9]\tTime 0.170639 (0.204)\tData 0.036\tLoss 0.1237\tAccuray 0.9805\n",
      "[0 1 0 1 0 1 2 2 1 0 2 1 1 1 1 0 1 1 1 2 1 2 2 1 0 1 1 2 0 2]\n",
      "[2 1 2 1 2 1 0 2 1 0 0 1 1 1 1 0 1 1 1 0 1 2 0 1 2 1 1 0 2 2]\n",
      "kappa:\t-0.336, accuracy:\t0.667\n",
      "Epoch: [45][7/9]\tTime 0.163718 (0.208)\tData 0.038\tLoss 0.0776\tAccuray 0.9922\n",
      "[1 1 2 1 2 0 2 2 1 2 1 2 1 1 1 1 1 1 1 1 1 2 1 0 1 2 0 0 2 1]\n",
      "[1 1 2 1 0 0 2 0 1 2 0 2 1 1 1 0 1 1 1 1 1 2 1 2 1 0 2 2 0 1]\n",
      "kappa:\t-0.084, accuracy:\t0.700\n",
      "Epoch: [46][7/9]\tTime 0.162486 (0.213)\tData 0.045\tLoss 0.0971\tAccuray 0.9883\n",
      "[2 0 1 0 2 2 2 1 1 0 1 1 1 1 1 0 2 0 2 1 2 2 1 2 2 2 0 1 1 1]\n",
      "[0 2 1 2 2 0 2 1 1 0 1 1 1 1 1 2 0 2 1 1 2 0 1 2 1 0 0 1 1 1]\n",
      "kappa:\t-0.200, accuracy:\t0.633\n",
      "Epoch: [47][7/9]\tTime 0.171591 (0.215)\tData 0.045\tLoss 0.1115\tAccuray 0.9805\n",
      "[2 2 1 2 1 1 1 1 1 2 1 1 1 2 0 1 0 1 2 2 1 0 0 0 1 1 2 0 1 2]\n",
      "[2 2 1 2 1 1 1 1 1 0 1 1 1 0 2 1 0 1 0 2 1 2 2 0 1 1 0 0 1 2]\n",
      "kappa:\t0.060, accuracy:\t0.767\n",
      "Epoch: [48][7/9]\tTime 0.166295 (0.214)\tData 0.045\tLoss 0.0755\tAccuray 0.9883\n",
      "[2 1 1 2 1 2 2 0 1 1 2 0 2 2 1 0 1 1 1 1 2 2 2 1 0 2 2 2 0 1]\n",
      "[0 1 1 1 1 2 1 2 1 1 2 2 0 2 1 0 1 1 1 1 0 2 2 1 1 0 0 0 2 1]\n",
      "kappa:\t-0.201, accuracy:\t0.600\n",
      "Epoch: [49][7/9]\tTime 0.165426 (0.206)\tData 0.035\tLoss 0.1408\tAccuray 0.9688\n",
      "[0 2 1 1 1 0 0 1 1 2 1 0 2 2 1 1 2 1 2 0 1 1 1 2 1 1 1 1 1 2]\n",
      "[2 0 1 1 0 2 0 1 1 0 1 0 2 2 1 1 2 1 2 2 1 1 1 0 1 1 1 0 1 2]\n",
      "kappa:\t0.065, accuracy:\t0.733\n",
      "Epoch: [50][7/9]\tTime 0.170551 (0.213)\tData 0.042\tLoss 0.1405\tAccuray 0.9688\n",
      "[2 1 1 1 1 1 2 1 2 1 2 1 0 1 1 0 1 2 0 2 1 1 1 0 1 2 1 0 1 2]\n",
      "[2 1 1 1 1 1 0 1 2 1 0 1 0 1 1 0 1 0 2 2 1 1 0 2 1 2 1 2 0 2]\n",
      "kappa:\t0.065, accuracy:\t0.733\n",
      "Epoch: [51][7/9]\tTime 0.169042 (0.215)\tData 0.045\tLoss 0.0845\tAccuray 0.9844\n",
      "[1 0 2 2 2 1 2 2 2 1 0 1 2 1 2 1 1 1 1 1 1 1 1 2 1 2 2 1 2 0]\n",
      "[1 0 0 0 0 1 2 2 2 1 2 1 0 1 2 1 1 1 1 1 1 1 1 0 1 2 0 1 2 2]\n",
      "kappa:\t-0.088, accuracy:\t0.733\n",
      "Epoch: [52][7/9]\tTime 0.169910 (0.215)\tData 0.045\tLoss 0.1192\tAccuray 0.9766\n",
      "[1 0 1 1 2 0 2 1 1 1 1 0 2 1 1 1 1 1 0 2 0 1 1 0 2 2 2 1 1 1]\n",
      "[1 2 1 1 2 2 0 1 1 1 0 0 2 1 1 1 1 1 0 2 0 1 1 2 0 2 2 1 1 0]\n",
      "kappa:\t0.212, accuracy:\t0.767\n",
      "Epoch: [53][7/9]\tTime 0.166185 (0.213)\tData 0.045\tLoss 0.1097\tAccuray 0.9766\n",
      "[2 2 2 1 0 1 2 1 0 0 1 1 1 2 1 1 2 0 0 1 1 1 2 1 1 1 1 2 2 2]\n",
      "[0 2 0 1 2 1 2 1 2 2 1 1 1 2 1 1 0 0 0 1 1 1 2 1 1 1 1 0 0 2]\n",
      "kappa:\t-0.079, accuracy:\t0.733\n",
      "Epoch: [54][7/9]\tTime 0.167093 (0.204)\tData 0.036\tLoss 0.0795\tAccuray 0.9922\n",
      "[2 1 1 2 2 1 1 0 1 0 0 1 1 1 2 1 0 2 2 1 2 0 1 1 0 2 1 1 0 1]\n",
      "[2 1 1 2 0 1 1 0 1 0 2 1 1 1 2 1 0 0 2 1 0 0 1 1 2 2 1 1 2 1]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [55][7/9]\tTime 0.170104 (0.215)\tData 0.044\tLoss 0.0640\tAccuray 0.9844\n",
      "[1 2 1 1 1 1 2 0 1 0 2 1 1 2 1 1 2 1 1 1 0 1 2 2 2 1 1 2 0 1]\n",
      "[0 2 1 1 1 0 0 0 1 2 0 1 1 2 1 1 2 1 1 1 2 1 2 0 2 1 1 2 0 1]\n",
      "kappa:\t0.205, accuracy:\t0.767\n",
      "Epoch: [56][7/9]\tTime 0.167387 (0.205)\tData 0.036\tLoss 0.0952\tAccuray 0.9688\n",
      "[1 2 0 0 1 1 2 1 1 2 1 2 1 0 1 1 1 2 2 1 0 1 1 2 1 0 2 1 0 2]\n",
      "[1 0 0 0 1 1 2 1 1 2 1 0 1 0 1 1 1 2 0 1 2 1 1 0 1 2 2 1 2 2]\n",
      "kappa:\t0.060, accuracy:\t0.767\n",
      "Epoch: [57][7/9]\tTime 0.168498 (0.211)\tData 0.043\tLoss 0.0764\tAccuray 0.9766\n",
      "[2 1 1 0 1 1 2 0 1 2 2 0 1 2 1 2 0 1 1 2 0 1 1 2 1 2 2 1 1 1]\n",
      "[2 1 1 2 1 1 2 2 1 2 0 0 1 2 1 0 0 1 1 0 2 1 1 0 1 2 0 1 1 1]\n",
      "kappa:\t-0.079, accuracy:\t0.733\n",
      "Epoch: [58][7/9]\tTime 0.170822 (0.213)\tData 0.044\tLoss 0.0742\tAccuray 0.9844\n",
      "[1 1 2 1 1 1 0 2 0 1 0 2 1 0 1 0 1 1 1 1 2 0 1 1 1 0 1 1 2 2]\n",
      "[1 1 0 1 1 1 2 0 0 1 0 2 1 2 0 2 1 1 1 1 2 0 1 1 1 2 1 0 2 2]\n",
      "kappa:\t0.074, accuracy:\t0.733\n",
      "Epoch: [59][7/9]\tTime 0.166542 (0.215)\tData 0.046\tLoss 0.0741\tAccuray 0.9883\n",
      "[1 1 1 1 2 1 1 2 0 0 1 1 1 0 1 2 1 1 0 2 2 2 1 0 2 1 1 1 1 0]\n",
      "[1 1 1 1 2 0 1 2 2 2 1 1 1 0 1 0 1 1 0 2 0 2 1 2 2 0 1 1 1 0]\n",
      "kappa:\t0.212, accuracy:\t0.767\n",
      "Epoch: [60][7/9]\tTime 0.169015 (0.213)\tData 0.044\tLoss 0.0557\tAccuray 0.9805\n",
      "[2 2 2 0 2 2 2 1 1 0 1 2 1 1 2 0 1 1 1 1 1 1 1 0 1 0 1 1 2 0]\n",
      "[2 0 0 2 2 2 0 1 1 2 1 2 1 1 0 2 1 1 1 1 1 1 1 0 1 2 1 1 0 0]\n",
      "kappa:\t-0.208, accuracy:\t0.700\n",
      "Epoch: [61][7/9]\tTime 0.161860 (0.212)\tData 0.044\tLoss 0.0423\tAccuray 0.9922\n",
      "[0 1 0 1 2 1 1 2 1 1 0 1 2 1 1 1 1 2 2 2 1 1 2 1 2 1 0 1 1 2]\n",
      "[0 1 0 1 2 0 1 2 1 1 2 0 2 1 1 1 1 0 2 2 1 1 2 1 0 1 2 1 1 0]\n",
      "kappa:\t0.205, accuracy:\t0.767\n",
      "Epoch: [62][7/9]\tTime 0.167494 (0.207)\tData 0.037\tLoss 0.0607\tAccuray 0.9766\n",
      "[2 2 0 1 2 2 1 1 2 1 1 0 2 1 1 1 1 1 2 0 1 1 2 2 0 1 0 1 1 2]\n",
      "[2 2 0 1 0 0 1 1 0 1 1 2 2 1 1 1 1 1 0 0 1 1 0 2 2 1 2 1 1 2]\n",
      "kappa:\t-0.079, accuracy:\t0.733\n",
      "Epoch: [63][7/9]\tTime 0.165493 (0.204)\tData 0.035\tLoss 0.0924\tAccuray 0.9688\n",
      "[1 0 1 2 1 1 1 1 1 0 2 2 2 1 0 1 2 2 1 1 0 1 2 0 2 2 1 1 2 1]\n",
      "[1 2 1 0 1 1 1 1 1 0 0 2 2 1 2 1 0 2 1 1 2 1 2 0 2 0 1 1 0 1]\n",
      "kappa:\t-0.079, accuracy:\t0.733\n",
      "Epoch: [64][7/9]\tTime 0.165255 (0.212)\tData 0.046\tLoss 0.0561\tAccuray 0.9883\n",
      "[2 1 1 1 2 1 1 2 1 2 0 2 1 0 1 1 2 0 0 0 2 1 1 1 1 0 1 1 2 0]\n",
      "[2 1 1 1 0 1 1 2 1 0 0 2 1 0 1 1 2 2 2 2 2 1 1 1 1 0 1 1 0 0]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [65][7/9]\tTime 0.167042 (0.215)\tData 0.045\tLoss 0.0501\tAccuray 0.9883\n",
      "[1 2 1 0 2 1 0 2 0 1 0 1 2 1 1 2 1 1 2 1 1 0 1 0 2 2 1 1 1 0]\n",
      "[1 0 1 2 0 1 2 2 0 1 0 1 0 1 1 2 1 1 2 1 1 2 1 2 0 2 1 1 1 0]\n",
      "kappa:\t-0.069, accuracy:\t0.733\n",
      "Epoch: [66][7/9]\tTime 0.165634 (0.212)\tData 0.044\tLoss 0.0566\tAccuray 0.9844\n",
      "[1 1 1 1 2 2 1 1 1 1 2 0 1 2 1 1 1 2 1 1 0 0 1 1 1 2 2 0 0 0]\n",
      "[1 1 1 1 2 2 1 1 1 1 0 0 1 2 1 1 1 0 1 1 2 0 0 1 0 2 2 2 2 0]\n",
      "kappa:\t0.212, accuracy:\t0.767\n",
      "Epoch: [67][7/9]\tTime 0.169785 (0.208)\tData 0.038\tLoss 0.0812\tAccuray 0.9727\n",
      "[1 2 2 2 2 1 1 1 2 1 0 1 0 1 1 1 1 0 1 2 1 1 2 0 1 2 0 1 0 2]\n",
      "[1 2 0 2 0 1 1 1 2 1 2 1 0 1 1 1 1 0 1 0 1 1 2 0 1 2 2 1 0 2]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "\n",
      "current best accuracy is: 0.8333333333333334\n",
      "\n",
      "====> save model:\t/data/beast/df/alzheimer/out_model/alzheimer_recognition_xxx_2/alzheimer_recognition_0067_best.pth\n",
      "Epoch: [68][7/9]\tTime 0.167617 (0.206)\tData 0.037\tLoss 0.0398\tAccuray 0.9922\n",
      "[0 0 1 2 2 1 2 0 0 1 2 0 2 1 0 1 1 1 1 1 1 2 1 1 2 1 1 2 1 2]\n",
      "[0 0 1 2 2 1 0 2 0 1 2 2 2 1 0 1 1 1 1 1 1 2 1 1 0 1 1 2 1 0]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [69][7/9]\tTime 0.168936 (0.214)\tData 0.045\tLoss 0.0421\tAccuray 0.9922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 0 0 1 2 2 2 1 0 0 0 1 0 2 1 1 1 1 1 1 1 1 0 1 1 2 2 1 1]\n",
      "[0 2 2 0 1 2 2 0 1 0 0 2 1 2 2 1 1 1 1 1 1 1 1 0 1 1 0 2 1 1]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [70][7/9]\tTime 0.170141 (0.214)\tData 0.045\tLoss 0.0498\tAccuray 0.9883\n",
      "[0 1 0 0 1 1 1 0 2 2 1 1 1 2 1 2 1 1 2 1 0 1 2 1 1 2 0 0 0 1]\n",
      "[0 1 0 0 1 1 1 0 0 0 1 1 1 2 1 0 1 1 2 1 2 1 2 1 1 2 2 2 2 1]\n",
      "kappa:\t0.069, accuracy:\t0.767\n",
      "Epoch: [71][7/9]\tTime 0.167967 (0.212)\tData 0.043\tLoss 0.0679\tAccuray 0.9844\n",
      "[2 1 1 2 2 0 1 1 1 0 1 1 1 0 1 1 0 2 0 1 1 2 1 0 1 2 2 1 1 2]\n",
      "[0 1 1 2 2 2 1 1 1 0 1 0 1 2 1 1 2 0 0 1 1 2 1 0 1 2 2 1 1 0]\n",
      "kappa:\t0.134, accuracy:\t0.767\n",
      "Epoch: [72][7/9]\tTime 0.165783 (0.205)\tData 0.035\tLoss 0.0626\tAccuray 0.9844\n",
      "[2 1 1 0 0 2 1 1 2 1 1 0 1 2 2 2 1 0 1 1 2 1 1 0 0 1 0 2 1 1]\n",
      "[2 1 1 0 2 2 1 1 2 1 1 2 1 2 0 0 1 0 1 1 2 1 1 2 0 1 0 0 1 1]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [73][7/9]\tTime 0.168667 (0.221)\tData 0.050\tLoss 0.0524\tAccuray 0.9922\n",
      "[1 0 0 1 2 1 0 1 2 2 2 2 2 1 1 1 2 1 2 0 1 1 0 1 1 1 0 1 2 1]\n",
      "[1 0 0 1 0 1 0 1 2 2 0 2 2 1 1 1 2 1 0 2 1 1 2 1 1 1 2 1 0 1]\n",
      "kappa:\t0.060, accuracy:\t0.767\n",
      "Epoch: [74][7/9]\tTime 0.166402 (0.206)\tData 0.036\tLoss 0.0439\tAccuray 0.9883\n",
      "[1 1 0 1 0 2 1 2 1 1 0 1 2 2 1 2 1 2 0 0 1 1 1 1 1 2 2 0 2 1]\n",
      "[1 1 0 1 0 0 1 2 1 1 2 1 2 2 1 2 1 0 2 2 1 1 1 1 1 0 2 0 0 1]\n",
      "kappa:\t0.060, accuracy:\t0.767\n",
      "Epoch: [75][7/9]\tTime 0.164345 (0.210)\tData 0.042\tLoss 0.0605\tAccuray 0.9922\n",
      "[0 1 1 1 1 0 0 2 1 2 0 2 1 1 2 0 1 1 1 0 0 1 0 2 1 1 1 2 1 2]\n",
      "[0 1 1 1 1 2 0 2 1 2 2 2 1 1 2 0 1 1 1 2 2 1 0 0 1 1 1 0 1 0]\n",
      "kappa:\t0.069, accuracy:\t0.767\n",
      "Epoch: [76][7/9]\tTime 0.164816 (0.215)\tData 0.047\tLoss 0.0616\tAccuray 0.9922\n",
      "[0 2 1 2 1 1 2 1 1 0 1 1 2 1 1 2 0 1 1 2 2 1 1 2 0 1 1 2 0 2]\n",
      "[0 2 1 0 1 1 2 1 1 2 1 1 2 1 1 2 0 1 1 0 0 1 1 0 0 1 1 2 2 2]\n",
      "kappa:\t0.191, accuracy:\t0.800\n",
      "Epoch: [77][7/9]\tTime 0.170130 (0.208)\tData 0.036\tLoss 0.0575\tAccuray 0.9844\n",
      "[2 2 2 1 2 1 0 1 2 2 1 1 1 1 0 1 2 0 1 2 1 0 1 2 1 1 1 2 1 0]\n",
      "[0 0 2 1 2 1 2 1 0 2 1 1 1 1 0 1 0 0 1 2 1 2 1 2 1 1 1 0 1 2]\n",
      "kappa:\t-0.079, accuracy:\t0.733\n",
      "Epoch: [78][7/9]\tTime 0.166496 (0.211)\tData 0.042\tLoss 0.0922\tAccuray 0.9844\n",
      "[2 2 2 2 0 1 1 0 0 1 1 1 2 1 2 1 2 1 0 1 1 1 0 1 1 0 2 1 1 2]\n",
      "[2 2 2 0 2 1 1 0 0 1 1 1 0 1 0 1 2 1 0 1 1 1 2 1 1 0 2 1 1 2]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [79][7/9]\tTime 0.168832 (0.210)\tData 0.039\tLoss 0.0982\tAccuray 0.9844\n",
      "[1 0 2 1 0 2 1 2 2 1 0 1 1 1 0 1 1 1 1 1 0 2 2 2 1 0 1 0 2 1]\n",
      "[1 2 2 1 0 0 1 0 2 1 2 1 1 1 2 1 1 1 1 1 0 2 2 0 1 0 1 2 0 1]\n",
      "kappa:\t-0.069, accuracy:\t0.733\n",
      "Epoch: [80][7/9]\tTime 0.169780 (0.207)\tData 0.037\tLoss 0.0659\tAccuray 0.9766\n",
      "[2 1 1 2 1 2 1 0 1 1 1 1 0 1 2 2 1 2 1 1 1 0 2 1 0 2 0 2 1 2]\n",
      "[2 1 1 2 1 2 1 2 1 1 1 1 2 1 0 2 1 2 1 1 1 0 0 1 0 2 0 0 1 0]\n",
      "kappa:\t0.191, accuracy:\t0.800\n",
      "Epoch: [81][7/9]\tTime 0.165947 (0.215)\tData 0.046\tLoss 0.0456\tAccuray 0.9922\n",
      "[2 1 0 2 1 0 1 1 0 1 1 2 2 2 1 0 1 1 1 0 2 1 1 2 1 0 2 2 1 1]\n",
      "[2 1 2 0 1 0 1 1 0 1 1 0 0 0 1 0 1 1 1 2 2 1 1 2 1 2 2 2 1 1]\n",
      "kappa:\t0.060, accuracy:\t0.767\n",
      "Epoch: [82][7/9]\tTime 0.168624 (0.209)\tData 0.038\tLoss 0.0525\tAccuray 0.9805\n",
      "[0 2 1 2 1 1 0 0 1 0 2 0 0 1 1 1 1 1 0 1 2 2 2 1 0 1 1 1 2 1]\n",
      "[0 2 1 2 1 1 2 0 1 0 0 0 0 1 1 1 1 1 2 1 2 0 2 1 2 1 1 1 2 1]\n",
      "kappa:\t0.335, accuracy:\t0.833\n",
      "Epoch: [83][7/9]\tTime 0.170588 (0.214)\tData 0.044\tLoss 0.0523\tAccuray 0.9883\n",
      "[2 2 1 1 1 2 2 2 0 1 2 1 1 1 0 1 2 1 1 2 1 1 2 1 1 1 1 0 0 1]\n",
      "[0 2 1 1 1 2 2 2 2 1 2 1 1 1 0 1 0 1 0 2 1 1 2 1 1 0 1 0 0 1]\n",
      "kappa:\t0.494, accuracy:\t0.833\n",
      "Epoch: [84][7/9]\tTime 0.165661 (0.212)\tData 0.044\tLoss 0.0509\tAccuray 0.9844\n",
      "[1 2 1 0 1 0 2 1 1 1 1 0 2 1 2 1 1 2 2 1 1 1 1 2 1 2 0 1 0 1]\n",
      "[1 0 1 0 0 2 2 1 1 1 1 2 2 0 2 1 1 0 2 1 1 1 1 2 1 0 2 1 0 1]\n",
      "kappa:\t0.065, accuracy:\t0.733\n",
      "Epoch: [85][7/9]\tTime 0.164051 (0.210)\tData 0.043\tLoss 0.0397\tAccuray 0.9844\n",
      "[2 1 1 1 2 0 0 1 1 1 2 1 2 2 2 1 2 1 1 0 2 1 0 0 1 0 0 1 1 1]\n",
      "[2 1 1 1 0 0 0 1 1 1 2 1 2 0 2 1 0 1 1 0 2 1 2 2 1 2 0 1 1 1]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [86][7/9]\tTime 0.166159 (0.211)\tData 0.043\tLoss 0.0319\tAccuray 0.9922\n",
      "[2 1 1 2 1 0 1 2 2 1 1 1 2 2 1 2 1 2 1 0 1 2 2 0 0 1 1 1 1 2]\n",
      "[2 1 1 2 1 0 1 0 2 1 1 1 2 2 1 2 1 0 1 2 1 2 0 0 0 1 1 1 1 0]\n",
      "kappa:\t0.323, accuracy:\t0.833\n",
      "Epoch: [87][7/9]\tTime 0.170002 (0.207)\tData 0.037\tLoss 0.0261\tAccuray 0.9961\n",
      "[1 1 2 2 1 1 1 0 1 1 2 2 0 1 2 2 0 2 1 2 1 1 1 1 1 1 0 1 2 1]\n",
      "[0 1 2 0 1 1 1 2 1 1 2 0 0 1 2 2 2 2 1 2 1 1 0 1 1 1 0 1 0 1]\n",
      "kappa:\t0.205, accuracy:\t0.767\n",
      "Epoch: [88][7/9]\tTime 0.165045 (0.217)\tData 0.049\tLoss 0.0336\tAccuray 0.9883\n",
      "[0 1 1 1 2 2 2 1 1 0 0 1 1 1 1 2 2 2 1 2 1 0 1 1 2 1 2 1 0 2]\n",
      "[0 1 1 1 2 0 2 1 1 0 0 1 1 1 1 0 2 2 1 2 1 0 1 1 2 1 2 1 2 0]\n",
      "kappa:\t0.461, accuracy:\t0.867\n",
      "\n",
      "current best accuracy is: 0.8666666666666667\n",
      "\n",
      "====> save model:\t/data/beast/df/alzheimer/out_model/alzheimer_recognition_xxx_2/alzheimer_recognition_0088_best.pth\n",
      "Epoch: [89][7/9]\tTime 0.169736 (0.208)\tData 0.036\tLoss 0.0222\tAccuray 0.9961\n",
      "[1 2 2 0 0 1 1 2 1 1 0 1 1 1 0 2 2 1 1 2 1 1 1 0 1 2 2 0 1 0]\n",
      "[1 2 2 2 0 1 1 0 1 1 0 1 1 1 0 2 0 1 1 0 1 1 1 0 1 2 2 2 1 2]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [90][7/9]\tTime 0.163843 (0.213)\tData 0.046\tLoss 0.0372\tAccuray 0.9844\n",
      "[1 2 2 2 1 1 1 1 0 1 1 1 2 2 1 1 0 1 0 2 0 2 2 1 2 2 1 1 1 2]\n",
      "[1 2 0 2 1 1 1 1 0 1 1 1 2 2 1 1 2 1 0 0 0 0 2 1 0 2 1 1 1 2]\n",
      "kappa:\t0.323, accuracy:\t0.833\n",
      "Epoch: [91][7/9]\tTime 0.166290 (0.205)\tData 0.036\tLoss 0.0402\tAccuray 0.9883\n",
      "[0 1 1 1 1 2 2 2 1 1 2 1 1 2 0 1 1 1 2 1 2 1 1 2 2 0 2 2 0 1]\n",
      "[0 1 1 1 1 0 0 2 1 1 2 1 1 2 0 1 1 1 2 1 2 1 1 2 0 0 0 2 2 1]\n",
      "kappa:\t0.323, accuracy:\t0.833\n",
      "Epoch: [92][7/9]\tTime 0.165792 (0.211)\tData 0.044\tLoss 0.0535\tAccuray 0.9922\n",
      "[2 1 1 1 1 0 1 1 1 0 1 0 1 2 1 1 1 2 0 2 0 1 1 1 2 2 0 1 1 2]\n",
      "[2 1 1 1 1 0 0 0 1 0 1 0 1 0 1 1 1 2 2 2 2 1 1 1 0 2 2 1 1 2]\n",
      "kappa:\t0.212, accuracy:\t0.767\n",
      "Epoch: [93][7/9]\tTime 0.170143 (0.215)\tData 0.045\tLoss 0.0504\tAccuray 0.9922\n",
      "[1 1 2 1 0 1 2 0 1 1 1 0 1 2 0 2 1 1 1 2 2 1 1 1 2 2 2 0 2 1]\n",
      "[1 1 0 1 2 1 0 0 1 1 1 2 1 0 0 2 1 1 1 2 2 1 1 1 0 2 2 0 2 1]\n",
      "kappa:\t0.191, accuracy:\t0.800\n",
      "Epoch: [94][7/9]\tTime 0.167466 (0.211)\tData 0.043\tLoss 0.1052\tAccuray 0.9727\n",
      "[2 1 2 0 1 2 0 2 1 0 0 0 1 2 1 1 0 1 1 1 1 1 2 1 2 1 1 2 1 0]\n",
      "[0 1 0 2 1 0 2 2 1 2 0 2 1 2 1 1 2 1 1 1 1 1 2 1 0 1 1 0 1 0]\n",
      "kappa:\t-0.336, accuracy:\t0.667\n",
      "Epoch: [95][7/9]\tTime 0.165964 (0.210)\tData 0.043\tLoss 0.0974\tAccuray 0.9805\n",
      "[2 1 1 0 1 2 0 1 2 0 1 1 1 1 0 1 0 0 1 1 0 1 1 2 1 1 0 2 2 0]\n",
      "[2 1 1 2 1 0 0 1 0 2 1 1 1 1 2 1 2 0 1 1 0 1 1 0 1 1 2 0 2 2]\n",
      "kappa:\t-0.325, accuracy:\t0.667\n",
      "Epoch: [96][7/9]\tTime 0.168385 (0.214)\tData 0.044\tLoss 0.0513\tAccuray 0.9922\n",
      "[2 1 1 2 0 0 1 2 2 0 1 2 0 1 1 0 2 1 1 2 1 1 0 1 1 2 1 2 1 1]\n",
      "[0 1 1 0 0 0 1 2 0 2 1 2 2 1 1 2 2 1 1 0 1 1 2 1 1 2 1 0 1 1]\n",
      "kappa:\t-0.208, accuracy:\t0.700\n",
      "Epoch: [97][7/9]\tTime 0.165734 (0.210)\tData 0.044\tLoss 0.0685\tAccuray 0.9805\n",
      "[0 0 0 1 2 0 2 1 1 2 1 1 0 1 2 2 1 1 0 1 2 1 1 1 1 1 2 2 2 1]\n",
      "[2 2 0 1 2 2 2 1 1 0 1 1 0 1 0 2 1 1 2 1 0 1 1 1 1 1 0 2 0 1]\n",
      "kappa:\t-0.208, accuracy:\t0.700\n",
      "Epoch: [98][7/9]\tTime 0.165752 (0.205)\tData 0.036\tLoss 0.0957\tAccuray 0.9883\n",
      "[1 1 1 2 0 1 1 0 2 2 1 2 1 1 0 2 2 2 2 1 1 2 2 1 2 1 2 1 1 1]\n",
      "[1 1 1 2 0 1 1 2 2 2 1 0 1 1 2 0 0 0 0 1 1 0 2 1 2 1 2 1 1 1]\n",
      "kappa:\t-0.088, accuracy:\t0.733\n",
      "Epoch: [99][7/9]\tTime 0.169352 (0.218)\tData 0.046\tLoss 0.0478\tAccuray 0.9922\n",
      "[0 1 2 0 0 1 1 2 1 2 1 2 1 1 2 1 2 1 1 1 2 0 0 1 0 1 0 2 1 1]\n",
      "[0 1 0 2 2 1 1 2 1 0 1 2 1 1 2 1 0 1 1 1 0 2 0 1 0 1 2 2 1 1]\n",
      "kappa:\t-0.069, accuracy:\t0.733\n",
      "Epoch: [100][7/9]\tTime 0.166963 (0.216)\tData 0.045\tLoss 0.0677\tAccuray 0.9844\n",
      "[1 0 1 1 2 1 0 1 0 1 1 1 1 2 2 1 0 2 2 0 1 2 0 0 2 1 1 0 1 1]\n",
      "[1 2 1 1 2 1 2 1 2 1 1 1 1 0 2 1 0 0 0 0 1 2 0 0 2 1 1 2 1 1]\n",
      "kappa:\t0.069, accuracy:\t0.767\n",
      "Epoch: [101][7/9]\tTime 0.168742 (0.212)\tData 0.042\tLoss 0.0398\tAccuray 0.9844\n",
      "[1 0 1 2 0 2 0 1 1 1 1 0 2 1 2 0 1 2 1 1 2 1 1 0 1 1 0 2 2 1]\n",
      "[1 0 1 2 0 0 0 1 1 1 1 2 2 1 0 2 1 2 1 1 2 1 1 0 1 1 0 2 2 1]\n",
      "kappa:\t0.465, accuracy:\t0.867\n",
      "Epoch: [102][7/9]\tTime 0.167341 (0.212)\tData 0.044\tLoss 0.0340\tAccuray 0.9961\n",
      "[2 1 0 1 2 1 0 1 2 1 2 2 1 2 1 2 1 2 1 1 1 1 2 2 1 0 0 0 1 1]\n",
      "[2 1 0 1 0 1 2 1 2 1 0 0 1 2 1 2 1 2 1 1 1 1 2 0 1 2 0 0 1 1]\n",
      "kappa:\t0.191, accuracy:\t0.800\n",
      "Epoch: [103][7/9]\tTime 0.164126 (0.218)\tData 0.049\tLoss 0.1130\tAccuray 0.9688\n",
      "[1 0 1 1 0 1 1 1 2 1 1 1 0 2 1 2 1 1 2 0 1 1 2 1 0 0 2 0 0 0]\n",
      "[1 2 1 1 0 1 1 1 2 1 1 1 0 2 1 2 1 1 2 2 1 1 0 1 0 0 0 2 0 2]\n",
      "kappa:\t0.205, accuracy:\t0.800\n",
      "Epoch: [104][7/9]\tTime 0.164321 (0.204)\tData 0.035\tLoss 0.1009\tAccuray 0.9883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 1 2 2 2 1 1 1 1 1 1 1 0 0 1 2 2 1 2 1 0 0 0 2 1 1 1 2 1]\n",
      "[0 2 1 0 2 2 1 1 1 1 1 1 1 0 0 1 2 2 1 0 1 0 2 2 2 1 1 1 0 1]\n",
      "kappa:\t0.191, accuracy:\t0.800\n",
      "Epoch: [105][7/9]\tTime 0.167713 (0.213)\tData 0.043\tLoss 0.0732\tAccuray 0.9805\n",
      "[1 2 0 1 1 1 2 1 2 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 1 1 1 2 2 2]\n",
      "[1 2 0 1 1 1 2 1 0 0 0 2 0 1 1 2 0 1 2 1 1 1 2 1 1 1 1 2 2 0]\n",
      "kappa:\t0.205, accuracy:\t0.800\n",
      "Epoch: [106][7/9]\tTime 0.167312 (0.213)\tData 0.043\tLoss 0.0608\tAccuray 0.9844\n",
      "[1 0 2 1 2 0 1 1 0 1 2 0 1 1 1 1 1 1 0 0 1 2 2 1 2 1 0 1 2 2]\n",
      "[1 2 0 1 2 0 1 1 2 1 2 0 1 1 1 1 1 1 2 0 1 0 2 1 2 1 0 1 0 2]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [107][7/9]\tTime 0.169176 (0.208)\tData 0.037\tLoss 0.0513\tAccuray 0.9883\n",
      "[0 1 2 0 2 1 1 2 1 1 0 1 0 1 2 2 0 1 1 1 2 1 1 1 1 0 0 0 1 2]\n",
      "[0 1 2 0 2 1 1 2 1 1 2 1 0 1 2 2 2 1 1 1 0 1 1 1 1 0 2 0 1 0]\n",
      "kappa:\t0.335, accuracy:\t0.833\n",
      "Epoch: [108][7/9]\tTime 0.167517 (0.210)\tData 0.043\tLoss 0.0420\tAccuray 0.9883\n",
      "[2 2 0 0 1 1 2 1 1 1 2 0 1 1 1 2 1 2 0 0 0 1 2 2 1 1 1 0 1 1]\n",
      "[2 0 2 0 1 1 2 1 1 1 2 0 1 1 1 0 1 2 0 2 0 1 0 2 1 1 1 2 1 1]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [109][7/9]\tTime 0.166933 (0.216)\tData 0.048\tLoss 0.0298\tAccuray 0.9922\n",
      "[0 1 0 1 1 1 2 0 0 1 1 1 2 2 2 2 1 1 0 1 0 0 2 1 1 1 2 2 1 1]\n",
      "[2 1 0 1 1 1 0 0 2 1 1 1 0 2 2 2 1 1 2 1 0 2 2 1 1 1 0 0 1 1]\n",
      "kappa:\t-0.069, accuracy:\t0.733\n",
      "Epoch: [110][7/9]\tTime 0.171933 (0.215)\tData 0.045\tLoss 0.0589\tAccuray 0.9883\n",
      "[0 2 1 0 2 1 2 0 1 1 1 1 0 2 1 0 1 1 0 1 1 0 1 2 1 2 2 2 1 1]\n",
      "[2 2 1 0 0 1 0 2 1 1 1 1 2 2 1 0 1 1 2 1 1 0 1 2 1 0 0 2 1 1]\n",
      "kappa:\t-0.069, accuracy:\t0.733\n",
      "Epoch: [111][7/9]\tTime 0.169578 (0.213)\tData 0.039\tLoss 0.0519\tAccuray 0.9883\n",
      "[2 1 1 1 0 2 2 2 1 0 2 1 2 1 0 2 1 1 1 0 1 1 0 1 1 0 1 0 2 1]\n",
      "[2 1 1 1 2 2 2 2 1 0 0 1 0 1 2 0 1 1 1 0 1 1 0 1 1 2 1 0 2 1]\n",
      "kappa:\t0.198, accuracy:\t0.800\n",
      "Epoch: [112][7/9]\tTime 0.168502 (0.218)\tData 0.048\tLoss 0.0325\tAccuray 0.9961\n",
      "[0 1 0 1 0 1 1 1 1 2 1 0 1 2 1 1 2 1 0 2 1 1 0 0 2 2 2 2 1 1]\n",
      "[0 1 2 1 0 1 1 1 1 2 1 0 1 2 1 1 0 1 0 2 1 1 0 2 2 2 0 2 1 1]\n",
      "kappa:\t0.465, accuracy:\t0.867\n",
      "Epoch: [113][7/9]\tTime 0.167564 (0.206)\tData 0.036\tLoss 0.0329\tAccuray 0.9922\n",
      "[0 2 1 2 1 0 1 2 2 2 1 0 1 2 1 1 1 1 1 0 0 1 0 2 1 2 1 1 1 2]\n",
      "[2 2 1 2 1 2 1 2 0 2 1 0 1 2 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 2]\n",
      "kappa:\t0.329, accuracy:\t0.833\n",
      "Epoch: [114][7/9]\tTime 0.164570 (0.216)\tData 0.047\tLoss 0.0399\tAccuray 0.9805\n",
      "[2 0 2 0 0 1 2 1 1 1 2 1 0 0 2 1 1 2 1 0 1 1 1 1 1 1 2 0 0 1]\n",
      "[2 2 0 0 2 1 2 1 1 1 2 1 0 0 0 1 1 2 1 0 1 1 1 1 1 1 2 0 2 1]\n",
      "kappa:\t0.335, accuracy:\t0.833\n",
      "Epoch: [115][7/9]\tTime 0.162639 (0.205)\tData 0.036\tLoss 0.0224\tAccuray 0.9922\n",
      "[1 1 0 0 1 1 1 1 2 1 2 2 0 2 2 1 1 1 1 1 0 1 2 1 0 0 0 1 0 2]\n",
      "[1 1 0 2 1 1 1 1 0 1 2 2 0 2 0 1 1 1 1 1 2 1 2 1 0 0 2 1 0 2]\n",
      "kappa:\t0.335, accuracy:\t0.833\n",
      "Epoch: [116][7/9]\tTime 0.169433 (0.215)\tData 0.045\tLoss 0.0339\tAccuray 0.9883\n",
      "[1 1 1 2 2 1 2 1 0 2 1 0 2 0 0 2 2 1 0 0 1 1 1 2 1 1 2 1 1 1]\n",
      "[1 1 1 2 2 1 2 1 0 2 1 0 0 2 2 0 2 1 0 2 1 1 1 0 1 1 0 1 1 1]\n",
      "kappa:\t0.060, accuracy:\t0.767\n",
      "Epoch: [117][7/9]\tTime 0.165153 (0.206)\tData 0.036\tLoss 0.0208\tAccuray 0.9961\n",
      "[2 1 2 0 1 1 1 2 1 1 2 2 1 0 1 2 1 1 0 2 1 0 2 1 1 1 0 2 1 2]\n",
      "[2 1 2 0 1 1 1 2 1 1 0 2 1 2 1 2 1 1 0 2 1 0 0 1 1 1 0 2 1 0]\n",
      "kappa:\t0.461, accuracy:\t0.867\n",
      "Epoch: [118][7/9]\tTime 0.165695 (0.209)\tData 0.039\tLoss 0.0528\tAccuray 0.9883\n",
      "[1 0 1 1 1 0 2 2 0 0 0 1 1 1 2 0 1 2 1 2 0 1 1 1 1 0 1 0 1 0]\n",
      "[1 0 1 1 1 0 2 0 2 2 0 1 1 1 2 2 1 2 1 0 0 1 1 1 1 2 1 2 1 0]\n",
      "kappa:\t0.077, accuracy:\t0.767\n",
      "Epoch: [119][7/9]\tTime 0.165442 (0.217)\tData 0.048\tLoss 0.0262\tAccuray 0.9922\n",
      "[0 1 1 2 1 0 1 2 1 0 1 1 1 0 1 1 2 2 1 1 0 2 1 1 2 0 0 2 1 0]\n",
      "[0 1 1 2 1 2 1 0 1 2 1 1 1 0 1 1 2 0 1 1 0 2 1 1 2 0 0 2 1 2]\n",
      "kappa:\t0.335, accuracy:\t0.833\n",
      "====> parse options\n",
      "Namespace(batch_size=32, display=8, epoch=120, fix=50, lr=0.001, model='resnet34', mom=0.9, num_workers=2, out_dir='/data/beast/df/alzheimer/out_model', phase='train', step=40, train_images='/data/beast/df/alzheimer/train.h5', train_labels='/data/beast/df/alzheimer/train.csv', val_images='/data/beast/df/alzheimer/val.h5', val_labels='/data/beast/df/alzheimer/val.csv', wd=0.0001, weight=None)\n",
      "====> building model:\n",
      "Epoch: [0][7/9]\tTime 0.167080 (0.211)\tData 0.043\tLoss 1.1089\tAccuray 0.3789\n",
      "[2 2 0 2 1 2 1 2 1 0 2 2 1 2 1 0 2 1 2 2 2 2 2 2 2 2 2 1 1 1]\n",
      "[1 1 0 2 1 0 1 2 1 2 1 0 1 2 1 2 0 1 0 1 2 0 2 1 0 1 2 1 1 1]\n",
      "kappa:\t-0.086, accuracy:\t0.533\n",
      "Epoch: [1][7/9]\tTime 0.169653 (0.213)\tData 0.043\tLoss 1.0597\tAccuray 0.4375\n",
      "[1 0 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1 0 1 0 2 0 2 1 1 0 0 2 1 1 1 2 1 1 1 1 0 2 2 0 1 2 1 2 1 1]\n",
      "kappa:\t0.235, accuracy:\t0.567\n",
      "Epoch: [2][7/9]\tTime 0.164943 (0.225)\tData 0.050\tLoss 1.0261\tAccuray 0.5742\n",
      "[1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1]\n",
      "[1 1 2 2 0 1 0 2 1 2 1 2 1 0 1 1 1 0 1 1 0 0 2 0 1 1 2 2 1 1]\n",
      "kappa:\t-0.355, accuracy:\t0.533\n",
      "Epoch: [3][7/9]\tTime 0.165194 (0.213)\tData 0.045\tLoss 0.9905\tAccuray 0.6875\n",
      "[2 2 2 2 1 2 2 1 2 2 2 2 2 2 2 1 1 1 1 1 1 2 1 2 2 2 2 2 2 1]\n",
      "[0 2 0 0 1 0 2 1 1 2 0 2 1 0 2 1 1 1 1 1 1 1 1 1 1 2 2 0 2 1]\n",
      "kappa:\t0.020, accuracy:\t0.600\n",
      "Epoch: [4][7/9]\tTime 0.168258 (0.210)\tData 0.042\tLoss 0.9454\tAccuray 0.6758\n",
      "[0 0 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 0 0 1 0 1 0 1 1 1 0 0]\n",
      "[0 2 1 2 1 0 1 1 1 1 1 1 2 2 0 1 2 1 1 2 2 1 2 0 0 1 1 1 0 0]\n",
      "kappa:\t-0.102, accuracy:\t0.700\n",
      "Epoch: [5][7/9]\tTime 0.166920 (0.208)\tData 0.035\tLoss 0.9183\tAccuray 0.6875\n",
      "[1 1 1 1 2 2 1 1 1 2 1 2 2 1 2 2 2 1 2 1 2 1 2 1 2 1 2 2 2 1]\n",
      "[1 1 1 1 0 2 1 1 1 2 1 0 2 1 0 2 2 1 0 1 0 1 2 1 0 1 0 2 2 1]\n",
      "kappa:\t0.034, accuracy:\t0.767\n",
      "\n",
      "current best accuracy is: 0.7666666666666667\n",
      "\n",
      "====> save model:\t/data/beast/df/alzheimer/out_model/alzheimer_recognition_xxx_3/alzheimer_recognition_0005_best.pth\n",
      "Epoch: [6][7/9]\tTime 0.165446 (0.211)\tData 0.044\tLoss 0.8471\tAccuray 0.7852\n",
      "[1 1 1 1 2 1 2 1 1 1 1 2 1 2 2 1 2 2 2 2 2 1 2 2 1 2 1 2 1 2]\n",
      "[1 1 1 1 2 1 0 1 1 1 1 2 1 0 0 1 2 0 2 2 2 1 2 0 1 0 1 0 1 2]\n",
      "kappa:\t0.034, accuracy:\t0.767\n",
      "Epoch: [7][7/9]\tTime 0.168221 (0.210)\tData 0.038\tLoss 0.8024\tAccuray 0.7656\n",
      "[2 2 1 2 1 2 2 2 1 2 2 1 1 1 2 2 1 2 1 1 1 2 1 1 1 1 1 2 2 2]\n",
      "[2 0 1 2 1 0 0 0 1 2 2 1 1 1 0 2 1 0 1 1 1 2 1 1 1 1 1 2 0 2]\n",
      "kappa:\t0.034, accuracy:\t0.767\n",
      "Epoch: [8][7/9]\tTime 0.170939 (0.218)\tData 0.047\tLoss 0.7537\tAccuray 0.8008\n",
      "[1 2 1 2 1 1 2 2 1 2 1 1 1 1 2 1 1 1 2 2 1 2 2 1 2 2 2 2 1 2]\n",
      "[1 2 1 0 1 1 0 2 1 0 1 1 1 1 0 1 1 1 2 0 1 0 2 1 2 2 2 0 1 2]\n",
      "kappa:\t0.034, accuracy:\t0.767\n",
      "Epoch: [9][7/9]\tTime 0.163638 (0.210)\tData 0.039\tLoss 0.6867\tAccuray 0.8008\n",
      "[2 2 1 1 1 2 1 2 1 0 2 1 2 2 0 1 2 0 1 1 1 2 1 2 1 2 1 1 1 2]\n",
      "[0 0 1 1 1 0 1 2 1 2 2 1 2 0 2 1 2 0 1 1 1 0 1 2 1 2 1 1 1 0]\n",
      "kappa:\t-0.088, accuracy:\t0.733\n",
      "Epoch: [10][7/9]\tTime 0.167756 (0.213)\tData 0.043\tLoss 0.6399\tAccuray 0.8242\n",
      "[2 1 1 2 2 2 2 1 2 1 2 1 2 1 1 2 2 1 2 1 2 1 1 2 1 1 2 1 1 2]\n",
      "[0 1 1 2 0 2 0 1 0 1 2 1 2 1 1 2 2 1 0 1 2 1 1 2 1 1 0 1 1 0]\n",
      "kappa:\t0.034, accuracy:\t0.767\n",
      "Epoch: [11][7/9]\tTime 0.167377 (0.216)\tData 0.044\tLoss 0.5996\tAccuray 0.8477\n",
      "[1 2 1 1 1 1 2 1 1 2 2 1 1 1 2 1 2 2 2 2 2 1 2 2 1 2 2 1 1 2]\n",
      "[1 2 1 1 1 1 0 1 1 2 2 1 1 1 2 1 0 0 0 2 0 1 2 2 1 2 0 1 1 0]\n",
      "kappa:\t0.034, accuracy:\t0.767\n"
     ]
    }
   ],
   "source": [
    "# main()\n",
    "for i in range(5):\n",
    "    main(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('====> parse options')\n",
    "# opt = parse_args()\n",
    "# print(opt)\n",
    "    \n",
    "#     os.makedirs(opt.out_dir, exist_ok=True)\n",
    "#     time_stamp = time.strftime('%Y%m%d%H%M%S', time.localtime(time.time()))\n",
    "#     out_dir = os.path.join(opt.out_dir, 'alzheimer_recognition_{}'.format(time_stamp))\n",
    "#     os.makedirs(out_dir, exist_ok=True)\n",
    "#     print('====> building model:')\n",
    "# model = resnet34(num_classes=3, shortcut_type=True, sample_size=79, sample_duration=95)\n",
    "# initial_cls_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls '/data/beast/df/alzheimer/out_model/alzheimer_recognition_20191018150905/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_weights = '/data/beast/df/alzheimer/out_model/alzheimer_recognition_20191022143605/alzheimer_recognition_0091_best.pth'\n",
    "# model.load_state_dict(torch.load(model_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calc_stat_info(infile):\n",
    "#     f = h5py.File(infile)\n",
    "#     images = f['data']\n",
    "#     mean = np.mean(images)\n",
    "#     std = np.std(images)\n",
    "#     return mean, std\n",
    "\n",
    "# mean, std = calc_stat_info(opt.train_images)\n",
    "# print('mean:\\t{}'.format(mean))\n",
    "# print('std:\\t{}'.format(std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlzheimerPredictDS(Dataset):\n",
    "    def __init__(self, infile, mean, std):\n",
    "        f = h5py.File(infile)\n",
    "        images = f['data']\n",
    "        self.images = np.transpose(images, [0,1,3,2,4])\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.images = (self.images - self.mean)/self.std\n",
    "        self.images = torch.from_numpy(self.images).float()\n",
    "    def __getitem__(self, item):\n",
    "        image = self.images[item]\n",
    "        return image, item\n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "    \n",
    "# eval_ds = AlzheimerPredictDS('/data/beast/df/alzheimer/testa.h5', mean, std)\n",
    "# eval_data_loader = DataLoader(eval_ds, batch_size=4, num_workers=2, shuffle=False, pin_memory=False)\n",
    "# for i, (images, items) in enumerate(eval_data_loader):\n",
    "#     print(images.shape)\n",
    "#     print(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_eval(eval_data_loader, model, display):\n",
    "    model.eval()\n",
    "    tot_pred = np.array([], dtype=int)\n",
    "    tot_items = np.array([], dtype=int)\n",
    "    tot_pred_probs = np.array([], dtype=float)\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    end = time.time()\n",
    "    logger = []\n",
    "    for num_iter, (images, items) in enumerate(eval_data_loader):\n",
    "        data_time.update(time.time()-end)\n",
    "        output = model(Variable(images.cuda()))\n",
    "#         print(output.cpu().data.numpy().squeeze())\n",
    "        probs = torch.nn.functional.softmax(output.cpu())\n",
    "        probs = probs.data.numpy().squeeze()\n",
    "#         print(probs)\n",
    "        tot_pred_probs = np.append(tot_pred_probs, probs)\n",
    "        _,pred = torch.max(output, 1)\n",
    "        pred = pred.cpu().data.numpy().squeeze()\n",
    "        items = items.numpy().squeeze()\n",
    "        batch_time.update(time.time()-end)\n",
    "        tot_pred = np.append(tot_pred, pred)\n",
    "        tot_items = np.append(tot_items, items)\n",
    "        end = time.time()\n",
    "    return tot_pred, tot_items, tot_pred_probs\n",
    "        \n",
    "# pred, items = predict_eval(eval_data_loader, nn.DataParallel(model).cuda(), 2)\n",
    "# print(pred)\n",
    "# print(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(infile, model_weights=None):\n",
    "    print('====> parse options')\n",
    "    opt = parse_args()\n",
    "    print(opt)\n",
    "    model = resnet18(num_classes=3, shortcut_type=True, sample_size=79, sample_duration=95)\n",
    "    initial_cls_weights(model)\n",
    "#     model_weights = '/data/beast/df/alzheimer/out_model/alzheimer_recognition_20191022165341/alzheimer_recognition_0056_best.pth'\n",
    "#     if not model_weights:\n",
    "    model.load_state_dict(torch.load(model_weights))\n",
    "    eval_ds = AlzheimerPredictDS(infile, mean, std)\n",
    "    eval_data_loader = DataLoader(eval_ds, batch_size=4, num_workers=2, shuffle=False, pin_memory=False)\n",
    "    pred, items, probs = predict_eval(eval_data_loader, nn.DataParallel(model).cuda(), 2)\n",
    "    return pred, items, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infiles = []\n",
    "# infiles.append('/data/beast/df/alzheimer/out_model/alzheimer_recognition_xxx_0/alzheimer_recognition_0059_best.pth')\n",
    "# infiles.append('/data/beast/df/alzheimer/out_model/alzheimer_recognition_xxx_1/alzheimer_recognition_0053_best.pth')\n",
    "# infiles.append('/data/beast/df/alzheimer/out_model/alzheimer_recognition_xxx_2/alzheimer_recognition_0043_best.pth')\n",
    "infiles.append('/data/beast/df/alzheimer/out_model/alzheimer_recognition_xxx_3/alzheimer_recognition_0050_best.pth')\n",
    "# infiles.append('/data/beast/df/alzheimer/out_model/alzheimer_recognition_xxx_4/alzheimer_recognition_0080_best.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile_a = '/data/beast/df/alzheimer/testa.h5'\n",
    "infile_b = '/data/beast/df/alzheimer/testb.h5'\n",
    "test_id = None\n",
    "probs = []\n",
    "for i in range(len(infiles)):\n",
    "    pred_a, items_a, probs_a = predict(infile_a, infiles[0])\n",
    "    pred_b, items_b, probs_b = predict(infile_b, infiles[0])\n",
    "    test_id = ['testa_{}'.format(i) for i in items_a] + ['testb_{}'.format(i) for i in items_b]\n",
    "    test_id = np.array(test_id)\n",
    "    probs_ab = np.array([], dtype=float)\n",
    "    probs_ab = np.append(probs_ab, probs_a)\n",
    "    probs_ab = np.append(probs_ab, probs_b)\n",
    "    probs.append(probs_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_res = None\n",
    "for i in range(len(probs)):\n",
    "    if probs_res is None:\n",
    "        probs_res = probs[0].copy()\n",
    "        print(probs_res.shape)\n",
    "        continue\n",
    "    probs_res = probs_res + probs[i]\n",
    "print(probs_res.shape)\n",
    "probs_res = np.resize(probs_res, (232,3))\n",
    "print(probs_res.shape)\n",
    "label_res = np.argmax(probs_res, axis=1)\n",
    "label = np.array(label_res, dtype=int)\n",
    "print(label.shape)\n",
    "print(probs_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infile_a = '/data/beast/df/alzheimer/testa.h5'\n",
    "# infile_b = '/data/beast/df/alzheimer/testb.h5'\n",
    "# pred_a, items_a, probs_a = predict(infile_a, infiles[0])\n",
    "# pred_b, items_b, probs_b = predict(infile_b, infiles[0])\n",
    "# test_id = ['testa_{}'.format(i) for i in items_a] + ['testb_{}'.format(i) for i in items_b]\n",
    "# test_id = np.array(test_id)\n",
    "# label = np.array([], dtype=int)\n",
    "# label = np.append(label, pred_a)\n",
    "# label = np.append(label, pred_b)\n",
    "# # print(label)\n",
    "# # print(test_id)\n",
    "# print(label.shape)\n",
    "# print(test_id.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_id.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'testa_id': test_id, 'label': label}\n",
    "df_result = pd.DataFrame(data=d)\n",
    "df_result.to_csv('./result_mean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls /data/beast/df/alzheimer/out_model/alzheimer_recognition_20191022143605"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infiles = []\n",
    "infiles.append('/data/beast/df/alzheimer/out_model/alzheimer_recognition_xxx_0/alzheimer_recognition_0046_best.pth')\n",
    "infiles.append('/data/beast/df/alzheimer/out_model/alzheimer_recognition_xxx_1/alzheimer_recognition_0067_best.pth')\n",
    "infiles.append('/data/beast/df/alzheimer/out_model/alzheimer_recognition_xxx_2/alzheimer_recognition_0076_best.pth')\n",
    "infiles.append('/data/beast/df/alzheimer/out_model/alzheimer_recognition_xxx_3/alzheimer_recognition_0057_best.pth')\n",
    "infiles.append('/data/beast/df/alzheimer/out_model/alzheimer_recognition_xxx_4/alzheimer_recognition_0084_best.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
